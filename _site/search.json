[
  {
    "objectID": "In-Class_Ex/In-Class_Ex_5/MC1.html",
    "href": "In-Class_Ex/In-Class_Ex_5/MC1.html",
    "title": "In-Class Exercise 05",
    "section": "",
    "text": "MC 01\npacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph, ggraph)\nkg &lt;- fromJSON(\"data/MC1_graph.json\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex_5/MC1.html#initial-eda",
    "href": "In-Class_Ex/In-Class_Ex_5/MC1.html#initial-eda",
    "title": "In-Class Exercise 05",
    "section": "Initial EDA",
    "text": "Initial EDA\n\nggplot(data = edges_tbl, aes(y = `Edge Type`)) + \n  geom_bar()"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex_5/MC1.html#creating-knowledge-graph",
    "href": "In-Class_Ex/In-Class_Ex_5/MC1.html#creating-knowledge-graph",
    "title": "In-Class Exercise 05",
    "section": "Creating knowledge graph",
    "text": "Creating knowledge graph\n\nStep 1: Mapping from node id to row index\n\nid_map &lt;- tibble(id = nodes_tbl$id, index = seq_len(nrow(nodes_tbl)))\n\n\n\nStep 2: Map source and target IDs to row indices\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"), suffix = c(\"\", \"_source\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"), suffix = c(\"\", \"_target\")) %&gt;%\n  rename(to = index)\n\n\n\nStep 3\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n\n\nStep 4: Creating the graph\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl, edges = edges_tbl, \n                   directed = kg$directed)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex_5/MC1.html#visualizing-the-knowledge-graph",
    "href": "In-Class_Ex/In-Class_Ex_5/MC1.html#visualizing-the-knowledge-graph",
    "title": "In-Class Exercise 05",
    "section": "Visualizing the knowledge graph",
    "text": "Visualizing the knowledge graph\n\nset.seed(1234)\n\n\nVisualizing the whole Graph\n\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(alpha = 0.3, colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`), size = 4) +\n  geom_node_text(aes(label = name), repel = TRUE, size = 2.5) +\n  theme_void()\n\n\nStep 1: Filter edges to only “MemberOf”\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%\n  filter(`Edge Type` == \"MemberOf\")\n\n\n\nStep 2: Extract only connected nodes (ie. used in these edges)\n\nused_node_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from, to) %&gt;%\n  unlist() %&gt;%\n  unique()\n\n\n\nStep 3: Keep only those nodes\n\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_node_indices) %&gt;%\n  select(-row_id)  #optional cleanup\n\n\n\nPlot the sub-graph\n\nggraph(graph_memberof, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5, colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`), size = 1) +\n  geom_node_text(aes(label = name), repel = TRUE, size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course.\nThe Reference materials used can be found in Prof Kam Tin Seong’s course Webpage.\nhttps://isss608-ay2024-25apr.netlify.app/"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1B/Take-home_Ex01B.html",
    "href": "Take-home_Ex/Take-home_Ex_1B/Take-home_Ex01B.html",
    "title": "Take-home Exercise 01B",
    "section": "",
    "text": "Phase 2: to select one submission provided by a classmate, critic three good design principles and three areas for further improvement. With reference to the comment, prepare the makeover version of the data visualisation. I am selecting this submission from other classmate, as shown here.\n\n\nThe data should be processed by using appropriate tidyverse family of packages and the data visualisation must be prepared using ggplot2 and its extensions.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggplot2) \n\n\n\n\nTo accomplish the task, Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore (DOS) will be used and we wil load it as follows:\n\npop_data &lt;- read_csv(\"data/respopagesex2024.csv\", col_names = TRUE)\n\n\n\n\n\n\nOriginal Data Visualization:\n\npyramid_data &lt;- pop_data %&gt;%\n  group_by(Age, Sex) %&gt;%\n  summarise(Pop = sum(Pop), .groups = \"drop\") %&gt;%\n  mutate(Pop = ifelse(Sex == \"Males\", -Pop, Pop))\n\nggplot(pyramid_data, aes(x = Age, y = Pop, fill = Sex)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_y_continuous(labels = abs) +\n  scale_fill_manual(values = c(\"Males\" = \"#102E50\", \"Females\" = \"#F7CFD8\")) + \n  scale_x_discrete(breaks = seq(0, 100, by = 10)) +\n  labs(title = \"Singapore Age Pyramid (2024)\",\n       x = \"Age\", y = \"Population\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nComments:\nThree good design principles:\n\nDifferent contrast colours are used to differentiate between Males and Females Resident count\nAppropriate use of chart (pyramid chart) instead of points to represent discrete values\nClear labeling for chart title, legend, x axis title and y axis title\n\nThree areas for further improvement:\n\nAxis Labeling and Scale Consistency\nConfusing x axis (starts from 0) and y axis (0 starts from the center) labeling. And, the distance between 0 to 10 to 20 on the y-axis is not consistent which signalling there is an error in the data preparation. The y-axis values ranges from 0 mark to 80 mark, whereas the dataset for Age ranges from 0 to 90+. There should be a 90 mark in the y-axis to represent the clearer and more accurate representation of the chart.\nGraphical Integrity: The top chart shows 2 wide bars after tapering off of the top pyramid which is not a true representation of the dataset. There should be a data cleaning performed before the visualization to change the data type for Age column from strings to integer and there is 1 value in the Age column: 90_and_Over that needs to be recoded to a numeric number. The lack of data preparation has led to the wrong representation of the data in this chart.\nGroup Ages into 5-Year Bins: The current age pyramid displays age in single-year intervals, resulting in a visually dense and harder-to-read chart. Binning the ages into 5-year groups (e.g., 0–4, 5–9, …, 85–89, 90+) would simplify the structure and highlight broader population trends more effectively. Additionally, including a vertical line to indicate the median age would provide a valuable reference point, making it easier to interpret the overall age distribution and identify demographic imbalance\n\nMakeover version of the Chart\nSome data preparation is needed: - to make the age group of interval 5 years from 0 to 90+ - to change the data type of Age from character to numeric\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\n# Data preparation\npyramid_data &lt;- pop_data %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"91\", Age),\n         Age = as.numeric(Age)) %&gt;%\n  filter(!is.na(Age)) %&gt;%\n  mutate(AgeGroup = cut(Age,\n                        breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45,\n                                   50, 55, 60, 65, 70, 75, 80, 85, 90, Inf),\n                        right = TRUE,\n                        include.lowest = TRUE,\n                        labels = c(\"0–5\", \"6–10\", \"11–15\", \"16–20\", \"21–25\",\n                                   \"26–30\", \"31–35\", \"36–40\", \"41–45\", \"46–50\",\n                                   \"51–55\", \"56–60\", \"61–65\", \"66–70\", \"71–75\",\n                                   \"76–80\", \"81–85\", \"86–90\", \"90+\"))) %&gt;%\n  group_by(AgeGroup, Sex) %&gt;%\n  summarise(Pop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(Pop = ifelse(Sex == \"Males\", -Pop, Pop),\n         Label = comma(abs(Pop), accuracy = 1),\n         Rank = dense_rank(desc(AgeGroup)))\n\nmedian_group &lt;- pyramid_data %&gt;%\n  group_by(AgeGroup) %&gt;%\n  summarise(TotalPop = sum(abs(Pop))) %&gt;%\n  mutate(CumSum = cumsum(TotalPop),\n         MedianFlag = CumSum &gt;= sum(TotalPop) / 2) %&gt;%\n  filter(MedianFlag) %&gt;%\n  slice(1) %&gt;%\n  pull(AgeGroup)\n\n# Plot\nggplot(pyramid_data, aes(x = AgeGroup, y = Pop, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 0.9) +\n  geom_text(aes(label = Label,\n              hjust = case_when(\n                AgeGroup %in% c(\"90+\", \"86–90\") & Sex == \"Males\" ~ 1.1,\n                AgeGroup %in% c(\"90+\", \"86–90\") & Sex == \"Females\" ~ -0.1,\n                Sex == \"Males\" ~ 0,  # centered inside left bar\n                Sex == \"Females\" ~ 1.5  # centered inside right bar\n              )),\n          size = 3, color = \"black\") +  # &lt;- Added the missing plus sign here\n  geom_vline(xintercept = 0, color = \"black\") +\n  coord_flip() +\n  scale_y_continuous(labels = NULL, breaks = NULL) +  # Remove x-axis tick values\n  scale_fill_manual(values = c(\"Males\" = \"#7EC8E3\", \"Females\" = \"#F7CFD8\")) +\n  labs(title = \"Singapore Population Age Pyramid (2024)\",\n       x = \"Age Group (Years)\", y = NULL, fill = \"Sex\") +\n  theme_minimal(base_size = 11) +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        axis.text.y = element_text(size = 9),\n        panel.grid.major.y = element_blank(),\n        legend.position = \"right\") +\n  annotate(\"text\", x = median_group, y = 0,\n           label = paste(\"Median:\", median_group),\n           vjust = -0.8, fontface = \"italic\", color = \"gray40\", size = 4)\n\n\n\n\n\n\n\nOriginal Visualization:\n\nlibrary(tidyverse)\n\n# Summarise total and elderly population by PA\ntop_areas &lt;- pop_data %&gt;%\n  group_by(PA) %&gt;%\n  summarise(\n    Total = sum(Pop),\n    Elderly = sum(Pop[Age &gt;= 65]),\n    .groups = \"drop\"\n  ) %&gt;%\n  \n  top_n(15, Total)  # or 20 if you prefer\n\n# Reshape into long format for grouped bars\nplot_data &lt;- top_areas %&gt;%\n  pivot_longer(cols = c(Total, Elderly),\n               names_to = \"Type\",\n               values_to = \"Population\") %&gt;%\n  mutate(\n    Type = recode(Type,\n                  \"Total\" = \"Total Population\",\n                  \"Elderly\" = \"Elderly (65+)\")\n  )\n# Reorder PA by Total Population (not elderly)\nplot_data &lt;- plot_data %&gt;%\n  left_join(top_areas %&gt;% select(PA, Total), by = \"PA\") %&gt;%\n  mutate(PA = fct_reorder(PA, Total, .desc = FALSE))  # use forcats::fct_reorder\n\nggplot(plot_data, aes(x = PA, y = Population, fill = Type)) +\n  geom_col(position = \"dodge\") +\n  geom_text(aes(label = scales::comma(Population)),\n            position = position_dodge(width = 0.9), hjust = -0.1, size = 3) +\n  scale_y_continuous(labels = scales::comma,\n                     expand = expansion(mult = c(0, 0.15))) +\n  scale_fill_manual(values = c(\"Total Population\" = \"#8E7DBE\", \"Elderly (65+)\" = \"#EFC000\")) +\n  coord_flip() +\n  labs(\n    title = \"Total vs Elderly Population in Top Planning Areas (2024)\",\n    x = \"Planning Area\",\n    y = \"Population\",\n    fill = \"\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n\n\nComments:\nThree good design principles:\n\nEffective use of contrast colours are used to differentiate between the total population and elderly population count by planning areas\nClear notation of the data values inside the chart\nClear labeling for legend, x axis and y axis title and mark.\n\nThree areas for further improvement\n\nThe chart currently includes both detailed bar annotations and x-axis tick marks, which introduces visual redundancy. When values are already clearly displayed inside or beside the bars, retaining dense tick marks on the x-axis adds clutter without enhancing interpretability. It is advisable to choose either to annotate values inside the chart or to rely on well-spaced x-axis tick marks—not both. Removing one will streamline the visual presentation and improve focus on the data.\nMisleading data due to insufficient data cleaning and preparation. The chart reflects inaccurate figures—e.g., Bedok’s elderly population is overstated as 70,130 instead of the correct 62,990—due to lack of data preparation. Proper data cleaning, including converting the Age column to numeric and recoding “90_and_Over” as 90, is essential to ensure data integrity and reliable insights.\nSorting and chart type The chart should be sorted by elderly population, not total population, to match its stated purpose. Using a stacked bar chart (rather than side-by-side horizontal barbars) would better show the elderly count in relation to the total population within each planning area.\n\nMakeover version of the Chart\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Data Preparation\npop_data &lt;- pop_data %&gt;%\n  mutate(\n    Age = str_trim(Age),\n    Age = case_when(\n      Age == \"90_and_Over\" ~ \"90\",\n      str_detect(Age, \"^[0-9]+$\") ~ Age,\n      TRUE ~ NA_character_\n    ),\n    Age = as.numeric(Age)\n  )\n\n\ntop_areas &lt;- pop_data %&gt;%\n  group_by(PA) %&gt;%\n  summarise(\n    Total = sum(Pop, na.rm = TRUE),\n    Elderly = sum(Pop[Age &gt;= 65], na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  slice_max(Elderly, n = 20)\n\n# Prepare data\nplot_data &lt;- top_areas %&gt;%\n  mutate(NonElderly = Total - Elderly) %&gt;%\n  select(PA, Elderly, NonElderly) %&gt;%\n  pivot_longer(cols = c(Elderly, NonElderly),\n               names_to = \"Group\",\n               values_to = \"Population\") %&gt;%\n  mutate(Group = recode(Group,\n                        \"Elderly\" = \"Elderly (65+)\",\n                        \"NonElderly\" = \"Non-Elderly\"),\n         Group = factor(Group, levels = c(\"Non-Elderly\", \"Elderly (65+)\"))) %&gt;%\n  left_join(top_areas %&gt;% select(PA, Elderly), by = \"PA\") %&gt;%\n  mutate(PA = fct_reorder(PA, Elderly, .desc = FALSE))  \n\n# Plot\nggplot(plot_data, aes(x = PA, y = Population, fill = Group)) +\n  geom_col(width = 0.9) +\n  scale_y_continuous(\n    breaks = seq(25000, 300000, by = 25000),\n    labels = function(x) x / 1000,  # Show in '000\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  scale_fill_manual(values = c(\n    \"Non-Elderly\" = \"#A6D1E6\",\n    \"Elderly (65+)\" = \"#FFB347\"\n  )) +\n  coord_flip() +\n  labs(\n    title = \"Top 20 PA by Elderly Population Count (Age 65+)\",\n    x = \"Planning Area\",\n    y = \"Population (in '000)\",\n    fill = \"\"\n  ) +\n  theme_classic(base_size = 12) +\n  theme(legend.position = \"right\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1B/Take-home_Ex01B.html#the-designing-tool",
    "href": "Take-home_Ex/Take-home_Ex_1B/Take-home_Ex01B.html#the-designing-tool",
    "title": "Take-home Exercise 01B",
    "section": "",
    "text": "The data should be processed by using appropriate tidyverse family of packages and the data visualisation must be prepared using ggplot2 and its extensions.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggplot2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1B/Take-home_Ex01B.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex_1B/Take-home_Ex01B.html#import-data",
    "title": "Take-home Exercise 01B",
    "section": "",
    "text": "To accomplish the task, Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore (DOS) will be used and we wil load it as follows:\n\npop_data &lt;- read_csv(\"data/respopagesex2024.csv\", col_names = TRUE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1B/Take-home_Ex01B.html#data-visualization",
    "href": "Take-home_Ex/Take-home_Ex_1B/Take-home_Ex01B.html#data-visualization",
    "title": "Take-home Exercise 01B",
    "section": "",
    "text": "Original Data Visualization:\n\npyramid_data &lt;- pop_data %&gt;%\n  group_by(Age, Sex) %&gt;%\n  summarise(Pop = sum(Pop), .groups = \"drop\") %&gt;%\n  mutate(Pop = ifelse(Sex == \"Males\", -Pop, Pop))\n\nggplot(pyramid_data, aes(x = Age, y = Pop, fill = Sex)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_y_continuous(labels = abs) +\n  scale_fill_manual(values = c(\"Males\" = \"#102E50\", \"Females\" = \"#F7CFD8\")) + \n  scale_x_discrete(breaks = seq(0, 100, by = 10)) +\n  labs(title = \"Singapore Age Pyramid (2024)\",\n       x = \"Age\", y = \"Population\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nComments:\nThree good design principles:\n\nDifferent contrast colours are used to differentiate between Males and Females Resident count\nAppropriate use of chart (pyramid chart) instead of points to represent discrete values\nClear labeling for chart title, legend, x axis title and y axis title\n\nThree areas for further improvement:\n\nAxis Labeling and Scale Consistency\nConfusing x axis (starts from 0) and y axis (0 starts from the center) labeling. And, the distance between 0 to 10 to 20 on the y-axis is not consistent which signalling there is an error in the data preparation. The y-axis values ranges from 0 mark to 80 mark, whereas the dataset for Age ranges from 0 to 90+. There should be a 90 mark in the y-axis to represent the clearer and more accurate representation of the chart.\nGraphical Integrity: The top chart shows 2 wide bars after tapering off of the top pyramid which is not a true representation of the dataset. There should be a data cleaning performed before the visualization to change the data type for Age column from strings to integer and there is 1 value in the Age column: 90_and_Over that needs to be recoded to a numeric number. The lack of data preparation has led to the wrong representation of the data in this chart.\nGroup Ages into 5-Year Bins: The current age pyramid displays age in single-year intervals, resulting in a visually dense and harder-to-read chart. Binning the ages into 5-year groups (e.g., 0–4, 5–9, …, 85–89, 90+) would simplify the structure and highlight broader population trends more effectively. Additionally, including a vertical line to indicate the median age would provide a valuable reference point, making it easier to interpret the overall age distribution and identify demographic imbalance\n\nMakeover version of the Chart\nSome data preparation is needed: - to make the age group of interval 5 years from 0 to 90+ - to change the data type of Age from character to numeric\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\n# Data preparation\npyramid_data &lt;- pop_data %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"91\", Age),\n         Age = as.numeric(Age)) %&gt;%\n  filter(!is.na(Age)) %&gt;%\n  mutate(AgeGroup = cut(Age,\n                        breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45,\n                                   50, 55, 60, 65, 70, 75, 80, 85, 90, Inf),\n                        right = TRUE,\n                        include.lowest = TRUE,\n                        labels = c(\"0–5\", \"6–10\", \"11–15\", \"16–20\", \"21–25\",\n                                   \"26–30\", \"31–35\", \"36–40\", \"41–45\", \"46–50\",\n                                   \"51–55\", \"56–60\", \"61–65\", \"66–70\", \"71–75\",\n                                   \"76–80\", \"81–85\", \"86–90\", \"90+\"))) %&gt;%\n  group_by(AgeGroup, Sex) %&gt;%\n  summarise(Pop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(Pop = ifelse(Sex == \"Males\", -Pop, Pop),\n         Label = comma(abs(Pop), accuracy = 1),\n         Rank = dense_rank(desc(AgeGroup)))\n\nmedian_group &lt;- pyramid_data %&gt;%\n  group_by(AgeGroup) %&gt;%\n  summarise(TotalPop = sum(abs(Pop))) %&gt;%\n  mutate(CumSum = cumsum(TotalPop),\n         MedianFlag = CumSum &gt;= sum(TotalPop) / 2) %&gt;%\n  filter(MedianFlag) %&gt;%\n  slice(1) %&gt;%\n  pull(AgeGroup)\n\n# Plot\nggplot(pyramid_data, aes(x = AgeGroup, y = Pop, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 0.9) +\n  geom_text(aes(label = Label,\n              hjust = case_when(\n                AgeGroup %in% c(\"90+\", \"86–90\") & Sex == \"Males\" ~ 1.1,\n                AgeGroup %in% c(\"90+\", \"86–90\") & Sex == \"Females\" ~ -0.1,\n                Sex == \"Males\" ~ 0,  # centered inside left bar\n                Sex == \"Females\" ~ 1.5  # centered inside right bar\n              )),\n          size = 3, color = \"black\") +  # &lt;- Added the missing plus sign here\n  geom_vline(xintercept = 0, color = \"black\") +\n  coord_flip() +\n  scale_y_continuous(labels = NULL, breaks = NULL) +  # Remove x-axis tick values\n  scale_fill_manual(values = c(\"Males\" = \"#7EC8E3\", \"Females\" = \"#F7CFD8\")) +\n  labs(title = \"Singapore Population Age Pyramid (2024)\",\n       x = \"Age Group (Years)\", y = NULL, fill = \"Sex\") +\n  theme_minimal(base_size = 11) +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        axis.text.y = element_text(size = 9),\n        panel.grid.major.y = element_blank(),\n        legend.position = \"right\") +\n  annotate(\"text\", x = median_group, y = 0,\n           label = paste(\"Median:\", median_group),\n           vjust = -0.8, fontface = \"italic\", color = \"gray40\", size = 4)\n\n\n\n\n\n\n\nOriginal Visualization:\n\nlibrary(tidyverse)\n\n# Summarise total and elderly population by PA\ntop_areas &lt;- pop_data %&gt;%\n  group_by(PA) %&gt;%\n  summarise(\n    Total = sum(Pop),\n    Elderly = sum(Pop[Age &gt;= 65]),\n    .groups = \"drop\"\n  ) %&gt;%\n  \n  top_n(15, Total)  # or 20 if you prefer\n\n# Reshape into long format for grouped bars\nplot_data &lt;- top_areas %&gt;%\n  pivot_longer(cols = c(Total, Elderly),\n               names_to = \"Type\",\n               values_to = \"Population\") %&gt;%\n  mutate(\n    Type = recode(Type,\n                  \"Total\" = \"Total Population\",\n                  \"Elderly\" = \"Elderly (65+)\")\n  )\n# Reorder PA by Total Population (not elderly)\nplot_data &lt;- plot_data %&gt;%\n  left_join(top_areas %&gt;% select(PA, Total), by = \"PA\") %&gt;%\n  mutate(PA = fct_reorder(PA, Total, .desc = FALSE))  # use forcats::fct_reorder\n\nggplot(plot_data, aes(x = PA, y = Population, fill = Type)) +\n  geom_col(position = \"dodge\") +\n  geom_text(aes(label = scales::comma(Population)),\n            position = position_dodge(width = 0.9), hjust = -0.1, size = 3) +\n  scale_y_continuous(labels = scales::comma,\n                     expand = expansion(mult = c(0, 0.15))) +\n  scale_fill_manual(values = c(\"Total Population\" = \"#8E7DBE\", \"Elderly (65+)\" = \"#EFC000\")) +\n  coord_flip() +\n  labs(\n    title = \"Total vs Elderly Population in Top Planning Areas (2024)\",\n    x = \"Planning Area\",\n    y = \"Population\",\n    fill = \"\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n\n\nComments:\nThree good design principles:\n\nEffective use of contrast colours are used to differentiate between the total population and elderly population count by planning areas\nClear notation of the data values inside the chart\nClear labeling for legend, x axis and y axis title and mark.\n\nThree areas for further improvement\n\nThe chart currently includes both detailed bar annotations and x-axis tick marks, which introduces visual redundancy. When values are already clearly displayed inside or beside the bars, retaining dense tick marks on the x-axis adds clutter without enhancing interpretability. It is advisable to choose either to annotate values inside the chart or to rely on well-spaced x-axis tick marks—not both. Removing one will streamline the visual presentation and improve focus on the data.\nMisleading data due to insufficient data cleaning and preparation. The chart reflects inaccurate figures—e.g., Bedok’s elderly population is overstated as 70,130 instead of the correct 62,990—due to lack of data preparation. Proper data cleaning, including converting the Age column to numeric and recoding “90_and_Over” as 90, is essential to ensure data integrity and reliable insights.\nSorting and chart type The chart should be sorted by elderly population, not total population, to match its stated purpose. Using a stacked bar chart (rather than side-by-side horizontal barbars) would better show the elderly count in relation to the total population within each planning area.\n\nMakeover version of the Chart\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Data Preparation\npop_data &lt;- pop_data %&gt;%\n  mutate(\n    Age = str_trim(Age),\n    Age = case_when(\n      Age == \"90_and_Over\" ~ \"90\",\n      str_detect(Age, \"^[0-9]+$\") ~ Age,\n      TRUE ~ NA_character_\n    ),\n    Age = as.numeric(Age)\n  )\n\n\ntop_areas &lt;- pop_data %&gt;%\n  group_by(PA) %&gt;%\n  summarise(\n    Total = sum(Pop, na.rm = TRUE),\n    Elderly = sum(Pop[Age &gt;= 65], na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  slice_max(Elderly, n = 20)\n\n# Prepare data\nplot_data &lt;- top_areas %&gt;%\n  mutate(NonElderly = Total - Elderly) %&gt;%\n  select(PA, Elderly, NonElderly) %&gt;%\n  pivot_longer(cols = c(Elderly, NonElderly),\n               names_to = \"Group\",\n               values_to = \"Population\") %&gt;%\n  mutate(Group = recode(Group,\n                        \"Elderly\" = \"Elderly (65+)\",\n                        \"NonElderly\" = \"Non-Elderly\"),\n         Group = factor(Group, levels = c(\"Non-Elderly\", \"Elderly (65+)\"))) %&gt;%\n  left_join(top_areas %&gt;% select(PA, Elderly), by = \"PA\") %&gt;%\n  mutate(PA = fct_reorder(PA, Elderly, .desc = FALSE))  \n\n# Plot\nggplot(plot_data, aes(x = PA, y = Population, fill = Group)) +\n  geom_col(width = 0.9) +\n  scale_y_continuous(\n    breaks = seq(25000, 300000, by = 25000),\n    labels = function(x) x / 1000,  # Show in '000\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  scale_fill_manual(values = c(\n    \"Non-Elderly\" = \"#A6D1E6\",\n    \"Elderly (65+)\" = \"#FFB347\"\n  )) +\n  coord_flip() +\n  labs(\n    title = \"Top 20 PA by Elderly Population Count (Age 65+)\",\n    x = \"Planning Area\",\n    y = \"Population (in '000)\",\n    fill = \"\"\n  ) +\n  theme_classic(base_size = 12) +\n  theme(legend.position = \"right\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Creating enlightening and truthful data visualizations involves focusing on accuracy, transparency, and the ability to effectively communicate insights. It’s about presenting data in a way that is both informative and aesthetically pleasing, ensuring the audience can grasp the information quickly and accurately.\n\n\n\nA local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024.\n\n\n\nAssuming the role of the graphical editor of the media company, we are tasked to prepare at most three data visualization for the article.\n\n\n\n\n\nWe load the following R packages using the pacman::p_load() function:\n\ntidyverse: R packages designed for data science\nggrepel: to provides geoms for ggplot2 to repel overlapping text labels\nggthemes: to use additional themes for ggplot2\npatchwork: to prepare composite figure created using ggplot2\nscales: to provide the internal scaling infrastructure used by ggplot2\nggpubr to create publication ready ggplot2 plots.\n\nThe code chunk below uses the p_load() function in the pacman package to check if the packages are installed in the computer.\n\npacman::p_load(tidyverse, ggrepel, patchwork, ggthemes, scales,\n               ggpubr) \n\n\n\n\nTo accomplish the task, Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore (DOS) will be used and we wil load it as follows:\n\ndata &lt;- read_csv(\"data/respopagesex2024.csv\", col_names = TRUE)\n\n\n\n\n\n\nWe first take a look at the data. Using the code below, we can get the details of the dataset which contains 60,424 rows and 6 columns.\n\nglimpse(data)\n\nRows: 60,424\nColumns: 6\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ Age  &lt;chr&gt; \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"5\", \"6\", …\n$ Sex  &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Females\", \"Male…\n$ Pop  &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, 30, 10, 3…\n$ Time &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024,…\n\n\n\n\n\n\nWe notice that there is only one value in Time column (2024) which will not be used for further analysis, we will delete this column as per the code chunk below:\n\n\ndata &lt;- data %&gt;% select(-Time)\n\n\nWe will rename the column names in the dataset for clarity, as detailed provided by the Department of Statistics (DOS), as follows:\n\nPA → Planning Area\nSZ → Subzone\nPop → Resident Count\n\n\n\n\n\n\nSide Note:\n\n\n\nPlease note: according to the DOS accompanying documentation of this dataset, the population figures in the csv file have been rounded to the nearest 10, and as such, total counts may not sum exactly due to rounding adjustments.\n\n\n\ncolnames(data) &lt;- c(\"PlanningArea\", \"SubZone\", \"Age\", \"Sex\", \"ResidentCount\")\n\n\nNext, we observe that for the Age column, there is a value of : “90_and_over”. We will replace this value with “90” and change the data type from string/character to numeric and then create a new column to classify the age according to the age bracket in the interval of 5 years as per the standard age group published in DOS, with the following code:\n\n\ndata &lt;- data %&gt;%\n  mutate(\n    Age = str_to_lower(Age),\n    Age = ifelse(Age == \"90_and_over\", \"90\", Age),\n    Age = as.numeric(Age),\n    AgeGroup = cut(Age,\n                   breaks = c(0,4,9,14,19,24,29,34,39,44,49,54,59,64,69,74,79,84,89, Inf),\n                   labels = c(\"0–4\", \"5–9\", \"10–14\", \"15–19\", \"20–24\", \"25–29\",\n                              \"30–34\", \"35–39\", \"40–44\", \"45–49\", \"50–54\", \n                              \"55–59\", \"60–64\", \"65–69\", \"70–74\", \"75–79\", \n                              \"80–84\", \"85–89\", \"90+\"),\n                   right = TRUE, include.lowest = TRUE)\n  )\n\n\nFurther observation of the dataset, we discover there are multiple rows with “0” values in the “Pop”/“ResidentCount” column. We will remove these rows as per the code chunk below, and calculate the number of rows and total population before and after the deletion to ensure completeness with the following code:\n\n\ntotal_population_before &lt;- sum(data$ResidentCount, na.rm = TRUE)\ntotal_rows_before &lt;- nrow(data)\n\nzero_count &lt;- data %&gt;%\n  filter(ResidentCount == 0) %&gt;%\n  nrow()\n\ncat(\"Total population before cleaning:\", format(total_population_before, big.mark = \",\"), \"\\n\")\n\nTotal population before cleaning: 4,193,530 \n\ncat(\"Total rows before cleaning:\", total_rows_before, \"\\n\")\n\nTotal rows before cleaning: 60424 \n\ncat(\"Rows with 0 ResidentCount removed:\", zero_count, \"\\n\")\n\nRows with 0 ResidentCount removed: 23181 \n\ndata &lt;- data %&gt;%\n  filter(ResidentCount &gt; 0)\n\ntotal_population_after &lt;- sum(data$ResidentCount, na.rm = TRUE)\ntotal_rows_after &lt;- nrow(data)\n\ncat(\"Total population after cleaning:\", format(total_population_after, big.mark = \",\"), \"\\n\")\n\nTotal population after cleaning: 4,193,530 \n\ncat(\"Remaining rows:\", total_rows_after, \"\\n\")\n\nRemaining rows: 37243 \n\n\n\n\n\nNext, Using the duplicated function, we see that there are no duplicate entries in the data.\n\ndata[duplicated(data),]\n\n# A tibble: 0 × 6\n# ℹ 6 variables: PlanningArea &lt;chr&gt;, SubZone &lt;chr&gt;, Age &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   ResidentCount &lt;dbl&gt;, AgeGroup &lt;fct&gt;\n\n\n\n\n\nWe run the code below to check for any missing values, and there is none.\n\ncolSums(is.na(data))\n\n PlanningArea       SubZone           Age           Sex ResidentCount \n            0             0             0             0             0 \n     AgeGroup \n            0 \n\n\n\n\n\nWe run an overview of the final dataset again before proceeding to the visualization. Final dataset contains 37,243 rows and 7 columns:\n\nglimpse(data)\n\nRows: 37,243\nColumns: 6\n$ PlanningArea  &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", …\n$ SubZone       &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang…\n$ Age           &lt;dbl&gt; 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9,…\n$ Sex           &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Female…\n$ ResidentCount &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, …\n$ AgeGroup      &lt;fct&gt; 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 5–9, 5…\n\n\n\n\n\n\n\n\n\nInsights:\n\nThe population pyramid reveals a dominant working-age group between ages 30–44, forming the broadest segment of the chart, with largest age group for Female: from 35-39 age group: 166,150 and Males: from 30-34 age group with 155,630\nThe base is narrower, especially for those aged 0–14, which highlights the ongoing trend of declining birth rates.\nFemales significantly outnumber males from age 65 onwards, highlighting gender differences in life expectancy\nThe median age of 42 reinforces Singapore’s aging trend, with implications for healthcare and eldercare planning.\nThe median age of 42 underscores Singapore’s aging population, signaling increasing needs in healthcare, retirement, and eldercare.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npyramid_data &lt;- data %&gt;%\n  group_by(AgeGroup, Sex) %&gt;%\n  summarise(ResidentCount = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    ResidentCountSigned = ifelse(Sex == \"Males\", -ResidentCount, ResidentCount),\n    fill_color = case_when(\n      Sex == \"Males\" ~ \"#4292c6\",\n      Sex == \"Females\" ~ \"#e377c2\",\n      TRUE ~ \"gray\"\n    ),\n    AgeGroup = factor(AgeGroup, levels = c(\"0–4\", \"5–9\", \"10–14\", \"15–19\", \"20–24\",\n                                           \"25–29\", \"30–34\", \"35–39\", \"40–44\", \"45–49\",\n                                           \"50–54\", \"55–59\", \"60–64\", \"65–69\", \"70–74\",\n                                           \"75–79\", \"80–84\", \"85–89\", \"90+\"))\n  )\n\nmedian_age &lt;- data %&gt;%\n  group_by(Age) %&gt;%\n  summarise(Total = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  arrange(Age) %&gt;%\n  mutate(cum_pop = cumsum(Total), prop = cum_pop / sum(Total)) %&gt;%\n  filter(prop &gt;= 0.5) %&gt;%\n  slice(1) %&gt;%\n  pull(Age)\n\nage_group_labels &lt;- levels(pyramid_data$AgeGroup)\nmedian_group_index &lt;- findInterval(median_age, seq(0, 100, by = 5))\nmedian_group &lt;- age_group_labels[median_group_index]\n\ntotal_males &lt;- pyramid_data %&gt;% filter(Sex == \"Males\") %&gt;% summarise(sum = sum(abs(ResidentCountSigned))) %&gt;% pull(sum)\ntotal_females &lt;- pyramid_data %&gt;% filter(Sex == \"Females\") %&gt;% summarise(sum = sum(ResidentCountSigned)) %&gt;% pull(sum)\n\nggplot(pyramid_data, aes(y = AgeGroup, x = ResidentCountSigned, fill = fill_color)) +\n  geom_col(width = 0.9) +\n  geom_text(aes(label = abs(ResidentCountSigned),\n                x = ifelse(ResidentCountSigned &lt; 0, ResidentCountSigned - 5000, ResidentCountSigned + 5000)),\n            hjust = ifelse(pyramid_data$ResidentCountSigned &lt; 0, 1, 0),\n            size = 3, color = \"black\") +\n  annotate(\"segment\",\n           x = -max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           xend = max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           y = median_group, yend = median_group,\n           linetype = \"dotted\", color = \"#A9A9A9\", linewidth = 0.9) +\n  annotate(\"text\",\n           x = max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           y = median_group,\n           label = paste0(\"Median: \", median_age),\n           hjust = 0, size = 2.8, color = \"black\", fontface = \"bold\") +\n  annotate(\"text\", y = \"0–4\",\n           x = -max(abs(pyramid_data$ResidentCountSigned)) * 0.95,\n           label = paste0(\"Males\\nTotal: \", format(total_males, big.mark = \",\")),\n           size = 2.6, color = \"#1E90FF\", fontface = \"bold\", hjust = 1) +\n  annotate(\"text\", y = \"0–4\",\n           x = max(abs(pyramid_data$ResidentCountSigned)) * 0.95,\n           label = paste0(\"Females\\nTotal: \", format(total_females, big.mark = \",\")),\n           size = 2.6, color = \"#c51b8a\", fontface = \"bold\", hjust = 0) +\n  scale_fill_identity() +\n  scale_x_continuous(labels = abs, expand = expansion(mult = c(0.12, 0.12))) +\n  labs(\n    title = \"Singapore’s Shifting Age Structure (June 2024)\",\n    subtitle = \"Middle-age Population Dominates; Youth Base Shrinking, Elderly Segment Rising\",\n    x = NULL,\n    y = \"Age Group (Years)\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\", margin = margin(b = 6)),\n    plot.subtitle = element_text(hjust = 0.5, size = 12, margin = margin(b = 12)),\n    axis.text.y = element_text(size = 10),\n    axis.title.y = element_text(size = 11, face = \"bold\"),\n    axis.text.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\nInsights:\n\nThe top chart shows the proportion of elderly residents in the top 10 planning areas. Outram has the highest share, with 26.9% of its population are seniors, followed by Ang Mo Kio (24.3%) and Bukit Merah (23.4%). These established towns may benefit from enhanced elderly-supportive environments, such as barrier-free access, senior-oriented amenities, and close-proximity services.\nThe bottom chart presents the elderly resident count, with Bedok having the largest at 60,770, followed by Tampines (49,700) and Hougang (44,640). This is largely due to their larger area size and population base. These towns would benefit from service scaling, such as Active Ageing Centres (AACs), public transport connectivity, and healthcare access.\nWith Singapore’s elderly population projected to reach one in four residents (DOS, 2024), it is important to consider both distribution by proportion and resident count for effective planning.\nThis dual perspective supports the Ministry of Health’s 2023 Action Plan, which aims to double eldercare centres by 2025 and enhance community-based support (MOH, 2023).\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly_data &lt;- data %&gt;% filter(Age &gt;= 65)\n\ntotal_pop &lt;- data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Total_Pop = sum(ResidentCount, na.rm = TRUE))\n\nelderly_count &lt;- elderly_data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Elderly_Pop = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  arrange(desc(Elderly_Pop)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(PlanningArea = fct_reorder(PlanningArea, Elderly_Pop))\n\nelderly_prop &lt;- elderly_data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Elderly_Pop = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  left_join(total_pop, by = \"PlanningArea\") %&gt;%\n  mutate(Elderly_Proportion = Elderly_Pop / Total_Pop) %&gt;%\n  arrange(desc(Elderly_Proportion)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(PlanningArea = fct_reorder(PlanningArea, Elderly_Proportion))\n\n# Plot\np1 &lt;- ggplot(elderly_prop, aes(x = Elderly_Proportion, y = PlanningArea)) +\n  geom_col(fill = \"#4DAF4A\", width = 0.85) +\n  scale_x_continuous(\n    breaks = seq(0, 0.35, by = 0.05),\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Top 10 Planning Areas by Elderly Proportion (Age 65+)\",\n    x = \"Proportion of Elderly Residents\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 11),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n    panel.grid.minor = element_blank()\n  )\n\n\np2 &lt;- ggplot(elderly_count, aes(x = Elderly_Pop, y = PlanningArea)) +\n  geom_col(fill = \"#4DAF4A\", width = 0.85) +\n  scale_x_continuous(\n    breaks = seq(0, 70000, by = 10000),\n    labels = comma_format(),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Top 10 Planning Areas by Elderly Resident Count (Age 65+)\",\n    x = \"Number of Elderly Residents\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 11),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n    panel.grid.minor = element_blank()\n  )\n\np1 / p2\n\n\n\n\n\n\n\nInsights:\n\nTampines, Bedok, and Sengkang top the list of most populated PA with over 250,000 residents each.\nMillennials (age 28–43) are the largest group in most PA, while Gen X dominates in Bedok, a mature estate.\nYounger generations (Gen Alpha and Gen Z) are more concentrated in newer towns like Sengkang, Punggol, and Jurong West, aligned with recent BTO developments that attract young families.\nThe distribution reflects a balanced generational mix, highlighting Singapore’s multigenerational living pattern—with both aging residents and young households sharing town spaces.\nThese trends align with Singapore’s Smart Nation and HDB’s ‘Designing for Life’ vision: fostering harmonious, inclusive communities where families of all ages can live, age, and thrive together through well-integrated facilities, technology, and people-first urban design.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata &lt;- data %&gt;%\n  mutate(Age = as.numeric(Age),\n         Generation = case_when(\n           Age &lt;= 9 ~ \"Gen Alpha (≤9)\",\n           Age &lt;= 27 ~ \"Gen Z (10–27)\",\n           Age &lt;= 43 ~ \"Millennials (28–43)\",\n           Age &lt;= 59 ~ \"Gen X (44–59)\",\n           Age &lt;= 77 ~ \"Baby Boomers (60–77)\",\n           TRUE ~ \"Silent Gen (78+)\"\n         ))\n\ngen_by_area &lt;- data %&gt;%\n  group_by(PlanningArea, Generation) %&gt;%\n  summarise(ResidentCount = sum(ResidentCount, na.rm = TRUE), .groups = \"drop\")\n\ntop10_areas &lt;- gen_by_area %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(TotalPop = sum(ResidentCount)) %&gt;%\n  arrange(desc(TotalPop)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(PlanningArea)\n\ngen_top10 &lt;- gen_by_area %&gt;%\n  filter(PlanningArea %in% top10_areas) %&gt;%\n  mutate(\n    PlanningArea = fct_reorder(PlanningArea, ResidentCount, .fun = sum, .desc = TRUE),\n    Generation = factor(Generation, levels = c(\"Silent Gen (78+)\", \"Baby Boomers (60–77)\",\n                                               \"Gen X (44–59)\", \"Millennials (28–43)\",\n                                               \"Gen Z (10–27)\", \"Gen Alpha (≤9)\"))\n  )\n\ngen_colors &lt;- c(\n  \"Silent Gen (78+)\" = \"#c6dbef\",\n  \"Baby Boomers (60–77)\" = \"#6baed6\",\n  \"Gen X (44–59)\" = \"#b2df8a\",\n  \"Millennials (28–43)\" = \"#33a02c\",\n  \"Gen Z (10–27)\" = \"#fb9a99\",\n  \"Gen Alpha (≤9)\" = \"#e31a1c\"\n)\n\n#Plot\nggplot(gen_top10, aes(x = PlanningArea, y = ResidentCount, fill = Generation)) +\n  geom_col(width = 0.8, color = \"white\") +\n  scale_fill_manual(values = gen_colors) +\n  scale_y_continuous(\n    labels = comma,\n    breaks = seq(0, 300000, 50000),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Generational Composition of Top 10 Most Populated Planning Areas\",\n    subtitle = \"Younger generations dominate newer towns, while older cohorts concentrate in mature estates\",\n    x = \"Planning Area\",\n    y = \"Resident Count\",\n    fill = \"Generation\"\n  ) +\n  theme_clean(base_size = 12) +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 11, hjust = 0.5),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major.x = element_blank(),\n    legend.position = \"right\"\n  )\n\n\n\n\n\n\n\n\nSingapore’s demographic structure, based on June 2024 data, highlights a maturing society with a dominant working-age group and a median age of 42. The growing share of seniors and the narrowing base of younger age groups reflect the effects of population aging and low birth rates. Mature estates such as Outram have the highest proportion of elderly residents, while Bedok and Tampines house the largest absolute numbers. In contrast, newer towns like Sengkang and Punggol show higher concentrations of younger generations—particularly Gen Alpha and Gen Z—driven by recent BTO developments attracting young families. Millennials remain the largest generational group across most areas, reinforcing their role in shaping urban life. This evolving yet balanced generational landscape underscores the need for inclusive community planning that supports both young families and seniors—fostering intergenerational harmony and enabling families to live, age, and thrive together.\n\n\n\n\nDepartment of Statistics Singapore. (2024). Population Trends 2024.\nRetrieved from: https://www.singstat.gov.sg/publications/population/population-trends\nMinistry of Health Singapore. (2023). Action Plan for Successful Ageing.\nRetrieved from: https://www.moh.gov.sg/newsroom/launch-of-the-2023-action-plan-for-successful-ageing\nHousing & Development Board (HDB). (2021). Designing for Life: Community Planning and Design Guide.\nRetrieved from: https://www.hdb.gov.sg/cs/infoweb/designing-for-life\nSmart Nation and Digital Government Office. (2023). Smart Nation: Empowering Everyone Through Technology.\nRetrieved from: https://www.smartnation.gov.sg\nSingapore Department of Statistics. (n.d.). National Statistical Standards.\nRetrieved from: https://www.singstat.gov.sg/standards"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#overview",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#overview",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Creating enlightening and truthful data visualizations involves focusing on accuracy, transparency, and the ability to effectively communicate insights. It’s about presenting data in a way that is both informative and aesthetically pleasing, ensuring the audience can grasp the information quickly and accurately."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#setting-the-scene",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "A local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#the-task",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Assuming the role of the graphical editor of the media company, we are tasked to prepare at most three data visualization for the article."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#getting-started",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "We load the following R packages using the pacman::p_load() function:\n\ntidyverse: R packages designed for data science\nggrepel: to provides geoms for ggplot2 to repel overlapping text labels\nggthemes: to use additional themes for ggplot2\npatchwork: to prepare composite figure created using ggplot2\nscales: to provide the internal scaling infrastructure used by ggplot2\nggpubr to create publication ready ggplot2 plots.\n\nThe code chunk below uses the p_load() function in the pacman package to check if the packages are installed in the computer.\n\npacman::p_load(tidyverse, ggrepel, patchwork, ggthemes, scales,\n               ggpubr) \n\n\n\n\nTo accomplish the task, Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore (DOS) will be used and we wil load it as follows:\n\ndata &lt;- read_csv(\"data/respopagesex2024.csv\", col_names = TRUE)\n\n\n\n\n\n\nWe first take a look at the data. Using the code below, we can get the details of the dataset which contains 60,424 rows and 6 columns.\n\nglimpse(data)\n\nRows: 60,424\nColumns: 6\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ Age  &lt;chr&gt; \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"5\", \"6\", …\n$ Sex  &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Females\", \"Male…\n$ Pop  &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, 30, 10, 3…\n$ Time &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024,…\n\n\n\n\n\n\nWe notice that there is only one value in Time column (2024) which will not be used for further analysis, we will delete this column as per the code chunk below:\n\n\ndata &lt;- data %&gt;% select(-Time)\n\n\nWe will rename the column names in the dataset for clarity, as detailed provided by the Department of Statistics (DOS), as follows:\n\nPA → Planning Area\nSZ → Subzone\nPop → Resident Count\n\n\n\n\n\n\nSide Note:\n\n\n\nPlease note: according to the DOS accompanying documentation of this dataset, the population figures in the csv file have been rounded to the nearest 10, and as such, total counts may not sum exactly due to rounding adjustments.\n\n\n\ncolnames(data) &lt;- c(\"PlanningArea\", \"SubZone\", \"Age\", \"Sex\", \"ResidentCount\")\n\n\nNext, we observe that for the Age column, there is a value of : “90_and_over”. We will replace this value with “90” and change the data type from string/character to numeric and then create a new column to classify the age according to the age bracket in the interval of 5 years as per the standard age group published in DOS, with the following code:\n\n\ndata &lt;- data %&gt;%\n  mutate(\n    Age = str_to_lower(Age),\n    Age = ifelse(Age == \"90_and_over\", \"90\", Age),\n    Age = as.numeric(Age),\n    AgeGroup = cut(Age,\n                   breaks = c(0,4,9,14,19,24,29,34,39,44,49,54,59,64,69,74,79,84,89, Inf),\n                   labels = c(\"0–4\", \"5–9\", \"10–14\", \"15–19\", \"20–24\", \"25–29\",\n                              \"30–34\", \"35–39\", \"40–44\", \"45–49\", \"50–54\", \n                              \"55–59\", \"60–64\", \"65–69\", \"70–74\", \"75–79\", \n                              \"80–84\", \"85–89\", \"90+\"),\n                   right = TRUE, include.lowest = TRUE)\n  )\n\n\nFurther observation of the dataset, we discover there are multiple rows with “0” values in the “Pop”/“ResidentCount” column. We will remove these rows as per the code chunk below, and calculate the number of rows and total population before and after the deletion to ensure completeness with the following code:\n\n\ntotal_population_before &lt;- sum(data$ResidentCount, na.rm = TRUE)\ntotal_rows_before &lt;- nrow(data)\n\nzero_count &lt;- data %&gt;%\n  filter(ResidentCount == 0) %&gt;%\n  nrow()\n\ncat(\"Total population before cleaning:\", format(total_population_before, big.mark = \",\"), \"\\n\")\n\nTotal population before cleaning: 4,193,530 \n\ncat(\"Total rows before cleaning:\", total_rows_before, \"\\n\")\n\nTotal rows before cleaning: 60424 \n\ncat(\"Rows with 0 ResidentCount removed:\", zero_count, \"\\n\")\n\nRows with 0 ResidentCount removed: 23181 \n\ndata &lt;- data %&gt;%\n  filter(ResidentCount &gt; 0)\n\ntotal_population_after &lt;- sum(data$ResidentCount, na.rm = TRUE)\ntotal_rows_after &lt;- nrow(data)\n\ncat(\"Total population after cleaning:\", format(total_population_after, big.mark = \",\"), \"\\n\")\n\nTotal population after cleaning: 4,193,530 \n\ncat(\"Remaining rows:\", total_rows_after, \"\\n\")\n\nRemaining rows: 37243 \n\n\n\n\n\nNext, Using the duplicated function, we see that there are no duplicate entries in the data.\n\ndata[duplicated(data),]\n\n# A tibble: 0 × 6\n# ℹ 6 variables: PlanningArea &lt;chr&gt;, SubZone &lt;chr&gt;, Age &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   ResidentCount &lt;dbl&gt;, AgeGroup &lt;fct&gt;\n\n\n\n\n\nWe run the code below to check for any missing values, and there is none.\n\ncolSums(is.na(data))\n\n PlanningArea       SubZone           Age           Sex ResidentCount \n            0             0             0             0             0 \n     AgeGroup \n            0 \n\n\n\n\n\nWe run an overview of the final dataset again before proceeding to the visualization. Final dataset contains 37,243 rows and 7 columns:\n\nglimpse(data)\n\nRows: 37,243\nColumns: 6\n$ PlanningArea  &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", …\n$ SubZone       &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang…\n$ Age           &lt;dbl&gt; 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9,…\n$ Sex           &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Female…\n$ ResidentCount &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, …\n$ AgeGroup      &lt;fct&gt; 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 5–9, 5…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#data-visualization",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#data-visualization",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Insights:\n\nThe population pyramid reveals a dominant working-age group between ages 30–44, forming the broadest segment of the chart, with largest age group for Female: from 35-39 age group: 166,150 and Males: from 30-34 age group with 155,630\nThe base is narrower, especially for those aged 0–14, which highlights the ongoing trend of declining birth rates.\nFemales significantly outnumber males from age 65 onwards, highlighting gender differences in life expectancy\nThe median age of 42 reinforces Singapore’s aging trend, with implications for healthcare and eldercare planning.\nThe median age of 42 underscores Singapore’s aging population, signaling increasing needs in healthcare, retirement, and eldercare.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npyramid_data &lt;- data %&gt;%\n  group_by(AgeGroup, Sex) %&gt;%\n  summarise(ResidentCount = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    ResidentCountSigned = ifelse(Sex == \"Males\", -ResidentCount, ResidentCount),\n    fill_color = case_when(\n      Sex == \"Males\" ~ \"#4292c6\",\n      Sex == \"Females\" ~ \"#e377c2\",\n      TRUE ~ \"gray\"\n    ),\n    AgeGroup = factor(AgeGroup, levels = c(\"0–4\", \"5–9\", \"10–14\", \"15–19\", \"20–24\",\n                                           \"25–29\", \"30–34\", \"35–39\", \"40–44\", \"45–49\",\n                                           \"50–54\", \"55–59\", \"60–64\", \"65–69\", \"70–74\",\n                                           \"75–79\", \"80–84\", \"85–89\", \"90+\"))\n  )\n\nmedian_age &lt;- data %&gt;%\n  group_by(Age) %&gt;%\n  summarise(Total = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  arrange(Age) %&gt;%\n  mutate(cum_pop = cumsum(Total), prop = cum_pop / sum(Total)) %&gt;%\n  filter(prop &gt;= 0.5) %&gt;%\n  slice(1) %&gt;%\n  pull(Age)\n\nage_group_labels &lt;- levels(pyramid_data$AgeGroup)\nmedian_group_index &lt;- findInterval(median_age, seq(0, 100, by = 5))\nmedian_group &lt;- age_group_labels[median_group_index]\n\ntotal_males &lt;- pyramid_data %&gt;% filter(Sex == \"Males\") %&gt;% summarise(sum = sum(abs(ResidentCountSigned))) %&gt;% pull(sum)\ntotal_females &lt;- pyramid_data %&gt;% filter(Sex == \"Females\") %&gt;% summarise(sum = sum(ResidentCountSigned)) %&gt;% pull(sum)\n\nggplot(pyramid_data, aes(y = AgeGroup, x = ResidentCountSigned, fill = fill_color)) +\n  geom_col(width = 0.9) +\n  geom_text(aes(label = abs(ResidentCountSigned),\n                x = ifelse(ResidentCountSigned &lt; 0, ResidentCountSigned - 5000, ResidentCountSigned + 5000)),\n            hjust = ifelse(pyramid_data$ResidentCountSigned &lt; 0, 1, 0),\n            size = 3, color = \"black\") +\n  annotate(\"segment\",\n           x = -max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           xend = max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           y = median_group, yend = median_group,\n           linetype = \"dotted\", color = \"#A9A9A9\", linewidth = 0.9) +\n  annotate(\"text\",\n           x = max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           y = median_group,\n           label = paste0(\"Median: \", median_age),\n           hjust = 0, size = 2.8, color = \"black\", fontface = \"bold\") +\n  annotate(\"text\", y = \"0–4\",\n           x = -max(abs(pyramid_data$ResidentCountSigned)) * 0.95,\n           label = paste0(\"Males\\nTotal: \", format(total_males, big.mark = \",\")),\n           size = 2.6, color = \"#1E90FF\", fontface = \"bold\", hjust = 1) +\n  annotate(\"text\", y = \"0–4\",\n           x = max(abs(pyramid_data$ResidentCountSigned)) * 0.95,\n           label = paste0(\"Females\\nTotal: \", format(total_females, big.mark = \",\")),\n           size = 2.6, color = \"#c51b8a\", fontface = \"bold\", hjust = 0) +\n  scale_fill_identity() +\n  scale_x_continuous(labels = abs, expand = expansion(mult = c(0.12, 0.12))) +\n  labs(\n    title = \"Singapore’s Shifting Age Structure (June 2024)\",\n    subtitle = \"Middle-age Population Dominates; Youth Base Shrinking, Elderly Segment Rising\",\n    x = NULL,\n    y = \"Age Group (Years)\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\", margin = margin(b = 6)),\n    plot.subtitle = element_text(hjust = 0.5, size = 12, margin = margin(b = 12)),\n    axis.text.y = element_text(size = 10),\n    axis.title.y = element_text(size = 11, face = \"bold\"),\n    axis.text.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\nInsights:\n\nThe top chart shows the proportion of elderly residents in the top 10 planning areas. Outram has the highest share, with 26.9% of its population are seniors, followed by Ang Mo Kio (24.3%) and Bukit Merah (23.4%). These established towns may benefit from enhanced elderly-supportive environments, such as barrier-free access, senior-oriented amenities, and close-proximity services.\nThe bottom chart presents the elderly resident count, with Bedok having the largest at 60,770, followed by Tampines (49,700) and Hougang (44,640). This is largely due to their larger area size and population base. These towns would benefit from service scaling, such as Active Ageing Centres (AACs), public transport connectivity, and healthcare access.\nWith Singapore’s elderly population projected to reach one in four residents (DOS, 2024), it is important to consider both distribution by proportion and resident count for effective planning.\nThis dual perspective supports the Ministry of Health’s 2023 Action Plan, which aims to double eldercare centres by 2025 and enhance community-based support (MOH, 2023).\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly_data &lt;- data %&gt;% filter(Age &gt;= 65)\n\ntotal_pop &lt;- data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Total_Pop = sum(ResidentCount, na.rm = TRUE))\n\nelderly_count &lt;- elderly_data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Elderly_Pop = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  arrange(desc(Elderly_Pop)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(PlanningArea = fct_reorder(PlanningArea, Elderly_Pop))\n\nelderly_prop &lt;- elderly_data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Elderly_Pop = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  left_join(total_pop, by = \"PlanningArea\") %&gt;%\n  mutate(Elderly_Proportion = Elderly_Pop / Total_Pop) %&gt;%\n  arrange(desc(Elderly_Proportion)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(PlanningArea = fct_reorder(PlanningArea, Elderly_Proportion))\n\n# Plot\np1 &lt;- ggplot(elderly_prop, aes(x = Elderly_Proportion, y = PlanningArea)) +\n  geom_col(fill = \"#4DAF4A\", width = 0.85) +\n  scale_x_continuous(\n    breaks = seq(0, 0.35, by = 0.05),\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Top 10 Planning Areas by Elderly Proportion (Age 65+)\",\n    x = \"Proportion of Elderly Residents\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 11),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n    panel.grid.minor = element_blank()\n  )\n\n\np2 &lt;- ggplot(elderly_count, aes(x = Elderly_Pop, y = PlanningArea)) +\n  geom_col(fill = \"#4DAF4A\", width = 0.85) +\n  scale_x_continuous(\n    breaks = seq(0, 70000, by = 10000),\n    labels = comma_format(),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Top 10 Planning Areas by Elderly Resident Count (Age 65+)\",\n    x = \"Number of Elderly Residents\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 11),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n    panel.grid.minor = element_blank()\n  )\n\np1 / p2\n\n\n\n\n\n\n\nInsights:\n\nTampines, Bedok, and Sengkang top the list of most populated PA with over 250,000 residents each.\nMillennials (age 28–43) are the largest group in most PA, while Gen X dominates in Bedok, a mature estate.\nYounger generations (Gen Alpha and Gen Z) are more concentrated in newer towns like Sengkang, Punggol, and Jurong West, aligned with recent BTO developments that attract young families.\nThe distribution reflects a balanced generational mix, highlighting Singapore’s multigenerational living pattern—with both aging residents and young households sharing town spaces.\nThese trends align with Singapore’s Smart Nation and HDB’s ‘Designing for Life’ vision: fostering harmonious, inclusive communities where families of all ages can live, age, and thrive together through well-integrated facilities, technology, and people-first urban design.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata &lt;- data %&gt;%\n  mutate(Age = as.numeric(Age),\n         Generation = case_when(\n           Age &lt;= 9 ~ \"Gen Alpha (≤9)\",\n           Age &lt;= 27 ~ \"Gen Z (10–27)\",\n           Age &lt;= 43 ~ \"Millennials (28–43)\",\n           Age &lt;= 59 ~ \"Gen X (44–59)\",\n           Age &lt;= 77 ~ \"Baby Boomers (60–77)\",\n           TRUE ~ \"Silent Gen (78+)\"\n         ))\n\ngen_by_area &lt;- data %&gt;%\n  group_by(PlanningArea, Generation) %&gt;%\n  summarise(ResidentCount = sum(ResidentCount, na.rm = TRUE), .groups = \"drop\")\n\ntop10_areas &lt;- gen_by_area %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(TotalPop = sum(ResidentCount)) %&gt;%\n  arrange(desc(TotalPop)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(PlanningArea)\n\ngen_top10 &lt;- gen_by_area %&gt;%\n  filter(PlanningArea %in% top10_areas) %&gt;%\n  mutate(\n    PlanningArea = fct_reorder(PlanningArea, ResidentCount, .fun = sum, .desc = TRUE),\n    Generation = factor(Generation, levels = c(\"Silent Gen (78+)\", \"Baby Boomers (60–77)\",\n                                               \"Gen X (44–59)\", \"Millennials (28–43)\",\n                                               \"Gen Z (10–27)\", \"Gen Alpha (≤9)\"))\n  )\n\ngen_colors &lt;- c(\n  \"Silent Gen (78+)\" = \"#c6dbef\",\n  \"Baby Boomers (60–77)\" = \"#6baed6\",\n  \"Gen X (44–59)\" = \"#b2df8a\",\n  \"Millennials (28–43)\" = \"#33a02c\",\n  \"Gen Z (10–27)\" = \"#fb9a99\",\n  \"Gen Alpha (≤9)\" = \"#e31a1c\"\n)\n\n#Plot\nggplot(gen_top10, aes(x = PlanningArea, y = ResidentCount, fill = Generation)) +\n  geom_col(width = 0.8, color = \"white\") +\n  scale_fill_manual(values = gen_colors) +\n  scale_y_continuous(\n    labels = comma,\n    breaks = seq(0, 300000, 50000),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Generational Composition of Top 10 Most Populated Planning Areas\",\n    subtitle = \"Younger generations dominate newer towns, while older cohorts concentrate in mature estates\",\n    x = \"Planning Area\",\n    y = \"Resident Count\",\n    fill = \"Generation\"\n  ) +\n  theme_clean(base_size = 12) +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 11, hjust = 0.5),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major.x = element_blank(),\n    legend.position = \"right\"\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#summary",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#summary",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Singapore’s demographic structure, based on June 2024 data, highlights a maturing society with a dominant working-age group and a median age of 42. The growing share of seniors and the narrowing base of younger age groups reflect the effects of population aging and low birth rates. Mature estates such as Outram have the highest proportion of elderly residents, while Bedok and Tampines house the largest absolute numbers. In contrast, newer towns like Sengkang and Punggol show higher concentrations of younger generations—particularly Gen Alpha and Gen Z—driven by recent BTO developments attracting young families. Millennials remain the largest generational group across most areas, reinforcing their role in shaping urban life. This evolving yet balanced generational landscape underscores the need for inclusive community planning that supports both young families and seniors—fostering intergenerational harmony and enabling families to live, age, and thrive together."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#references",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-home_Ex01.html#references",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Department of Statistics Singapore. (2024). Population Trends 2024.\nRetrieved from: https://www.singstat.gov.sg/publications/population/population-trends\nMinistry of Health Singapore. (2023). Action Plan for Successful Ageing.\nRetrieved from: https://www.moh.gov.sg/newsroom/launch-of-the-2023-action-plan-for-successful-ageing\nHousing & Development Board (HDB). (2021). Designing for Life: Community Planning and Design Guide.\nRetrieved from: https://www.hdb.gov.sg/cs/infoweb/designing-for-life\nSmart Nation and Digital Government Office. (2023). Smart Nation: Empowering Everyone Through Technology.\nRetrieved from: https://www.smartnation.gov.sg\nSingapore Department of Statistics. (n.d.). National Statistical Standards.\nRetrieved from: https://www.singstat.gov.sg/standards"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R,\nto be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.\n\n\n\n\n\n\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\n\nShow the code\n\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)\n\n\n\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\n\nIn this step, we will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\n\nShow the code\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\n\nShow the code\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\n\nShow the code\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges_aggregated data frame\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\n\n\n\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, we will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, it is recommended to review to reference guide of tbl_graph()\n\n\nShow the code\n\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\n\n\nShow the code\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nShow the code\n\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\n\nVisit the reference guide of activate() to find out more about the function.\n\n\n\n\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\n\nShow the code\n\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nIn this section, we will colour each node by referring to their respective departments.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\n\n\n\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, we will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for us to read it’s reference guide at least once.\n\n\nShow the code\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\n\nShow the code\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\n\nShow the code\n\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\n\nShow the code\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nShow the code\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nShow the code\n\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nShow the code\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\n\nPlease be reminded that you must to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\n\n\nShow the code\n\n\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nwe can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nwe can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\n\nShow the code\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\n\nShow the code\n\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument.\n\n\n\n\n\n\n\n\nVisual Analysis of Complex Networks for Business Intelligence with Gephi\nGraph Drawing\nGraph Analytics - Lesson Learned and Challenges Ahead\nLearning to Read and Interpret Network Graph Data Visualizations\nThe Visualization of Networks\nViZster: Visualizing Online Social Networks\nAdam Perer. “Finding Beautiful Insights in the Chaos of Social Network Visualizations”. In ’‘’Beautiful Visualization’’’. O’Reilly Press.\nVisual Complexity"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R,\nto be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\n\nShow the code\n\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\n\nIn this step, we will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\n\nShow the code\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\n\nShow the code\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\n\nShow the code\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges_aggregated data frame\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "In this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, we will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, it is recommended to review to reference guide of tbl_graph()\n\n\nShow the code\n\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\n\n\nShow the code\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nShow the code\n\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "ggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\n\nShow the code\n\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nIn this section, we will colour each node by referring to their respective departments.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nShow the code\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "Another very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, we will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for us to read it’s reference guide at least once.\n\n\nShow the code\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\n\nShow the code\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\n\nShow the code\n\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\n\nShow the code\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "Centrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nShow the code\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nShow the code\n\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nShow the code\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\n\nPlease be reminded that you must to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\n\n\nShow the code\n\n\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "visNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nwe can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nwe can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\n\nShow the code\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\n\nShow the code\n\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\n\nShow the code\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#readings",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#readings",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "Visual Analysis of Complex Networks for Business Intelligence with Gephi\nGraph Drawing\nGraph Analytics - Lesson Learned and Challenges Ahead\nLearning to Read and Interpret Network Graph Data Visualizations\nThe Visualization of Networks\nViZster: Visualizing Online Social Networks\nAdam Perer. “Finding Beautiful Insights in the Chaos of Social Network Visualizations”. In ’‘’Beautiful Visualization’’’. O’Reilly Press.\nVisual Complexity"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html",
    "href": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html",
    "title": "Hands-on Exercise 04C",
    "section": "",
    "text": "Visualizing uncertainty is relatively new in statistical graphics. In this exercise, we will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this exercise we will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.\n\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, we will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe code chunkThe Table\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\n\n\n\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nFor example, in the code chunk below the following arguments are used:\n.width = 0.95 .point = median .interval = qi\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\nPlot below shows 95% and 99% Confidence Interval\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width = 0.95,\n    .point = \"median\",\n    .interval = \"quantile\",\n    aes(colour = \"95% CI\")) +\n  stat_pointinterval(\n    .width = 0.99,\n    .point = \"median\",\n    .interval = \"quantile\",\n    aes(colour = \"99% CI\")) +\n  scale_colour_manual(\n    values = c(\"95% CI\" = \"green\", \"99% CI\" = \"red\"),\n    labels = c(\"95% CI\", \"99% CI\")) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\") +\n  theme_minimal()\n\n\n\n\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: We only need to perform this step once.\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\nNext, the code chunk below will be used to build the HOPs.\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#learning-outcome",
    "title": "Hands-on Exercise 04C",
    "section": "",
    "text": "Visualizing uncertainty is relatively new in statistical graphics. In this exercise, we will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this exercise we will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#getting-started",
    "title": "Hands-on Exercise 04C",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 04C",
    "section": "",
    "text": "A point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, we will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe code chunkThe Table\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#visualizing-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#visualizing-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 04C",
    "section": "",
    "text": "ggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nFor example, in the code chunk below the following arguments are used:\n.width = 0.95 .point = median .interval = qi\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\nPlot below shows 95% and 99% Confidence Interval\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width = 0.95,\n    .point = \"median\",\n    .interval = \"quantile\",\n    aes(colour = \"95% CI\")) +\n  stat_pointinterval(\n    .width = 0.99,\n    .point = \"median\",\n    .interval = \"quantile\",\n    aes(colour = \"99% CI\")) +\n  scale_colour_manual(\n    values = c(\"95% CI\" = \"green\", \"99% CI\" = \"red\"),\n    labels = c(\"95% CI\", \"99% CI\")) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\") +\n  theme_minimal()\n\n\n\n\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04C/Hands-on_Ex04C.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 04C",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\nNote: We only need to perform this step once.\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\nNext, the code chunk below will be used to build the HOPs.\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html",
    "href": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html",
    "title": "Hands-on Exercise 04A",
    "section": "",
    "text": "Visualizing distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualizing distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualizing distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions.\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualizing distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualizations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nRidgeline plot (sometimes called Joyplot) is a data visualization technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\n# Load libraries\nlibrary(ggplot2)\nlibrary(ggridges)\n\n# Plot\nggplot(exam, aes(x = ENGLISH, y = CLASS)) +\n  geom_density_ridges(\n    scale = 1.2,\n    rel_min_height = 0.01,\n    fill = \"gray\",\n    color = \"black\"\n  ) +\n  scale_x_continuous(\n    name = \"ENGLISH\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = \"CLASS\",\n    expand = expansion(add = c(0.2, 0.5))\n  ) +\n  theme_minimal(base_size = 14) +  # Clean base theme\n  theme(\n    panel.grid.major.x = element_line(color =\"whitesmoke\"),  # vertical lines\n    panel.grid.major.y = element_line(color = \"whitesmoke\"),  # horizontal lines\n    panel.grid.minor = element_blank(),                   # no minor gridlines\n    panel.background = element_rect(fill = \"white\", color = NA),  # white background\n    plot.background = element_rect(fill = \"white\", color = NA)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of groups to represent is medium to high. A classic window separation would take up too much space. The overlapping design of ridgelines makes better use of space. If you have fewer than 5 groups, other distribution plots may be more effective.\nRidgeline plots work well when there’s a clear pattern or ranking among groups. Otherwise, excessive overlap may lead to a messy plot with little insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nRaincloud Plot is a data visualization techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, you will learn how to create a raincloud plot to visualize the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\n\n\n\n\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#learning-outcome",
    "title": "Hands-on Exercise 04A",
    "section": "",
    "text": "Visualizing distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualizing distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualizing distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#getting-started",
    "title": "Hands-on Exercise 04A",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualizing distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualizations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#visualizing-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#visualizing-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 04A",
    "section": "",
    "text": "Ridgeline plot (sometimes called Joyplot) is a data visualization technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\n# Load libraries\nlibrary(ggplot2)\nlibrary(ggridges)\n\n# Plot\nggplot(exam, aes(x = ENGLISH, y = CLASS)) +\n  geom_density_ridges(\n    scale = 1.2,\n    rel_min_height = 0.01,\n    fill = \"gray\",\n    color = \"black\"\n  ) +\n  scale_x_continuous(\n    name = \"ENGLISH\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = \"CLASS\",\n    expand = expansion(add = c(0.2, 0.5))\n  ) +\n  theme_minimal(base_size = 14) +  # Clean base theme\n  theme(\n    panel.grid.major.x = element_line(color =\"whitesmoke\"),  # vertical lines\n    panel.grid.major.y = element_line(color = \"whitesmoke\"),  # horizontal lines\n    panel.grid.minor = element_blank(),                   # no minor gridlines\n    panel.background = element_rect(fill = \"white\", color = NA),  # white background\n    plot.background = element_rect(fill = \"white\", color = NA)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of groups to represent is medium to high. A classic window separation would take up too much space. The overlapping design of ridgelines makes better use of space. If you have fewer than 5 groups, other distribution plots may be more effective.\nRidgeline plots work well when there’s a clear pattern or ranking among groups. Otherwise, excessive overlap may lead to a messy plot with little insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#visualizing-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#visualizing-distribution-with-raincloud-plot",
    "title": "Hands-on Exercise 04A",
    "section": "",
    "text": "Raincloud Plot is a data visualization techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, you will learn how to create a raincloud plot to visualize the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04A/Hands-on_Ex04A.html#references",
    "title": "Hands-on Exercise 04A",
    "section": "",
    "text": "Introducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04B/Hands-on_Ex04B.html",
    "href": "Hands-on_Ex/Hands-on_Ex04B/Hands-on_Ex04B.html",
    "title": "Hands-on Exercise 04B",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\n\nDo-It-Yourself\n\n\n\nImporting Exam.csv data by using appropriate tidyverse package.\n\n\n# A tibble: 322 × 7 ID CLASS GENDER RACE ENGLISH MATHS SCIENCE &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Student321 3I Male Malay 21 9 15 2 Student305 3I Female Malay 24 22 16 3 Student289 3H Male Chinese 26 16 16 4 Student227 3F Male Chinese 27 77 31 5 Student318 3I Male Malay 27 11 25 6 Student306 3I Female Malay 31 16 16 7 Student313 3I Male Chinese 31 21 25 8 Student316 3I Male Malay 31 18 27 9 Student312 3I Male Malay 33 19 15 10 Student297 3H Male Indian 34 49 37 # ℹ 312 more rows\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04B/Hands-on_Ex04B.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04B/Hands-on_Ex04B.html#learning-outcome",
    "title": "Hands-on Exercise 04B",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04B/Hands-on_Ex04B.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04B/Hands-on_Ex04B.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 04B",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04B/Hands-on_Ex04B.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04B/Hands-on_Ex04B.html#getting-started",
    "title": "Hands-on Exercise 04B",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\n\nDo-It-Yourself\n\n\n\nImporting Exam.csv data by using appropriate tidyverse package.\n\n\n# A tibble: 322 × 7 ID CLASS GENDER RACE ENGLISH MATHS SCIENCE &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Student321 3I Male Malay 21 9 15 2 Student305 3I Female Malay 24 22 16 3 Student289 3H Male Chinese 26 16 16 4 Student227 3F Male Chinese 27 77 31 5 Student318 3I Male Malay 27 11 25 6 Student306 3I Female Malay 31 16 16 7 Student313 3I Male Chinese 31 21 25 8 Student316 3I Male Malay 31 18 27 9 Student312 3I Male Malay 33 19 15 10 Student297 3H Male Indian 34 49 37 # ℹ 312 more rows\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html",
    "href": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html",
    "title": "Hands-on Exercise 04D",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\n\n\n\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-district ID\nCity\nDistrict\nSub-district\nPositive\nRecovered\nDeath\n\n\n\n\n3172051003\nJAKARTA UTARA\nPADEMANGAN\nANCOL\n1776\n1691\n26\n\n\n3173041007\nJAKARTA BARAT\nTAMBORA\nANGKE\n1783\n1720\n29\n\n\n3175041005\nJAKARTA TIMUR\nKRAMAT JATI\nBALE KAMBANG\n2049\n1964\n31\n\n\n3175031003\nJAKARTA TIMUR\nJATINEGARA\nBALI MESTER\n827\n797\n13\n\n\n3175101006\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n2866\n2792\n27\n\n\n3174031002\nJAKARTA SELATAN\nMAMPANG PRAPATAN\nBANGKA\n1828\n1757\n26\n\n\n\n\n\n\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\n\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualization like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly\n\n\n\n\n\n\n\n\n\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#overview",
    "title": "Hands-on Exercise 04D",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 04D",
    "section": "",
    "text": "In this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#importing-data",
    "title": "Hands-on Exercise 04D",
    "section": "",
    "text": "In this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-district ID\nCity\nDistrict\nSub-district\nPositive\nRecovered\nDeath\n\n\n\n\n3172051003\nJAKARTA UTARA\nPADEMANGAN\nANCOL\n1776\n1691\n26\n\n\n3173041007\nJAKARTA BARAT\nTAMBORA\nANGKE\n1783\n1720\n29\n\n\n3175041005\nJAKARTA TIMUR\nKRAMAT JATI\nBALE KAMBANG\n2049\n1964\n31\n\n\n3175031003\nJAKARTA TIMUR\nJATINEGARA\nBALI MESTER\n827\n797\n13\n\n\n3175101006\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n2866\n2792\n27\n\n\n3174031002\nJAKARTA SELATAN\nMAMPANG PRAPATAN\nBANGKA\n1828\n1757\n26"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#funnelplotr-methods",
    "title": "Hands-on Exercise 04D",
    "section": "",
    "text": "FunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 04D",
    "section": "",
    "text": "In this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualization like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04D/Hands-on_Ex04D.html#references",
    "title": "Hands-on Exercise 04D",
    "section": "",
    "text": "funnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex_05/MC1.html",
    "href": "In-Class_Ex/In-Class_Ex_05/MC1.html",
    "title": "In-Class Exercise 05",
    "section": "",
    "text": "MC 01\npacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph, ggraph)\nkg &lt;- fromJSON(\"data/MC1_graph.json\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex_05/MC1.html#initial-eda",
    "href": "In-Class_Ex/In-Class_Ex_05/MC1.html#initial-eda",
    "title": "In-Class Exercise 05",
    "section": "Initial EDA",
    "text": "Initial EDA\n\nggplot(data = edges_tbl, aes(y = `Edge Type`)) + \n  geom_bar()"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex_05/MC1.html#creating-knowledge-graph",
    "href": "In-Class_Ex/In-Class_Ex_05/MC1.html#creating-knowledge-graph",
    "title": "In-Class Exercise 05",
    "section": "Creating knowledge graph",
    "text": "Creating knowledge graph\n\nStep 1: Mapping from node id to row index\n\nid_map &lt;- tibble(id = nodes_tbl$id, index = seq_len(nrow(nodes_tbl)))\n\n\n\nStep 2: Map source and target IDs to row indices\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"), suffix = c(\"\", \"_source\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"), suffix = c(\"\", \"_target\")) %&gt;%\n  rename(to = index)\n\n\n\nStep 3\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n\n\nStep 4: Creating the graph\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl, edges = edges_tbl, \n                   directed = kg$directed)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex_05/MC1.html#visualizing-the-knowledge-graph",
    "href": "In-Class_Ex/In-Class_Ex_05/MC1.html#visualizing-the-knowledge-graph",
    "title": "In-Class Exercise 05",
    "section": "Visualizing the knowledge graph",
    "text": "Visualizing the knowledge graph\n\nset.seed(1234)\n\n\nVisualizing the whole Graph\n\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(alpha = 0.3, colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`), size = 4) +\n  geom_node_text(aes(label = name), repel = TRUE, size = 2.5) +\n  theme_void()\n\n\nStep 1: Filter edges to only “MemberOf”\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%\n  filter(`Edge Type` == \"MemberOf\")\n\n\n\nStep 2: Extract only connected nodes (ie. used in these edges)\n\nused_node_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from, to) %&gt;%\n  unlist() %&gt;%\n  unique()\n\n\n\nStep 3: Keep only those nodes\n\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_node_indices) %&gt;%\n  select(-row_id)  #optional cleanup\n\n\n\nPlot the sub-graph\n\nggraph(graph_memberof, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5, colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`), size = 1) +\n  geom_node_text(aes(label = name), repel = TRUE, size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Creating enlightening and truthful data visualizations involves focusing on accuracy, transparency, and the ability to effectively communicate insights. It’s about presenting data in a way that is both informative and aesthetically pleasing, ensuring the audience can grasp the information quickly and accurately.\n\n\n\nA local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024.\n\n\n\nAssuming the role of the graphical editor of the media company, we are tasked to prepare at most three data visualization for the article.\n\n\n\n\n\nWe load the following R packages using the pacman::p_load() function:\n\ntidyverse: R packages designed for data science\nggrepel: to provides geoms for ggplot2 to repel overlapping text labels\nggthemes: to use additional themes for ggplot2\npatchwork: to prepare composite figure created using ggplot2\nscales: to provide the internal scaling infrastructure used by ggplot2\nggpubr to create publication ready ggplot2 plots.\n\nThe code chunk below uses the p_load() function in the pacman package to check if the packages are installed in the computer.\n\npacman::p_load(tidyverse, ggrepel, patchwork, ggthemes, scales,\n               ggpubr) \n\n\n\n\nTo accomplish the task, Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore (DOS) will be used and we wil load it as follows:\n\ndata &lt;- read_csv(\"data/respopagesex2024.csv\", col_names = TRUE)\n\n\n\n\n\n\nWe first take a look at the data. Using the code below, we can get the details of the dataset which contains 60,424 rows and 6 columns.\n\nglimpse(data)\n\nRows: 60,424\nColumns: 6\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ Age  &lt;chr&gt; \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"5\", \"6\", …\n$ Sex  &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Females\", \"Male…\n$ Pop  &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, 30, 10, 3…\n$ Time &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024,…\n\n\n\n\n\n\nWe notice that there is only one value in Time column (2024) which will not be used for further analysis, we will delete this column as per the code chunk below:\n\n\ndata &lt;- data %&gt;% select(-Time)\n\n\nWe will rename the column names in the dataset for clarity, as detailed provided by the Department of Statistics (DOS), as follows:\n\nPA → Planning Area\nSZ → Subzone\nPop → Resident Count\n\n\n\n\n\n\nSide Note:\n\n\n\nPlease note: according to the DOS accompanying documentation of this dataset, the population figures in the csv file have been rounded to the nearest 10, and as such, total counts may not sum exactly due to rounding adjustments.\n\n\n\ncolnames(data) &lt;- c(\"PlanningArea\", \"SubZone\", \"Age\", \"Sex\", \"ResidentCount\")\n\n\nNext, we observe that for the Age column, there is a value of : “90_and_over”. We will replace this value with “90” and change the data type from string/character to numeric and then create a new column to classify the age according to the age bracket in the interval of 5 years as per the standard age group published in DOS:\n\n\ndata &lt;- data %&gt;%\n  mutate(\n    # Normalize Age values to lowercase\n    Age = str_to_lower(Age),\n    \n    # Replace \"90_and_over\" with \"90\"\n    Age = ifelse(Age == \"90_and_over\", \"90\", Age),\n    \n    # Convert to numeric\n    Age = as.numeric(Age),\n    \n    # Create AgeGroup with standard bins\n    AgeGroup = cut(Age,\n                   breaks = c(0,4,9,14,19,24,29,34,39,44,49,54,59,64,69,74,79,84,89, Inf),\n                   labels = c(\"0–4\", \"5–9\", \"10–14\", \"15–19\", \"20–24\", \"25–29\",\n                              \"30–34\", \"35–39\", \"40–44\", \"45–49\", \"50–54\", \n                              \"55–59\", \"60–64\", \"65–69\", \"70–74\", \"75–79\", \n                              \"80–84\", \"85–89\", \"90+\"),\n                   right = TRUE, include.lowest = TRUE)\n  )\n\n\nFurther observation of the dataset, we discover there are multiple rows with “0” values in the “Pop”/“ResidentCount” column. We will remove these rows as per the code chunk below, and calculate the number of rows and total population before and after the deletion to ensure completeness:\n\n\n# Total population before removing zero-pop rows\ntotal_population_before &lt;- sum(data$ResidentCount, na.rm = TRUE)\ntotal_rows_before &lt;- nrow(data)\n\n# Count and show how many rows have 0 population\nzero_count &lt;- data %&gt;%\n  filter(ResidentCount == 0) %&gt;%\n  nrow()\n\ncat(\"Total population before cleaning:\", format(total_population_before, big.mark = \",\"), \"\\n\")\n\nTotal population before cleaning: 4,193,530 \n\ncat(\"Total rows before cleaning:\", total_rows_before, \"\\n\")\n\nTotal rows before cleaning: 60424 \n\ncat(\"Rows with 0 ResidentCount removed:\", zero_count, \"\\n\")\n\nRows with 0 ResidentCount removed: 23181 \n\n# Remove rows with 0 population\ndata &lt;- data %&gt;%\n  filter(ResidentCount &gt; 0)\n\n# Recalculate totals after cleaning\ntotal_population_after &lt;- sum(data$ResidentCount, na.rm = TRUE)\ntotal_rows_after &lt;- nrow(data)\n\ncat(\"Total population after cleaning:\", format(total_population_after, big.mark = \",\"), \"\\n\")\n\nTotal population after cleaning: 4,193,530 \n\ncat(\"Remaining rows:\", total_rows_after, \"\\n\")\n\nRemaining rows: 37243 \n\n\n\n\n\nNext, Using the duplicated function, we see that there are no duplicate entries in the data.\n\ndata[duplicated(data),]\n\n# A tibble: 0 × 6\n# ℹ 6 variables: PlanningArea &lt;chr&gt;, SubZone &lt;chr&gt;, Age &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   ResidentCount &lt;dbl&gt;, AgeGroup &lt;fct&gt;\n\n\n\n\n\nWe run the code below to check for any missing values, and there is none.\n\ncolSums(is.na(data))\n\n PlanningArea       SubZone           Age           Sex ResidentCount \n            0             0             0             0             0 \n     AgeGroup \n            0 \n\n\n\n\n\nWe run an overview of the final dataset again before proceeding to the visualization. Final dataset contains 37,243 rows and 7 columns:\n\nglimpse(data)\n\nRows: 37,243\nColumns: 6\n$ PlanningArea  &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", …\n$ SubZone       &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang…\n$ Age           &lt;dbl&gt; 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9,…\n$ Sex           &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Female…\n$ ResidentCount &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, …\n$ AgeGroup      &lt;fct&gt; 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 5–9, 5…\n\n\n\n\n\n\n\n\n\nInsights:\n\nThe population pyramid reveals a dominant working-age group between ages 30–44, forming the broadest segment of the chart, with largest age group for Female: from 35-39 age group: 166,150 and Males: from 30-34 age group with 155,630\nThe base is narrower, especially for those aged 0–14, which highlights the ongoing trend of declining birth rates.\nFemales significantly outnumber males from age 65 onwards, highlighting gender differences in life expectancy\nThe median age of 42 reinforces Singapore’s aging trend, with implications for healthcare and eldercare planning.\nThe median age of 42 underscores Singapore’s aging population, signaling increasing needs in healthcare, retirement, and eldercare.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npyramid_data &lt;- data %&gt;%\n  group_by(AgeGroup, Sex) %&gt;%\n  summarise(ResidentCount = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    ResidentCountSigned = ifelse(Sex == \"Males\", -ResidentCount, ResidentCount),\n    fill_color = case_when(\n      Sex == \"Males\" ~ \"#4292c6\",\n      Sex == \"Females\" ~ \"#e377c2\",\n      TRUE ~ \"gray\"\n    ),\n    AgeGroup = factor(AgeGroup, levels = c(\"0–4\", \"5–9\", \"10–14\", \"15–19\", \"20–24\",\n                                           \"25–29\", \"30–34\", \"35–39\", \"40–44\", \"45–49\",\n                                           \"50–54\", \"55–59\", \"60–64\", \"65–69\", \"70–74\",\n                                           \"75–79\", \"80–84\", \"85–89\", \"90+\"))\n  )\n\nmedian_age &lt;- data %&gt;%\n  group_by(Age) %&gt;%\n  summarise(Total = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  arrange(Age) %&gt;%\n  mutate(cum_pop = cumsum(Total), prop = cum_pop / sum(Total)) %&gt;%\n  filter(prop &gt;= 0.5) %&gt;%\n  slice(1) %&gt;%\n  pull(Age)\n\nage_group_labels &lt;- levels(pyramid_data$AgeGroup)\nmedian_group_index &lt;- findInterval(median_age, seq(0, 100, by = 5))\nmedian_group &lt;- age_group_labels[median_group_index]\n\ntotal_males &lt;- pyramid_data %&gt;% filter(Sex == \"Males\") %&gt;% summarise(sum = sum(abs(ResidentCountSigned))) %&gt;% pull(sum)\ntotal_females &lt;- pyramid_data %&gt;% filter(Sex == \"Females\") %&gt;% summarise(sum = sum(ResidentCountSigned)) %&gt;% pull(sum)\n\nggplot(pyramid_data, aes(y = AgeGroup, x = ResidentCountSigned, fill = fill_color)) +\n  geom_col(width = 0.9) +\n  geom_text(aes(label = abs(ResidentCountSigned),\n                x = ifelse(ResidentCountSigned &lt; 0, ResidentCountSigned - 5000, ResidentCountSigned + 5000)),\n            hjust = ifelse(pyramid_data$ResidentCountSigned &lt; 0, 1, 0),\n            size = 3, color = \"black\") +\n  annotate(\"segment\",\n           x = -max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           xend = max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           y = median_group, yend = median_group,\n           linetype = \"dotted\", color = \"#A9A9A9\", linewidth = 0.9) +\n  annotate(\"text\",\n           x = max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           y = median_group,\n           label = paste0(\"Median: \", median_age),\n           hjust = 0, size = 2.8, color = \"black\", fontface = \"bold\") +\n  annotate(\"text\", y = \"0–4\",\n           x = -max(abs(pyramid_data$ResidentCountSigned)) * 0.95,\n           label = paste0(\"Males\\nTotal: \", format(total_males, big.mark = \",\")),\n           size = 2.6, color = \"#1E90FF\", fontface = \"bold\", hjust = 1) +\n  annotate(\"text\", y = \"0–4\",\n           x = max(abs(pyramid_data$ResidentCountSigned)) * 0.95,\n           label = paste0(\"Females\\nTotal: \", format(total_females, big.mark = \",\")),\n           size = 2.6, color = \"#c51b8a\", fontface = \"bold\", hjust = 0) +\n  scale_fill_identity() +\n  scale_x_continuous(labels = abs, expand = expansion(mult = c(0.12, 0.12))) +\n  labs(\n    title = \"Singapore’s Shifting Age Structure (June 2024)\",\n    subtitle = \"Middle-age Population Dominates; Youth Base Shrinking, Elderly Segment Rising\",\n    x = NULL,\n    y = \"Age Group (Years)\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\", margin = margin(b = 6)),\n    plot.subtitle = element_text(hjust = 0.5, size = 12, margin = margin(b = 12)),\n    axis.text.y = element_text(size = 10),\n    axis.title.y = element_text(size = 11, face = \"bold\"),\n    axis.text.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\nInsights:\n\nThe top chart shows the proportion of elderly residents in the top 10 planning areas. Outram has the highest share, with 26.9% of its population are seniors, followed by Ang Mo Kio (24.3%) and Bukit Merah (23.4%). These established towns may benefit from enhanced elderly-supportive environments, such as barrier-free access, senior-oriented amenities, and close-proximity services.\nThe bottom chart presents the elderly resident count, with Bedok having the largest at 60,770, followed by Tampines (49,700) and Hougang (44,640). This is largely due to their larger area size and population base. These towns would benefit from service scaling, such as Active Ageing Centres (AACs), public transport connectivity, and healthcare access.\nWith Singapore’s elderly population projected to reach one in four residents (DOS, 2024), it is important to consider both distribution by proportion and resident count for effective planning.\nThis dual perspective supports the Ministry of Health’s 2023 Action Plan, which aims to double eldercare centres by 2025 and enhance community-based support (MOH, 2023).\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly_data &lt;- data %&gt;% filter(Age &gt;= 65)\n\ntotal_pop &lt;- data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Total_Pop = sum(ResidentCount, na.rm = TRUE))\n\nelderly_count &lt;- elderly_data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Elderly_Pop = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  arrange(desc(Elderly_Pop)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(PlanningArea = fct_reorder(PlanningArea, Elderly_Pop))\n\nelderly_prop &lt;- elderly_data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Elderly_Pop = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  left_join(total_pop, by = \"PlanningArea\") %&gt;%\n  mutate(Elderly_Proportion = Elderly_Pop / Total_Pop) %&gt;%\n  arrange(desc(Elderly_Proportion)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(PlanningArea = fct_reorder(PlanningArea, Elderly_Proportion))\n\n# Plot\np1 &lt;- ggplot(elderly_prop, aes(x = Elderly_Proportion, y = PlanningArea)) +\n  geom_col(fill = \"#4DAF4A\", width = 0.85) +\n  scale_x_continuous(\n    breaks = seq(0, 0.35, by = 0.05),\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Top 10 Planning Areas by Elderly Proportion (Age 65+)\",\n    x = \"Proportion of Elderly Residents\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 11),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n    panel.grid.minor = element_blank()\n  )\n\n\np2 &lt;- ggplot(elderly_count, aes(x = Elderly_Pop, y = PlanningArea)) +\n  geom_col(fill = \"#4DAF4A\", width = 0.85) +\n  scale_x_continuous(\n    breaks = seq(0, 70000, by = 10000),\n    labels = comma_format(),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Top 10 Planning Areas by Elderly Resident Count (Age 65+)\",\n    x = \"Number of Elderly Residents\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 11),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n    panel.grid.minor = element_blank()\n  )\n\np1 / p2\n\n\n\n\n\n\n\nInsights:\n\nTampines, Bedok, and Sengkang are top the list with over 250,000 residents each.\nMillennials (age 28–43) are the largest group in most PA, while Gen X dominates in Bedok, a mature estate.\nYounger generations (Gen Alpha and Gen Z) are more concentrated in newer towns like Sengkang, Punggol, and Jurong West, aligned with recent BTO developments that attract young families.\nThe distribution reflects a balanced generational mix, highlighting Singapore’s multigenerational living pattern—with both aging residents and young households sharing town spaces.\nThese trends align with Singapore’s Smart Nation and HDB’s ‘Designing for Life’ vision: fostering harmonious, inclusive communities where families of all ages can live, age, and thrive together through well-integrated facilities, technology, and people-first urban design.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata &lt;- data %&gt;%\n  mutate(Age = as.numeric(Age),\n         Generation = case_when(\n           Age &lt;= 9 ~ \"Gen Alpha (≤9)\",\n           Age &lt;= 27 ~ \"Gen Z (10–27)\",\n           Age &lt;= 43 ~ \"Millennials (28–43)\",\n           Age &lt;= 59 ~ \"Gen X (44–59)\",\n           Age &lt;= 77 ~ \"Baby Boomers (60–77)\",\n           TRUE ~ \"Silent Gen (78+)\"\n         ))\n\ngen_by_area &lt;- data %&gt;%\n  group_by(PlanningArea, Generation) %&gt;%\n  summarise(ResidentCount = sum(ResidentCount, na.rm = TRUE), .groups = \"drop\")\n\ntop10_areas &lt;- gen_by_area %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(TotalPop = sum(ResidentCount)) %&gt;%\n  arrange(desc(TotalPop)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(PlanningArea)\n\ngen_top10 &lt;- gen_by_area %&gt;%\n  filter(PlanningArea %in% top10_areas) %&gt;%\n  mutate(\n    PlanningArea = fct_reorder(PlanningArea, ResidentCount, .fun = sum, .desc = TRUE),\n    Generation = factor(Generation, levels = c(\"Silent Gen (78+)\", \"Baby Boomers (60–77)\",\n                                               \"Gen X (44–59)\", \"Millennials (28–43)\",\n                                               \"Gen Z (10–27)\", \"Gen Alpha (≤9)\"))\n  )\n\ngen_colors &lt;- c(\n  \"Silent Gen (78+)\" = \"#c6dbef\",\n  \"Baby Boomers (60–77)\" = \"#6baed6\",\n  \"Gen X (44–59)\" = \"#b2df8a\",\n  \"Millennials (28–43)\" = \"#33a02c\",\n  \"Gen Z (10–27)\" = \"#fb9a99\",\n  \"Gen Alpha (≤9)\" = \"#e31a1c\"\n)\n\n#Plot\nggplot(gen_top10, aes(x = PlanningArea, y = ResidentCount, fill = Generation)) +\n  geom_col(width = 0.8, color = \"white\") +\n  scale_fill_manual(values = gen_colors) +\n  scale_y_continuous(\n    labels = comma,\n    breaks = seq(0, 300000, 50000),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Generational Composition of Top 10 Most Populated Planning Areas\",\n    subtitle = \"Younger generations dominate newer towns, while older cohorts concentrate in mature estates\",\n    x = \"Planning Area\",\n    y = \"Resident Count\",\n    fill = \"Generation\"\n  ) +\n  theme_clean(base_size = 12) +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 11, hjust = 0.5),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major.x = element_blank(),\n    legend.position = \"right\"\n  )\n\n\n\n\n\n\n\n\nSingapore’s demographic structure, based on June 2024 data, highlights a maturing society with a dominant working-age group and a median age of 42. The growing share of seniors and the narrowing base of younger age groups reflect the effects of population aging and low birth rates. Mature estates such as Outram have the highest proportion of elderly residents, while Bedok and Tampines house the largest absolute numbers. In contrast, newer towns like Sengkang and Punggol show higher concentrations of younger generations—particularly Gen Alpha and Gen Z—driven by recent BTO developments attracting young families. Millennials remain the largest generational group across most areas, reinforcing their role in shaping urban life. This evolving yet balanced generational landscape underscores the need for inclusive community planning that supports both young families and seniors—fostering intergenerational harmony and enabling families to live, age, and thrive together.\n\n\n\n\nDepartment of Statistics Singapore. (2024). Population Trends 2024.\nRetrieved from: https://www.singstat.gov.sg/publications/population/population-trends\nMinistry of Health Singapore. (2023). Action Plan for Successful Ageing.\nRetrieved from: https://www.moh.gov.sg/newsroom/launch-of-the-2023-action-plan-for-successful-ageing\nHousing & Development Board (HDB). (2021). Designing for Life: Community Planning and Design Guide.\nRetrieved from: https://www.hdb.gov.sg/cs/infoweb/designing-for-life\nSmart Nation and Digital Government Office. (2023). Smart Nation: Empowering Everyone Through Technology.\nRetrieved from: https://www.smartnation.gov.sg\nSingapore Department of Statistics. (n.d.). National Statistical Standards.\nRetrieved from: https://www.singstat.gov.sg/standards"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#overview",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#overview",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Creating enlightening and truthful data visualizations involves focusing on accuracy, transparency, and the ability to effectively communicate insights. It’s about presenting data in a way that is both informative and aesthetically pleasing, ensuring the audience can grasp the information quickly and accurately."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#setting-the-scene",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "A local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#the-task",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Assuming the role of the graphical editor of the media company, we are tasked to prepare at most three data visualization for the article."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#getting-started",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "We load the following R packages using the pacman::p_load() function:\n\ntidyverse: R packages designed for data science\nggrepel: to provides geoms for ggplot2 to repel overlapping text labels\nggthemes: to use additional themes for ggplot2\npatchwork: to prepare composite figure created using ggplot2\nscales: to provide the internal scaling infrastructure used by ggplot2\nggpubr to create publication ready ggplot2 plots.\n\nThe code chunk below uses the p_load() function in the pacman package to check if the packages are installed in the computer.\n\npacman::p_load(tidyverse, ggrepel, patchwork, ggthemes, scales,\n               ggpubr) \n\n\n\n\nTo accomplish the task, Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore (DOS) will be used and we wil load it as follows:\n\ndata &lt;- read_csv(\"data/respopagesex2024.csv\", col_names = TRUE)\n\n\n\n\n\n\nWe first take a look at the data. Using the code below, we can get the details of the dataset which contains 60,424 rows and 6 columns.\n\nglimpse(data)\n\nRows: 60,424\nColumns: 6\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ Age  &lt;chr&gt; \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"5\", \"6\", …\n$ Sex  &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Females\", \"Male…\n$ Pop  &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, 30, 10, 3…\n$ Time &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024,…\n\n\n\n\n\n\nWe notice that there is only one value in Time column (2024) which will not be used for further analysis, we will delete this column as per the code chunk below:\n\n\ndata &lt;- data %&gt;% select(-Time)\n\n\nWe will rename the column names in the dataset for clarity, as detailed provided by the Department of Statistics (DOS), as follows:\n\nPA → Planning Area\nSZ → Subzone\nPop → Resident Count\n\n\n\n\n\n\nSide Note:\n\n\n\nPlease note: according to the DOS accompanying documentation of this dataset, the population figures in the csv file have been rounded to the nearest 10, and as such, total counts may not sum exactly due to rounding adjustments.\n\n\n\ncolnames(data) &lt;- c(\"PlanningArea\", \"SubZone\", \"Age\", \"Sex\", \"ResidentCount\")\n\n\nNext, we observe that for the Age column, there is a value of : “90_and_over”. We will replace this value with “90” and change the data type from string/character to numeric and then create a new column to classify the age according to the age bracket in the interval of 5 years as per the standard age group published in DOS:\n\n\ndata &lt;- data %&gt;%\n  mutate(\n    # Normalize Age values to lowercase\n    Age = str_to_lower(Age),\n    \n    # Replace \"90_and_over\" with \"90\"\n    Age = ifelse(Age == \"90_and_over\", \"90\", Age),\n    \n    # Convert to numeric\n    Age = as.numeric(Age),\n    \n    # Create AgeGroup with standard bins\n    AgeGroup = cut(Age,\n                   breaks = c(0,4,9,14,19,24,29,34,39,44,49,54,59,64,69,74,79,84,89, Inf),\n                   labels = c(\"0–4\", \"5–9\", \"10–14\", \"15–19\", \"20–24\", \"25–29\",\n                              \"30–34\", \"35–39\", \"40–44\", \"45–49\", \"50–54\", \n                              \"55–59\", \"60–64\", \"65–69\", \"70–74\", \"75–79\", \n                              \"80–84\", \"85–89\", \"90+\"),\n                   right = TRUE, include.lowest = TRUE)\n  )\n\n\nFurther observation of the dataset, we discover there are multiple rows with “0” values in the “Pop”/“ResidentCount” column. We will remove these rows as per the code chunk below, and calculate the number of rows and total population before and after the deletion to ensure completeness:\n\n\n# Total population before removing zero-pop rows\ntotal_population_before &lt;- sum(data$ResidentCount, na.rm = TRUE)\ntotal_rows_before &lt;- nrow(data)\n\n# Count and show how many rows have 0 population\nzero_count &lt;- data %&gt;%\n  filter(ResidentCount == 0) %&gt;%\n  nrow()\n\ncat(\"Total population before cleaning:\", format(total_population_before, big.mark = \",\"), \"\\n\")\n\nTotal population before cleaning: 4,193,530 \n\ncat(\"Total rows before cleaning:\", total_rows_before, \"\\n\")\n\nTotal rows before cleaning: 60424 \n\ncat(\"Rows with 0 ResidentCount removed:\", zero_count, \"\\n\")\n\nRows with 0 ResidentCount removed: 23181 \n\n# Remove rows with 0 population\ndata &lt;- data %&gt;%\n  filter(ResidentCount &gt; 0)\n\n# Recalculate totals after cleaning\ntotal_population_after &lt;- sum(data$ResidentCount, na.rm = TRUE)\ntotal_rows_after &lt;- nrow(data)\n\ncat(\"Total population after cleaning:\", format(total_population_after, big.mark = \",\"), \"\\n\")\n\nTotal population after cleaning: 4,193,530 \n\ncat(\"Remaining rows:\", total_rows_after, \"\\n\")\n\nRemaining rows: 37243 \n\n\n\n\n\nNext, Using the duplicated function, we see that there are no duplicate entries in the data.\n\ndata[duplicated(data),]\n\n# A tibble: 0 × 6\n# ℹ 6 variables: PlanningArea &lt;chr&gt;, SubZone &lt;chr&gt;, Age &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   ResidentCount &lt;dbl&gt;, AgeGroup &lt;fct&gt;\n\n\n\n\n\nWe run the code below to check for any missing values, and there is none.\n\ncolSums(is.na(data))\n\n PlanningArea       SubZone           Age           Sex ResidentCount \n            0             0             0             0             0 \n     AgeGroup \n            0 \n\n\n\n\n\nWe run an overview of the final dataset again before proceeding to the visualization. Final dataset contains 37,243 rows and 7 columns:\n\nglimpse(data)\n\nRows: 37,243\nColumns: 6\n$ PlanningArea  &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", …\n$ SubZone       &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang…\n$ Age           &lt;dbl&gt; 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9,…\n$ Sex           &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Female…\n$ ResidentCount &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, …\n$ AgeGroup      &lt;fct&gt; 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 0–4, 5–9, 5…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#data-visualization",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#data-visualization",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Insights:\n\nThe population pyramid reveals a dominant working-age group between ages 30–44, forming the broadest segment of the chart, with largest age group for Female: from 35-39 age group: 166,150 and Males: from 30-34 age group with 155,630\nThe base is narrower, especially for those aged 0–14, which highlights the ongoing trend of declining birth rates.\nFemales significantly outnumber males from age 65 onwards, highlighting gender differences in life expectancy\nThe median age of 42 reinforces Singapore’s aging trend, with implications for healthcare and eldercare planning.\nThe median age of 42 underscores Singapore’s aging population, signaling increasing needs in healthcare, retirement, and eldercare.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npyramid_data &lt;- data %&gt;%\n  group_by(AgeGroup, Sex) %&gt;%\n  summarise(ResidentCount = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    ResidentCountSigned = ifelse(Sex == \"Males\", -ResidentCount, ResidentCount),\n    fill_color = case_when(\n      Sex == \"Males\" ~ \"#4292c6\",\n      Sex == \"Females\" ~ \"#e377c2\",\n      TRUE ~ \"gray\"\n    ),\n    AgeGroup = factor(AgeGroup, levels = c(\"0–4\", \"5–9\", \"10–14\", \"15–19\", \"20–24\",\n                                           \"25–29\", \"30–34\", \"35–39\", \"40–44\", \"45–49\",\n                                           \"50–54\", \"55–59\", \"60–64\", \"65–69\", \"70–74\",\n                                           \"75–79\", \"80–84\", \"85–89\", \"90+\"))\n  )\n\nmedian_age &lt;- data %&gt;%\n  group_by(Age) %&gt;%\n  summarise(Total = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  arrange(Age) %&gt;%\n  mutate(cum_pop = cumsum(Total), prop = cum_pop / sum(Total)) %&gt;%\n  filter(prop &gt;= 0.5) %&gt;%\n  slice(1) %&gt;%\n  pull(Age)\n\nage_group_labels &lt;- levels(pyramid_data$AgeGroup)\nmedian_group_index &lt;- findInterval(median_age, seq(0, 100, by = 5))\nmedian_group &lt;- age_group_labels[median_group_index]\n\ntotal_males &lt;- pyramid_data %&gt;% filter(Sex == \"Males\") %&gt;% summarise(sum = sum(abs(ResidentCountSigned))) %&gt;% pull(sum)\ntotal_females &lt;- pyramid_data %&gt;% filter(Sex == \"Females\") %&gt;% summarise(sum = sum(ResidentCountSigned)) %&gt;% pull(sum)\n\nggplot(pyramid_data, aes(y = AgeGroup, x = ResidentCountSigned, fill = fill_color)) +\n  geom_col(width = 0.9) +\n  geom_text(aes(label = abs(ResidentCountSigned),\n                x = ifelse(ResidentCountSigned &lt; 0, ResidentCountSigned - 5000, ResidentCountSigned + 5000)),\n            hjust = ifelse(pyramid_data$ResidentCountSigned &lt; 0, 1, 0),\n            size = 3, color = \"black\") +\n  annotate(\"segment\",\n           x = -max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           xend = max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           y = median_group, yend = median_group,\n           linetype = \"dotted\", color = \"#A9A9A9\", linewidth = 0.9) +\n  annotate(\"text\",\n           x = max(abs(pyramid_data$ResidentCountSigned)) * 1.5,\n           y = median_group,\n           label = paste0(\"Median: \", median_age),\n           hjust = 0, size = 2.8, color = \"black\", fontface = \"bold\") +\n  annotate(\"text\", y = \"0–4\",\n           x = -max(abs(pyramid_data$ResidentCountSigned)) * 0.95,\n           label = paste0(\"Males\\nTotal: \", format(total_males, big.mark = \",\")),\n           size = 2.6, color = \"#1E90FF\", fontface = \"bold\", hjust = 1) +\n  annotate(\"text\", y = \"0–4\",\n           x = max(abs(pyramid_data$ResidentCountSigned)) * 0.95,\n           label = paste0(\"Females\\nTotal: \", format(total_females, big.mark = \",\")),\n           size = 2.6, color = \"#c51b8a\", fontface = \"bold\", hjust = 0) +\n  scale_fill_identity() +\n  scale_x_continuous(labels = abs, expand = expansion(mult = c(0.12, 0.12))) +\n  labs(\n    title = \"Singapore’s Shifting Age Structure (June 2024)\",\n    subtitle = \"Middle-age Population Dominates; Youth Base Shrinking, Elderly Segment Rising\",\n    x = NULL,\n    y = \"Age Group (Years)\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\", margin = margin(b = 6)),\n    plot.subtitle = element_text(hjust = 0.5, size = 12, margin = margin(b = 12)),\n    axis.text.y = element_text(size = 10),\n    axis.title.y = element_text(size = 11, face = \"bold\"),\n    axis.text.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\nInsights:\n\nThe top chart shows the proportion of elderly residents in the top 10 planning areas. Outram has the highest share, with 26.9% of its population are seniors, followed by Ang Mo Kio (24.3%) and Bukit Merah (23.4%). These established towns may benefit from enhanced elderly-supportive environments, such as barrier-free access, senior-oriented amenities, and close-proximity services.\nThe bottom chart presents the elderly resident count, with Bedok having the largest at 60,770, followed by Tampines (49,700) and Hougang (44,640). This is largely due to their larger area size and population base. These towns would benefit from service scaling, such as Active Ageing Centres (AACs), public transport connectivity, and healthcare access.\nWith Singapore’s elderly population projected to reach one in four residents (DOS, 2024), it is important to consider both distribution by proportion and resident count for effective planning.\nThis dual perspective supports the Ministry of Health’s 2023 Action Plan, which aims to double eldercare centres by 2025 and enhance community-based support (MOH, 2023).\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly_data &lt;- data %&gt;% filter(Age &gt;= 65)\n\ntotal_pop &lt;- data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Total_Pop = sum(ResidentCount, na.rm = TRUE))\n\nelderly_count &lt;- elderly_data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Elderly_Pop = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  arrange(desc(Elderly_Pop)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(PlanningArea = fct_reorder(PlanningArea, Elderly_Pop))\n\nelderly_prop &lt;- elderly_data %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(Elderly_Pop = sum(ResidentCount, na.rm = TRUE)) %&gt;%\n  left_join(total_pop, by = \"PlanningArea\") %&gt;%\n  mutate(Elderly_Proportion = Elderly_Pop / Total_Pop) %&gt;%\n  arrange(desc(Elderly_Proportion)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(PlanningArea = fct_reorder(PlanningArea, Elderly_Proportion))\n\n# Plot\np1 &lt;- ggplot(elderly_prop, aes(x = Elderly_Proportion, y = PlanningArea)) +\n  geom_col(fill = \"#4DAF4A\", width = 0.85) +\n  scale_x_continuous(\n    breaks = seq(0, 0.35, by = 0.05),\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Top 10 Planning Areas by Elderly Proportion (Age 65+)\",\n    x = \"Proportion of Elderly Residents\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 11),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n    panel.grid.minor = element_blank()\n  )\n\n\np2 &lt;- ggplot(elderly_count, aes(x = Elderly_Pop, y = PlanningArea)) +\n  geom_col(fill = \"#4DAF4A\", width = 0.85) +\n  scale_x_continuous(\n    breaks = seq(0, 70000, by = 10000),\n    labels = comma_format(),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Top 10 Planning Areas by Elderly Resident Count (Age 65+)\",\n    x = \"Number of Elderly Residents\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.background = element_rect(fill = \"#FFFCE8\", color = NA),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 11),\n    panel.grid.major.x = element_line(color = \"grey90\"),\n    panel.grid.minor = element_blank()\n  )\n\np1 / p2\n\n\n\n\n\n\n\nInsights:\n\nTampines, Bedok, and Sengkang are top the list with over 250,000 residents each.\nMillennials (age 28–43) are the largest group in most PA, while Gen X dominates in Bedok, a mature estate.\nYounger generations (Gen Alpha and Gen Z) are more concentrated in newer towns like Sengkang, Punggol, and Jurong West, aligned with recent BTO developments that attract young families.\nThe distribution reflects a balanced generational mix, highlighting Singapore’s multigenerational living pattern—with both aging residents and young households sharing town spaces.\nThese trends align with Singapore’s Smart Nation and HDB’s ‘Designing for Life’ vision: fostering harmonious, inclusive communities where families of all ages can live, age, and thrive together through well-integrated facilities, technology, and people-first urban design.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata &lt;- data %&gt;%\n  mutate(Age = as.numeric(Age),\n         Generation = case_when(\n           Age &lt;= 9 ~ \"Gen Alpha (≤9)\",\n           Age &lt;= 27 ~ \"Gen Z (10–27)\",\n           Age &lt;= 43 ~ \"Millennials (28–43)\",\n           Age &lt;= 59 ~ \"Gen X (44–59)\",\n           Age &lt;= 77 ~ \"Baby Boomers (60–77)\",\n           TRUE ~ \"Silent Gen (78+)\"\n         ))\n\ngen_by_area &lt;- data %&gt;%\n  group_by(PlanningArea, Generation) %&gt;%\n  summarise(ResidentCount = sum(ResidentCount, na.rm = TRUE), .groups = \"drop\")\n\ntop10_areas &lt;- gen_by_area %&gt;%\n  group_by(PlanningArea) %&gt;%\n  summarise(TotalPop = sum(ResidentCount)) %&gt;%\n  arrange(desc(TotalPop)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(PlanningArea)\n\ngen_top10 &lt;- gen_by_area %&gt;%\n  filter(PlanningArea %in% top10_areas) %&gt;%\n  mutate(\n    PlanningArea = fct_reorder(PlanningArea, ResidentCount, .fun = sum, .desc = TRUE),\n    Generation = factor(Generation, levels = c(\"Silent Gen (78+)\", \"Baby Boomers (60–77)\",\n                                               \"Gen X (44–59)\", \"Millennials (28–43)\",\n                                               \"Gen Z (10–27)\", \"Gen Alpha (≤9)\"))\n  )\n\ngen_colors &lt;- c(\n  \"Silent Gen (78+)\" = \"#c6dbef\",\n  \"Baby Boomers (60–77)\" = \"#6baed6\",\n  \"Gen X (44–59)\" = \"#b2df8a\",\n  \"Millennials (28–43)\" = \"#33a02c\",\n  \"Gen Z (10–27)\" = \"#fb9a99\",\n  \"Gen Alpha (≤9)\" = \"#e31a1c\"\n)\n\n#Plot\nggplot(gen_top10, aes(x = PlanningArea, y = ResidentCount, fill = Generation)) +\n  geom_col(width = 0.8, color = \"white\") +\n  scale_fill_manual(values = gen_colors) +\n  scale_y_continuous(\n    labels = comma,\n    breaks = seq(0, 300000, 50000),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  labs(\n    title = \"Generational Composition of Top 10 Most Populated Planning Areas\",\n    subtitle = \"Younger generations dominate newer towns, while older cohorts concentrate in mature estates\",\n    x = \"Planning Area\",\n    y = \"Resident Count\",\n    fill = \"Generation\"\n  ) +\n  theme_clean(base_size = 12) +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 11, hjust = 0.5),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major.x = element_blank(),\n    legend.position = \"right\"\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#summary",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#summary",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Singapore’s demographic structure, based on June 2024 data, highlights a maturing society with a dominant working-age group and a median age of 42. The growing share of seniors and the narrowing base of younger age groups reflect the effects of population aging and low birth rates. Mature estates such as Outram have the highest proportion of elderly residents, while Bedok and Tampines house the largest absolute numbers. In contrast, newer towns like Sengkang and Punggol show higher concentrations of younger generations—particularly Gen Alpha and Gen Z—driven by recent BTO developments attracting young families. Millennials remain the largest generational group across most areas, reinforcing their role in shaping urban life. This evolving yet balanced generational landscape underscores the need for inclusive community planning that supports both young families and seniors—fostering intergenerational harmony and enabling families to live, age, and thrive together."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#references",
    "href": "Take-home_Ex/Take-home_Ex_1/Take-Home_Ex1.html#references",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Department of Statistics Singapore. (2024). Population Trends 2024.\nRetrieved from: https://www.singstat.gov.sg/publications/population/population-trends\nMinistry of Health Singapore. (2023). Action Plan for Successful Ageing.\nRetrieved from: https://www.moh.gov.sg/newsroom/launch-of-the-2023-action-plan-for-successful-ageing\nHousing & Development Board (HDB). (2021). Designing for Life: Community Planning and Design Guide.\nRetrieved from: https://www.hdb.gov.sg/cs/infoweb/designing-for-life\nSmart Nation and Digital Government Office. (2023). Smart Nation: Empowering Everyone Through Technology.\nRetrieved from: https://www.smartnation.gov.sg\nSingapore Department of Statistics. (n.d.). National Statistical Standards.\nRetrieved from: https://www.singstat.gov.sg/standards"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 06",
    "section": "",
    "text": "By the end of this hands-on exercise we will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\n\n\n\n\n\n\n\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\n\nShow the code\n\n\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\n\nIn this section, we will learn how to plot a calender heatmap programmatically by using ggplot2 package.\n\nBy the end of this section, we will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, we will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\ntimestamp field stores date-time values in POSIXct format. source_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code. tz field stores time zone of the source IP address.\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n}\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section we will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor.\n\n\n\n\n\n\n\n\n\nA taxonomy of temporal data visualization techniques\nEdward Tufte’s “Slopegraphs”\nIntroduction to Cycle Plots\nVisualizing Change: An Innovation in Time-Series Analysis\nThe Development of the Horizon Graph\n\n\n\n\n\nwhat is a slopegraph?\nSlopegraph Update\nTime on the Horizon\nTimeSearcher\nWhat is a slopegraph?\nDonahue, Rafe M.J. Fundamental Statistical Concepts in Presenting Data: Principles for Constructing Better Graphics. This article provide a real world example of building truthful and functional time series graph.\nHockey stick graph at wiki.\nMichael E. Mann, Raymond S. Bradley, Malcolm K. Hughes (1999) “Northern hemisphere temperatures during the past millennium: Inferences, uncertainties, and limitations”. Geophysical Research Letters, Vol. 26, No. pp. 759-762.\nThe Guardian (2010) “Hockey stick graph took pride of place in IPCC report, despite doubts”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Hands-on Exercise 06",
    "section": "",
    "text": "By the end of this hands-on exercise we will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#do-it-yourself",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#do-it-yourself",
    "title": "Hands-on Exercise 06",
    "section": "",
    "text": "Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\n\nShow the code\n\n\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 06",
    "section": "",
    "text": "In this section, we will learn how to plot a calender heatmap programmatically by using ggplot2 package.\n\nBy the end of this section, we will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, we will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\ntimestamp field stores date-time values in POSIXct format. source_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code. tz field stores time zone of the source IP address.\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n}\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 06",
    "section": "",
    "text": "In this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on Exercise 06",
    "section": "",
    "text": "In this section we will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "In this exercise, we explore Mini-Challenge 2 (MC2) from the VAST Challenge 2025, which centers on the theme of conflict over societal change within the fictional island nation of Oceanus.\nOceanus is a historically fishing-based island economy that is now rapidly transforming due to the growth of tourism. This economic shift has sparked conflict between two influential groups:\n\nFishing is Living and Heritage (FILAH) – advocates for the preservation of Oceanus’s fishing heritage and industry.\nTourism Raises OceanUs Together (TROUT) – champions the modern tourism economy as the path to prosperity.\n\nBoth groups claim the Commission on Overseeing the Economic Future of Oceanus (COOTEFOO) of bias in its support of development initiatives. As data analysts, our goal is to reconstruct an unbiased understanding of COOTEFOO’s activities and assess the validity of these accusations using data from both camps and a more complete combined dataset.\n\n\n\nBased on the datasets that TROUT & FILAH have provided, use visual analytics to determine if each group’s accusations are supported by their own record set. In other words, develop a visualization to highlight bias (if present) in TROUT & FILAHS datasets. Is there evidence of bias in the COOTEFOO member actions in either dataset?\nAs a journalist, Ms. Moray would like a more complete picture of the COOTEFOO’s actions and activities. She has arranged to combine the data provided by TROUT and FILAH into a single knowledge graph along with additional records. Design visual analytics approaches for this combined knowledge graph to see how members of COOTEFOO spend their time. Is the committee as a whole biased? Provide visual evidence for your conclusions.\nThe TROUT and FILAH datasets are incomplete. Use your visualizations to compare and contrast conclusions drawn from the TROUT and FILAH datasets separately with behaviors in the whole dataset. Are the accusations of TROUT strengthened, weakened or unchanged when taken in context of the whole dataset?\nDesign a visualization that allows Ms. Moray to pick a person and highlight the differences in that person’s behavior as illustrated through the different datasets. Focus on the contrast in the story each dataset tells.\n\nPick at least one COOTEFOO member accused by TROUT. Illustrate how your understanding of their activities changed when using the more complete dataset.\nWhat are the key pieces of evidence missing from the original TROUT data that most influenced the change in judgement.\nWhose behaviors are most impacted by sampling bias when looking at the FILAH dataset in context of the other data?\nIllustrate the bias of the FILAH data in the context of the whole dataset.\n\n\n\n\n\nThe following packages are used to support data wrangling, spatial analysis, visualization, and network exploration:\n\ntidyverse: Core data science suite (dplyr, ggplot2, etc.)\njsonlite: Read/write JSON structured data\nsf: Handle and visualize spatial vector data (simple features)\nSmartEDA: Generate automated EDA reports\ntidygraph: Tidy framework for network/graph data\nggraph: Network plotting built on ggplot2\nggrepel: Prevent overlapping text labels in plots\ndata.table: High-performance data manipulation\nDT: Render interactive tables for web display\nvisNetwork: Interactive visualizations of graph objects\ntidyr: Tools for tidying and reshaping data\nnaniar: Explore and visualize missing data\nskimr: Compact summaries for data frames\nggridges: Create ridgeline density plots\nggalt: Additional geoms and stats for ggplot2\n\n\n\nShow the code\n\n\npacman::p_load(\n  tidyverse, jsonlite, sf, SmartEDA, tidygraph, ggrepel, ggraph,\n  data.table, DT, visNetwork, tidyr, naniar, skimr,\n  ggplot2, ggridges, ggalt\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#readings",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#readings",
    "title": "Hands-on Exercise 06",
    "section": "",
    "text": "A taxonomy of temporal data visualization techniques\nEdward Tufte’s “Slopegraphs”\nIntroduction to Cycle Plots\nVisualizing Change: An Innovation in Time-Series Analysis\nThe Development of the Horizon Graph\n\n\n\n\n\nwhat is a slopegraph?\nSlopegraph Update\nTime on the Horizon\nTimeSearcher\nWhat is a slopegraph?\nDonahue, Rafe M.J. Fundamental Statistical Concepts in Presenting Data: Principles for Constructing Better Graphics. This article provide a real world example of building truthful and functional time series graph.\nHockey stick graph at wiki.\nMichael E. Mann, Raymond S. Bradley, Malcolm K. Hughes (1999) “Northern hemisphere temperatures during the past millennium: Inferences, uncertainties, and limitations”. Geophysical Research Letters, Vol. 26, No. pp. 759-762.\nThe Guardian (2010) “Hockey stick graph took pride of place in IPCC report, despite doubts”."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#getting-started",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "The following packages are used to support data wrangling, spatial analysis, visualization, and network exploration:\n\ntidyverse: Core data science suite (dplyr, ggplot2, etc.)\njsonlite: Read/write JSON structured data\nsf: Handle and visualize spatial vector data (simple features)\nSmartEDA: Generate automated EDA reports\ntidygraph: Tidy framework for network/graph data\nggraph: Network plotting built on ggplot2\nggrepel: Prevent overlapping text labels in plots\ndata.table: High-performance data manipulation\nDT: Render interactive tables for web display\nvisNetwork: Interactive visualizations of graph objects\ntidyr: Tools for tidying and reshaping data\nnaniar: Explore and visualize missing data\nskimr: Compact summaries for data frames\nggridges: Create ridgeline density plots\nggalt: Additional geoms and stats for ggplot2\n\n\n\nShow the code\n\n\npacman::p_load(\n  tidyverse, jsonlite, sf, SmartEDA, tidygraph, ggrepel, ggraph,\n  data.table, DT, visNetwork, tidyr, naniar, skimr,\n  ggplot2, ggridges, ggalt\n)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#importing-knowledge-graph-data",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#importing-knowledge-graph-data",
    "title": "Take-home Exercise 02",
    "section": "2 Importing Knowledge Graph Data",
    "text": "2 Importing Knowledge Graph Data\nFirst, we will analyze the 3 files by importing them into R using the code chunk below:\n\nfilah &lt;- fromJSON(\"data/FILAH.json\")\ntrout &lt;- fromJSON(\"data/TROUT.json\")\njournalist &lt;- fromJSON(\"data/journalist.json\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#data-preparation",
    "title": "Take-home Exercise 02",
    "section": "3 Data Preparation",
    "text": "3 Data Preparation\n\n3.1 Inspecting Knowledge Graph Structure\nThe datasets contain graph data, where nodes can be accessed via nodes and edges via links. The datasets have a lot of columns but we will only filter the relevant columns in this analysis.\n\nFILAHTROUTJOURNALIST\n\n\n\nglimpse(filah)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 396 obs. of  17 variables:\n  ..$ type       : chr [1:396] \"meeting\" \"meeting\" \"meeting\" \"meeting\" ...\n  ..$ date       : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ label      : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ id         : chr [1:396] \"Meeting_1\" \"Meeting_2\" \"Meeting_3\" \"Meeting_4\" ...\n  ..$ name       : chr [1:396] NA NA NA NA ...\n  ..$ role       : chr [1:396] NA NA NA NA ...\n  ..$ short_topic: chr [1:396] NA NA NA NA ...\n  ..$ long_topic : chr [1:396] NA NA NA NA ...\n  ..$ short_title: chr [1:396] NA NA NA NA ...\n  ..$ long_title : chr [1:396] NA NA NA NA ...\n  ..$ plan_type  : chr [1:396] NA NA NA NA ...\n  ..$ lat        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ lon        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ zone       : chr [1:396] NA NA NA NA ...\n  ..$ zone_detail: chr [1:396] NA NA NA NA ...\n  ..$ start      : chr [1:396] NA NA NA NA ...\n  ..$ end        : chr [1:396] NA NA NA NA ...\n $ links     :'data.frame': 765 obs. of  9 variables:\n  ..$ role     : chr [1:765] \"part_of\" \"part_of\" \"part_of\" \"part_of\" ...\n  ..$ source   : chr [1:765] \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" ...\n  ..$ target   : chr [1:765] \"fish_vacuum_Meeting_1_Introduction_Discussion\" \"fish_vacuum_Meeting_1_Introduction\" \"seafood_festival_Meeting_1_Discussion\" \"seafood_festival_Meeting_1_Feasibility\" ...\n  ..$ key      : int [1:765] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:765] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:765] NA NA NA NA ...\n  ..$ industry :List of 765\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. .. [list output truncated]\n  ..$ status   : chr [1:765] NA NA NA NA ...\n  ..$ time     : chr [1:765] NA NA NA NA ...\n\n\n\n\n\nglimpse(trout)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 164 obs. of  17 variables:\n  ..$ type       : chr [1:164] \"plan\" \"plan\" \"plan\" \"meeting\" ...\n  ..$ short_title: chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" NA ...\n  ..$ long_title : chr [1:164] \"Present findings from the environmental impact study\" \"Report on travel and submit letter of support for low-volume unload crane\" \"Discuss maintenance plan and designate travel representatives\" NA ...\n  ..$ plan_type  : chr [1:164] \"Report\" \"report\" \"proposal\" NA ...\n  ..$ label      : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting 16\" ...\n  ..$ id         : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting_16\" ...\n  ..$ date       : chr [1:164] NA NA NA \"Meeting 16\" ...\n  ..$ short_topic: chr [1:164] NA NA NA NA ...\n  ..$ long_topic : chr [1:164] NA NA NA NA ...\n  ..$ lat        : num [1:164] NA NA NA NA NA ...\n  ..$ lon        : num [1:164] NA NA NA NA NA ...\n  ..$ zone       : chr [1:164] NA NA NA NA ...\n  ..$ zone_detail: chr [1:164] NA NA NA NA ...\n  ..$ name       : chr [1:164] NA NA NA NA ...\n  ..$ role       : chr [1:164] NA NA NA NA ...\n  ..$ start      : chr [1:164] NA NA NA NA ...\n  ..$ end        : chr [1:164] NA NA NA NA ...\n $ links     :'data.frame': 378 obs. of  9 variables:\n  ..$ role     : chr [1:378] \"plan\" \"participant\" \"plan\" \"participant\" ...\n  ..$ source   : chr [1:378] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"low_volume_crane_Meeting_8_Report\" ...\n  ..$ target   : chr [1:378] \"marine_life_deck\" \"Teddy Goldstein\" \"low_volume_crane\" \"Seal\" ...\n  ..$ key      : int [1:378] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:378] NA -0.5 NA 0.1 NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:378] NA \"Prefers resources to be allocated toward the fishing industry.\" NA \"Recognizes the crane's benefit to small-scale operations.\" ...\n  ..$ industry :List of 378\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. .. [list output truncated]\n  ..$ status   : chr [1:378] NA NA NA NA ...\n  ..$ time     : chr [1:378] NA NA NA NA ...\n\n\n\n\n\nglimpse(journalist)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 740 obs. of  17 variables:\n  ..$ type       : chr [1:740] \"meeting\" \"meeting\" \"meeting\" \"meeting\" ...\n  ..$ date       : chr [1:740] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ label      : chr [1:740] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ id         : chr [1:740] \"Meeting_1\" \"Meeting_2\" \"Meeting_3\" \"Meeting_4\" ...\n  ..$ name       : chr [1:740] NA NA NA NA ...\n  ..$ role       : chr [1:740] NA NA NA NA ...\n  ..$ short_topic: chr [1:740] NA NA NA NA ...\n  ..$ long_topic : chr [1:740] NA NA NA NA ...\n  ..$ short_title: chr [1:740] NA NA NA NA ...\n  ..$ long_title : chr [1:740] NA NA NA NA ...\n  ..$ plan_type  : chr [1:740] NA NA NA NA ...\n  ..$ lat        : num [1:740] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ lon        : num [1:740] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ zone       : chr [1:740] NA NA NA NA ...\n  ..$ zone_detail: chr [1:740] NA NA NA NA ...\n  ..$ start      : chr [1:740] NA NA NA NA ...\n  ..$ end        : chr [1:740] NA NA NA NA ...\n $ links     :'data.frame': 2436 obs. of  9 variables:\n  ..$ role     : chr [1:2436] \"part_of\" \"part_of\" \"part_of\" \"part_of\" ...\n  ..$ source   : chr [1:2436] \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" ...\n  ..$ target   : chr [1:2436] \"fish_vacuum_Meeting_1_Introduction_Discussion\" \"fish_vacuum_Meeting_1_Introduction\" \"seafood_festival_Meeting_1_Discussion\" \"seafood_festival_Meeting_1_Feasibility\" ...\n  ..$ key      : int [1:2436] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:2436] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:2436] NA NA NA NA ...\n  ..$ industry :List of 2436\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. .. [list output truncated]\n  ..$ status   : chr [1:2436] NA NA NA NA ...\n  ..$ time     : chr [1:2436] NA NA NA NA ...\n\n\n\n\n\n\n\n3.2 Extracting the edges and nodes tables\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from each of the dataframe into two separate tibble dataframes called nodes and edges respectively.\n\nFILAHTROUTJOURNALIST\n\n\n\nfilah_nodes &lt;- as_tibble(filah$nodes)\nfilah_edges &lt;- as_tibble(filah$links)\n\n\n\n\ntrout_nodes &lt;- as_tibble(trout$nodes)\ntrout_edges &lt;- as_tibble(trout$links)\n\n\n\n\njournalist_nodes &lt;- as_tibble(journalist$nodes)\njournalist_edges &lt;- as_tibble(journalist$links)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#initial-eda",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#initial-eda",
    "title": "Take-home Exercise 02",
    "section": "4 Initial EDA",
    "text": "4 Initial EDA\n\n4.1 Frequency Distribution\n\n4.1.1 Nodes Categorical Frequency Distribution\nIn the code chunk below, ExpCatViz() of SmartEDA package is used to reveal the frequency distribution of all categorical fields in each nodes tibble dataframe.\n\nFILAHTROUTJOURNALIST\n\n\n\nExpCatViz(data=filah_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to Note: Summary of Node Attribute Exploration\n\n\n\n\nNode Type (type)\n\nNearly half of all nodes (48%) are trip nodes, indicating a strong focus on travel records.\n\nOther significant types include discussion (15%), place (15%), and plan (10%).\n\n3% of node types are missing (NA), which may require cleaning or tagging.\n\nRole (role)\n\n99% of nodes have missing role values, making it difficult to analyze by committee roles.\n\nOnly a small portion are labeled as Member or Committee Chair.\n\nRole information may need to be imputed, enriched, or excluded depending on analysis goals.\n\nPlan Type (plan_type)\n\n90% of plan nodes lack plan_type values.\n\nOnly a small percentage are labeled as Travel, Proposal, etc.\n\nThis limits the usefulness of this variable unless cleaned or externally enriched.\n\nZone (zone)\n\n82% of place nodes are missing zone classification.\n\nMost of the known zones are commercial (14%) with small amounts of industrial and tourism.\n\nThis hinders any meaningful zoning or geographic segmentation.\n\nZone Detail (zone_detail)\n\n98% of zone_detail entries are missing.\n\nOnly 2% are labeled restaurant.\n\nThis variable may not be useful without enrichment from other sources.\n\n\n\n\n\n\n\nExpCatViz(data=trout_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpCatViz(data=journalist_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.2 Edges Categorical Frequency Distribution\nWe will also be using code chunk below that uses ExpCATViz() of SmartEDA package to reveal the frequency distribution of all categorical fields in the edges tibble dataframe.\n\nFILAHTROUTJOURNALIST\n\n\n\nExpCatViz(data=filah_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpCatViz(data=trout_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpCatViz(data=journalist_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.3 Nodes Numerical Frequency Distribution\nNext, we will use the code chunk below that uses ExpNumViz() of SmartEDA package to reveal the frequency distribution of all numerical fields in the nodes tibble dataframe.\n\nFILAHTROUTJOURNALIST\n\n\n\nExpNumViz(filah_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpNumViz(trout_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpNumViz(journalist_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.4 Nodes Numerical Frequency Distribution\nBelow, we will use the code chunk below that uses ExpNumViz() of SmartEDA package to reveal the frequency distribution of all numerical fields in the edges tibble dataframe.\n\nFILAHTROUTJOURNALIST\n\n\n\nExpNumViz(filah_edges)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpNumViz(trout_edges)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpNumViz(journalist_edges)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\nNode Type Distribution\n\nfilah_nodes %&gt;%\n  count(type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(type, n), y = n, fill = type)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"Node Type Distribution in FILAH\", x = \"Node Type\", y = \"Count\") +\n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#data-cleaning-and-wrangling",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#data-cleaning-and-wrangling",
    "title": "Take-home Exercise 02",
    "section": "5 Data Cleaning and Wrangling",
    "text": "5 Data Cleaning and Wrangling\n\n5.1 Cleaning and wrangling nodes\n\nfilah_nodes_cleaned &lt;- filah_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(id, type, label)   \n\n\n\n5.2 Cleaning and wrangling edges\n\nfilah_edges_cleaned &lt;- filah_edges %&gt;%\n  rename(from = source, to = target) %&gt;%\n  mutate(across(c(from, to), as.character)) %&gt;%\n  filter(from %in% filah_nodes_cleaned$id, to %in% filah_nodes_cleaned$id)\n\n# Remove problematic columns from edge table for graph building\nfilah_edges_min &lt;- filah_edges_cleaned %&gt;%\n  select(from, to, role)  # Only basic fields needed for graph structure\n\n\n\n5.3 Building the tidygraph object\n\nfilah_graph &lt;- tbl_graph(\n  nodes = filah_nodes_cleaned, \n  edges = filah_edges_min, \n  directed = TRUE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#visualising-the-knowledge-graph",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#visualising-the-knowledge-graph",
    "title": "Take-home Exercise 02",
    "section": "6 Visualising the knowledge graph",
    "text": "6 Visualising the knowledge graph\nIn this section, we will use ggraph’s functions to visualise and analyse the graph object.\n\nset.seed(1234)\n\nIn the code chunk below, ggraph functions are used to create the whole graph.\n\nggraph(filah_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#data-overview",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#data-overview",
    "title": "Take-home Exercise 02",
    "section": "3 Data Overview",
    "text": "3 Data Overview\n\n3.1 Inspecting Knowledge Graph Structure\nThe datasets contain graph data, where nodes can be accessed via nodes and edges via links. The datasets have a lot of columns but we will only filter the relevant data during wrangling step.\n\nFILAHTROUTJOURNALIST\n\n\n\nglimpse(filah)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 396 obs. of  17 variables:\n  ..$ type       : chr [1:396] \"meeting\" \"meeting\" \"meeting\" \"meeting\" ...\n  ..$ date       : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ label      : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ id         : chr [1:396] \"Meeting_1\" \"Meeting_2\" \"Meeting_3\" \"Meeting_4\" ...\n  ..$ name       : chr [1:396] NA NA NA NA ...\n  ..$ role       : chr [1:396] NA NA NA NA ...\n  ..$ short_topic: chr [1:396] NA NA NA NA ...\n  ..$ long_topic : chr [1:396] NA NA NA NA ...\n  ..$ short_title: chr [1:396] NA NA NA NA ...\n  ..$ long_title : chr [1:396] NA NA NA NA ...\n  ..$ plan_type  : chr [1:396] NA NA NA NA ...\n  ..$ lat        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ lon        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ zone       : chr [1:396] NA NA NA NA ...\n  ..$ zone_detail: chr [1:396] NA NA NA NA ...\n  ..$ start      : chr [1:396] NA NA NA NA ...\n  ..$ end        : chr [1:396] NA NA NA NA ...\n $ links     :'data.frame': 765 obs. of  9 variables:\n  ..$ role     : chr [1:765] \"part_of\" \"part_of\" \"part_of\" \"part_of\" ...\n  ..$ source   : chr [1:765] \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" ...\n  ..$ target   : chr [1:765] \"fish_vacuum_Meeting_1_Introduction_Discussion\" \"fish_vacuum_Meeting_1_Introduction\" \"seafood_festival_Meeting_1_Discussion\" \"seafood_festival_Meeting_1_Feasibility\" ...\n  ..$ key      : int [1:765] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:765] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:765] NA NA NA NA ...\n  ..$ industry :List of 765\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. .. [list output truncated]\n  ..$ status   : chr [1:765] NA NA NA NA ...\n  ..$ time     : chr [1:765] NA NA NA NA ...\n\n\n\n\n\nglimpse(trout)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 164 obs. of  17 variables:\n  ..$ type       : chr [1:164] \"plan\" \"plan\" \"plan\" \"meeting\" ...\n  ..$ short_title: chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" NA ...\n  ..$ long_title : chr [1:164] \"Present findings from the environmental impact study\" \"Report on travel and submit letter of support for low-volume unload crane\" \"Discuss maintenance plan and designate travel representatives\" NA ...\n  ..$ plan_type  : chr [1:164] \"Report\" \"report\" \"proposal\" NA ...\n  ..$ label      : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting 16\" ...\n  ..$ id         : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting_16\" ...\n  ..$ date       : chr [1:164] NA NA NA \"Meeting 16\" ...\n  ..$ short_topic: chr [1:164] NA NA NA NA ...\n  ..$ long_topic : chr [1:164] NA NA NA NA ...\n  ..$ lat        : num [1:164] NA NA NA NA NA ...\n  ..$ lon        : num [1:164] NA NA NA NA NA ...\n  ..$ zone       : chr [1:164] NA NA NA NA ...\n  ..$ zone_detail: chr [1:164] NA NA NA NA ...\n  ..$ name       : chr [1:164] NA NA NA NA ...\n  ..$ role       : chr [1:164] NA NA NA NA ...\n  ..$ start      : chr [1:164] NA NA NA NA ...\n  ..$ end        : chr [1:164] NA NA NA NA ...\n $ links     :'data.frame': 378 obs. of  9 variables:\n  ..$ role     : chr [1:378] \"plan\" \"participant\" \"plan\" \"participant\" ...\n  ..$ source   : chr [1:378] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"low_volume_crane_Meeting_8_Report\" ...\n  ..$ target   : chr [1:378] \"marine_life_deck\" \"Teddy Goldstein\" \"low_volume_crane\" \"Seal\" ...\n  ..$ key      : int [1:378] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:378] NA -0.5 NA 0.1 NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:378] NA \"Prefers resources to be allocated toward the fishing industry.\" NA \"Recognizes the crane's benefit to small-scale operations.\" ...\n  ..$ industry :List of 378\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. .. [list output truncated]\n  ..$ status   : chr [1:378] NA NA NA NA ...\n  ..$ time     : chr [1:378] NA NA NA NA ...\n\n\n\n\n\nglimpse(journalist)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 740 obs. of  17 variables:\n  ..$ type       : chr [1:740] \"meeting\" \"meeting\" \"meeting\" \"meeting\" ...\n  ..$ date       : chr [1:740] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ label      : chr [1:740] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ id         : chr [1:740] \"Meeting_1\" \"Meeting_2\" \"Meeting_3\" \"Meeting_4\" ...\n  ..$ name       : chr [1:740] NA NA NA NA ...\n  ..$ role       : chr [1:740] NA NA NA NA ...\n  ..$ short_topic: chr [1:740] NA NA NA NA ...\n  ..$ long_topic : chr [1:740] NA NA NA NA ...\n  ..$ short_title: chr [1:740] NA NA NA NA ...\n  ..$ long_title : chr [1:740] NA NA NA NA ...\n  ..$ plan_type  : chr [1:740] NA NA NA NA ...\n  ..$ lat        : num [1:740] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ lon        : num [1:740] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ zone       : chr [1:740] NA NA NA NA ...\n  ..$ zone_detail: chr [1:740] NA NA NA NA ...\n  ..$ start      : chr [1:740] NA NA NA NA ...\n  ..$ end        : chr [1:740] NA NA NA NA ...\n $ links     :'data.frame': 2436 obs. of  9 variables:\n  ..$ role     : chr [1:2436] \"part_of\" \"part_of\" \"part_of\" \"part_of\" ...\n  ..$ source   : chr [1:2436] \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" ...\n  ..$ target   : chr [1:2436] \"fish_vacuum_Meeting_1_Introduction_Discussion\" \"fish_vacuum_Meeting_1_Introduction\" \"seafood_festival_Meeting_1_Discussion\" \"seafood_festival_Meeting_1_Feasibility\" ...\n  ..$ key      : int [1:2436] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:2436] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:2436] NA NA NA NA ...\n  ..$ industry :List of 2436\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. .. [list output truncated]\n  ..$ status   : chr [1:2436] NA NA NA NA ...\n  ..$ time     : chr [1:2436] NA NA NA NA ...\n\n\n\n\n\n\n\n3.2 Extracting the edges and nodes tables\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from each of the dataframe into two separate tibble dataframes called nodes and edges respectively.\n\nFILAHTROUTJOURNALIST\n\n\n\nfilah_nodes &lt;- as_tibble(filah$nodes)\nfilah_edges &lt;- as_tibble(filah$links)\n\n\n\n\ntrout_nodes &lt;- as_tibble(trout$nodes)\ntrout_edges &lt;- as_tibble(trout$links)\n\n\n\n\njournalist_nodes &lt;- as_tibble(journalist$nodes)\njournalist_edges &lt;- as_tibble(journalist$links)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#overview",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#overview",
    "title": "Take-home Exercise 02",
    "section": "",
    "text": "In this exercise, we will be using Mini-Challenge 2 from VAST Challenge 2025, where we will take on the theme of conflict over societal change directly. Two opposing groups (FILAH and TROUT) representing the fishing and tourism industries are vying for economic development funding and claiming a local government board of bias. We will try to reconstruct a true timeline with data that comes from both sides.\n\n\n\nBased on the datasets that TROUT & FILAH have provided, use visual analytics to determine if each group’s accusations are supported by their own record set. In other words, develop a visualization to highlight bias (if present) in TROUT & FILAHS datasets. Is there evidence of bias in the COOTEFOO member actions in either dataset?\nAs a journalist, Ms. Moray would like a more complete picture of the COOTEFOO’s actions and activities. She has arranged to combine the data provided by TROUT and FILAH into a single knowledge graph along with additional records. Design visual analytics approaches for this combined knowledge graph to see how members of COOTEFOO spend their time. Is the committee as a whole biased? Provide visual evidence for your conclusions.\nThe TROUT and FILAH datasets are incomplete. Use your visualizations to compare and contrast conclusions drawn from the TROUT and FILAH datasets separately with behaviors in the whole dataset. Are the accusations of TROUT strengthened, weakened or unchanged when taken in context of the whole dataset?\nDesign a visualization that allows Ms. Moray to pick a person and highlight the differences in that person’s behavior as illustrated through the different datasets. Focus on the contrast in the story each dataset tells.\n\nPick at least one COOTEFOO member accused by TROUT. Illustrate how your understanding of their activities changed when using the more complete dataset.\nWhat are the key pieces of evidence missing from the original TROUT data that most influenced the change in judgement.\nWhose behaviors are most impacted by sampling bias when looking at the FILAH dataset in context of the other data?\nIllustrate the bias of the FILAH data in the context of the whole dataset.\n\n\n\n\n\nWe will use the following packages and using the p_load() of pacman package to load the R packages into R environment.\n\npacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph, ggraph, data.table, DT, visNetwork, tidyr, naniar)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#tasks-and-questions",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#tasks-and-questions",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "Based on the datasets that TROUT & FILAH have provided, use visual analytics to determine if each group’s accusations are supported by their own record set. In other words, develop a visualization to highlight bias (if present) in TROUT & FILAHS datasets. Is there evidence of bias in the COOTEFOO member actions in either dataset?\nAs a journalist, Ms. Moray would like a more complete picture of the COOTEFOO’s actions and activities. She has arranged to combine the data provided by TROUT and FILAH into a single knowledge graph along with additional records. Design visual analytics approaches for this combined knowledge graph to see how members of COOTEFOO spend their time. Is the committee as a whole biased? Provide visual evidence for your conclusions.\nThe TROUT and FILAH datasets are incomplete. Use your visualizations to compare and contrast conclusions drawn from the TROUT and FILAH datasets separately with behaviors in the whole dataset. Are the accusations of TROUT strengthened, weakened or unchanged when taken in context of the whole dataset?\nDesign a visualization that allows Ms. Moray to pick a person and highlight the differences in that person’s behavior as illustrated through the different datasets. Focus on the contrast in the story each dataset tells.\n\nPick at least one COOTEFOO member accused by TROUT. Illustrate how your understanding of their activities changed when using the more complete dataset.\nWhat are the key pieces of evidence missing from the original TROUT data that most influenced the change in judgement.\nWhose behaviors are most impacted by sampling bias when looking at the FILAH dataset in context of the other data?\nIllustrate the bias of the FILAH data in the context of the whole dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#inspecting-knowledge-graph-structure",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#inspecting-knowledge-graph-structure",
    "title": "Take-home Exercise 2",
    "section": "3.1 Inspecting Knowledge Graph Structure",
    "text": "3.1 Inspecting Knowledge Graph Structure\nThe datasets contain graph data, where nodes can be accessed via nodes and edges via links. The datasets have a lot of columns but we will only filter the relevant columns in this analysis.\n\n\nShow the code\n\n\nFILAHTROUTJOURNALIST\n\n\n\nglimpse(filah)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 396 obs. of  17 variables:\n  ..$ type       : chr [1:396] \"meeting\" \"meeting\" \"meeting\" \"meeting\" ...\n  ..$ date       : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ label      : chr [1:396] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ id         : chr [1:396] \"Meeting_1\" \"Meeting_2\" \"Meeting_3\" \"Meeting_4\" ...\n  ..$ name       : chr [1:396] NA NA NA NA ...\n  ..$ role       : chr [1:396] NA NA NA NA ...\n  ..$ short_topic: chr [1:396] NA NA NA NA ...\n  ..$ long_topic : chr [1:396] NA NA NA NA ...\n  ..$ short_title: chr [1:396] NA NA NA NA ...\n  ..$ long_title : chr [1:396] NA NA NA NA ...\n  ..$ plan_type  : chr [1:396] NA NA NA NA ...\n  ..$ lat        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ lon        : num [1:396] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ zone       : chr [1:396] NA NA NA NA ...\n  ..$ zone_detail: chr [1:396] NA NA NA NA ...\n  ..$ start      : chr [1:396] NA NA NA NA ...\n  ..$ end        : chr [1:396] NA NA NA NA ...\n $ links     :'data.frame': 765 obs. of  9 variables:\n  ..$ role     : chr [1:765] \"part_of\" \"part_of\" \"part_of\" \"part_of\" ...\n  ..$ source   : chr [1:765] \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" ...\n  ..$ target   : chr [1:765] \"fish_vacuum_Meeting_1_Introduction_Discussion\" \"fish_vacuum_Meeting_1_Introduction\" \"seafood_festival_Meeting_1_Discussion\" \"seafood_festival_Meeting_1_Feasibility\" ...\n  ..$ key      : int [1:765] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:765] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:765] NA NA NA NA ...\n  ..$ industry :List of 765\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. .. [list output truncated]\n  ..$ status   : chr [1:765] NA NA NA NA ...\n  ..$ time     : chr [1:765] NA NA NA NA ...\n\n\n\n\n\nglimpse(trout)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 164 obs. of  17 variables:\n  ..$ type       : chr [1:164] \"plan\" \"plan\" \"plan\" \"meeting\" ...\n  ..$ short_title: chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" NA ...\n  ..$ long_title : chr [1:164] \"Present findings from the environmental impact study\" \"Report on travel and submit letter of support for low-volume unload crane\" \"Discuss maintenance plan and designate travel representatives\" NA ...\n  ..$ plan_type  : chr [1:164] \"Report\" \"report\" \"proposal\" NA ...\n  ..$ label      : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting 16\" ...\n  ..$ id         : chr [1:164] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"deep_fishing_dock_Meeting_3_Maintenance_Plan\" \"Meeting_16\" ...\n  ..$ date       : chr [1:164] NA NA NA \"Meeting 16\" ...\n  ..$ short_topic: chr [1:164] NA NA NA NA ...\n  ..$ long_topic : chr [1:164] NA NA NA NA ...\n  ..$ lat        : num [1:164] NA NA NA NA NA ...\n  ..$ lon        : num [1:164] NA NA NA NA NA ...\n  ..$ zone       : chr [1:164] NA NA NA NA ...\n  ..$ zone_detail: chr [1:164] NA NA NA NA ...\n  ..$ name       : chr [1:164] NA NA NA NA ...\n  ..$ role       : chr [1:164] NA NA NA NA ...\n  ..$ start      : chr [1:164] NA NA NA NA ...\n  ..$ end        : chr [1:164] NA NA NA NA ...\n $ links     :'data.frame': 378 obs. of  9 variables:\n  ..$ role     : chr [1:378] \"plan\" \"participant\" \"plan\" \"participant\" ...\n  ..$ source   : chr [1:378] \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"marine_life_deck_Meeting_12_Environmental_Impact_Report\" \"low_volume_crane_Meeting_8_Report\" \"low_volume_crane_Meeting_8_Report\" ...\n  ..$ target   : chr [1:378] \"marine_life_deck\" \"Teddy Goldstein\" \"low_volume_crane\" \"Seal\" ...\n  ..$ key      : int [1:378] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:378] NA -0.5 NA 0.1 NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:378] NA \"Prefers resources to be allocated toward the fishing industry.\" NA \"Recognizes the crane's benefit to small-scale operations.\" ...\n  ..$ industry :List of 378\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : chr \"large vessel\"\n  .. ..$ : NULL\n  .. ..$ : chr \"tourism\"\n  .. ..$ : chr \"tourism\"\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : chr [1:2] \"large vessel\" \"small vessel\"\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : list()\n  .. .. [list output truncated]\n  ..$ status   : chr [1:378] NA NA NA NA ...\n  ..$ time     : chr [1:378] NA NA NA NA ...\n\n\n\n\n\nglimpse(journalist)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 740 obs. of  17 variables:\n  ..$ type       : chr [1:740] \"meeting\" \"meeting\" \"meeting\" \"meeting\" ...\n  ..$ date       : chr [1:740] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ label      : chr [1:740] \"Meeting 1\" \"Meeting 2\" \"Meeting 3\" \"Meeting 4\" ...\n  ..$ id         : chr [1:740] \"Meeting_1\" \"Meeting_2\" \"Meeting_3\" \"Meeting_4\" ...\n  ..$ name       : chr [1:740] NA NA NA NA ...\n  ..$ role       : chr [1:740] NA NA NA NA ...\n  ..$ short_topic: chr [1:740] NA NA NA NA ...\n  ..$ long_topic : chr [1:740] NA NA NA NA ...\n  ..$ short_title: chr [1:740] NA NA NA NA ...\n  ..$ long_title : chr [1:740] NA NA NA NA ...\n  ..$ plan_type  : chr [1:740] NA NA NA NA ...\n  ..$ lat        : num [1:740] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ lon        : num [1:740] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ zone       : chr [1:740] NA NA NA NA ...\n  ..$ zone_detail: chr [1:740] NA NA NA NA ...\n  ..$ start      : chr [1:740] NA NA NA NA ...\n  ..$ end        : chr [1:740] NA NA NA NA ...\n $ links     :'data.frame': 2436 obs. of  9 variables:\n  ..$ role     : chr [1:2436] \"part_of\" \"part_of\" \"part_of\" \"part_of\" ...\n  ..$ source   : chr [1:2436] \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" \"Meeting_1\" ...\n  ..$ target   : chr [1:2436] \"fish_vacuum_Meeting_1_Introduction_Discussion\" \"fish_vacuum_Meeting_1_Introduction\" \"seafood_festival_Meeting_1_Discussion\" \"seafood_festival_Meeting_1_Feasibility\" ...\n  ..$ key      : int [1:2436] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ sentiment: num [1:2436] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ reason   : chr [1:2436] NA NA NA NA ...\n  ..$ industry :List of 2436\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. ..$ : NULL\n  .. .. [list output truncated]\n  ..$ status   : chr [1:2436] NA NA NA NA ...\n  ..$ time     : chr [1:2436] NA NA NA NA ..."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#extracting-the-edges-and-nodes-tables",
    "title": "Take-home Exercise 2",
    "section": "3.2 Extracting the edges and nodes tables",
    "text": "3.2 Extracting the edges and nodes tables\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from each of the dataframe into two separate tibble dataframes called nodes and edges respectively.\n\n\nShow the code\n\n\nFILAHTROUTJOURNALIST\n\n\n\nfilah_nodes &lt;- as_tibble(filah$nodes)\nfilah_edges &lt;- as_tibble(filah$links)\n\n\n\n\ntrout_nodes &lt;- as_tibble(trout$nodes)\ntrout_edges &lt;- as_tibble(trout$links)\n\n\n\n\njournalist_nodes &lt;- as_tibble(journalist$nodes)\njournalist_edges &lt;- as_tibble(journalist$links)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#frequency-distribution",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#frequency-distribution",
    "title": "Take-home Exercise 2",
    "section": "4.1 Frequency Distribution",
    "text": "4.1 Frequency Distribution\n\n4.1.1 Nodes Categorical Frequency Distribution\nIn the code chunk below, ExpCatViz() of SmartEDA package is used to reveal the frequency distribution of all categorical fields in each nodes tibble dataframe.\n\nFILAHTROUTJOURNALIST\n\n\n\nExpCatViz(data=filah_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nNode Type : Nearly half (48%) of the nodes in FILAH are trip-related, indicating a strong emphasis on travel data. There is moderate representation of discussion (15%), place (15%), and plan (10%) nodes, while missing type values (NA) at around 3%.\nRole: 99% of nodes have missing role values. There are only 3 known roles: 2 Members and 1 Committee Chair.\nZone: 82% of place nodes are missing zoning info. Among known zones, commercial dominates (14%).\n\n\n\n\n\nExpCatViz(data=trout_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nNode Type: more evenly distributed, with Discussion (24%), Plan (20%), and Place (18%) making up the majority. Trip nodes are notably lower at 11% compared to 48% in FILAH, suggesting that TROUT places greater emphasis on planning and discourse rather than travel activity. NA values are minimal at 2%.\nZone: - 80% missing, only government zone shows some visibility (12%).\nRole: - 96% missing, but contains more variety than FILAH (includes Treasurer, Vice Chair).\n\n\n\n\n\nExpCatViz(data=journalist_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nNode Type: Strong emphasis on trip (46%) and place (21%) nodes, with plan (10%) and discussion (14%) also notable; NA values are minimal (~3%).\nRole: 99% of role values are missing\nZone: 77% missing, but better coverage than FILAH or TROUT. commercial (12%) is the most visible zone type, followed by residential (4%) and government (4%).\n\n\n\n\n\n\n\n4.1.2 Edges Categorical Frequency Distribution\nWe will also be using code chunk below that uses ExpCATViz() of SmartEDA package to reveal the frequency distribution of all categorical fields in the edges tibble dataframe.\n\nFILAHTROUTJOURNALIST\n\n\n\nExpCatViz(data=filah_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpCatViz(data=trout_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpCatViz(data=journalist_edges,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nAcross all three datasets, the role field shows a high proportion of missing (NA) values, with JOURNALIST at 70%, FILAH at 46%, and TROUT at 25%, indicating limited role clarity—especially in the full dataset. The status attribute is also largely incomplete, with over 90% of entries missing in every dataset, limiting insights into project progression. For sentiment, although a small proportion of edges carry values, positive sentiment (value = 1) dominates across all datasets—FILAH (5%), TROUT (10%), and JOURNALIST (4%)—while over 75–90% of entries are NA. This highlights a critical gap in annotation completeness, constraining deeper interpretation of engagement tone or project state.\n\n\n\n\n4.1.3 Nodes Numerical Frequency Distribution\nNext, we will use the code chunk below that uses ExpNumViz() of SmartEDA package to reveal the frequency distribution of all numerical fields in the nodes tibble dataframe.\n\nFILAHTROUTJOURNALIST\n\n\n\nExpNumViz(filah_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpNumViz(trout_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpNumViz(journalist_nodes)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThe spatial density plots reveal notable differences in geographic coverage across the datasets. FILAH shows a bi-modal distribution in both latitude and longitude, with mild skewness, indicating a focus on two primary regions—likely aligned with fishing routes or coastal hubs.\nTROUT, on the other hand, exhibits a more skewed latitude distribution and tighter clustering in longitude, suggesting activity is concentrated in fewer, likely policy- or tourism-related zones.\nIn contrast, the JOURNALIST dataset displays the most balanced and inclusive spatial distribution, combining patterns from both FILAH and TROUT. This makes JOURNALIST the best baseline for identifying potential geographic bias or omissions in the two advocacy group datasets.\n\n\n\n\n4.1.4 Edges Numerical Frequency Distribution\nBelow, we will use the code chunk below that uses ExpNumViz() of SmartEDA package to reveal the frequency distribution of all numerical fields in the edges tibble dataframe.\n\nFILAHTROUTJOURNALIST\n\n\n\nExpNumViz(filah_edges)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpNumViz(trout_edges)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\nExpNumViz(journalist_edges)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nAll three datasets show a left-skewed sentiment distribution, indicating a tendency toward positive sentiment in recorded interactions. FILAH displays moderate skewness, suggesting selective positivity likely aligned with pro-fishing narratives. TROUT is more balanced, showing a wider range of sentiment and possibly greater objectivity. JOURNALIST has the strongest left skew and a sharp peak, reflecting a high concentration of positive sentiment—likely a result of broader coverage rather than selective reporting. This highlights how sentiment framing differs across datasets, with TROUT offering more variation, while FILAH and JOURNALIST lean more positive overall."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#count-missing-values-by-column",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#count-missing-values-by-column",
    "title": "Take-home Exercise 02",
    "section": "4.2 Count missing values by column",
    "text": "4.2 Count missing values by column\n\n# Filter to only columns with missing values\nmiss_summary_nodes &lt;- bind_rows(\n  miss_var_summary(filah_nodes) %&gt;% mutate(dataset = \"FILAH\"),\n  miss_var_summary(trout_nodes) %&gt;% mutate(dataset = \"TROUT\"),\n  miss_var_summary(journalist_nodes) %&gt;% mutate(dataset = \"JOURNALIST\")\n) %&gt;% \n  filter(n_miss &gt; 0) %&gt;% \n  select(dataset, variable, n_miss, pct_miss)\n\nmiss_summary_edges &lt;- bind_rows(\n  miss_var_summary(filah_edges) %&gt;% mutate(dataset = \"FILAH\"),\n  miss_var_summary(trout_edges) %&gt;% mutate(dataset = \"TROUT\"),\n  miss_var_summary(journalist_edges) %&gt;% mutate(dataset = \"JOURNALIST\")\n) %&gt;% \n  filter(n_miss &gt; 0) %&gt;% \n  select(dataset, variable, n_miss, pct_miss)\n\n# Display filtered tables\nDT::datatable(miss_summary_nodes)\n\n\n\n\nDT::datatable(miss_summary_edges)\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nAcross all datasets, key attributes such as role, zone, plan_type, and sentiment exhibit high missingness—exceeding 90% in most cases for FILAH and TROUT. The JOURNALIST dataset provides broader coverage but still lacks complete detail in certain fields. These gaps highlight the need to interpret findings cautiously and emphasize the importance of using the full dataset for bias assessment.\n\n\n\n# Check for duplicate IDs in each dataset\nlist(\n  FILAH = filah_nodes %&gt;% summarise(duplicates = sum(duplicated(id))),\n  TROUT = trout_nodes %&gt;% summarise(duplicates = sum(duplicated(id))),\n  JOURNALIST = journalist_nodes %&gt;% summarise(duplicates = sum(duplicated(id)))\n)\n\n$FILAH\n# A tibble: 1 × 1\n  duplicates\n       &lt;int&gt;\n1          0\n\n$TROUT\n# A tibble: 1 × 1\n  duplicates\n       &lt;int&gt;\n1          0\n\n$JOURNALIST\n# A tibble: 1 × 1\n  duplicates\n       &lt;int&gt;\n1          0\n\n\n\n\n\n\n\n\nDuplicate ID Check\n\n\n\nAll three node datasets (FILAH, TROUT, and JOURNALIST) have unique id values with no duplicates, confirming structural integrity at the node level."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#check-for-missing-values",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#check-for-missing-values",
    "title": "Take-home Exercise 2",
    "section": "4.2 Check for Missing Values",
    "text": "4.2 Check for Missing Values\nNext, we will check the missing values in the dataset.\n\n\nShow the code\n\n\n# Filter to only columns with missing values\nmiss_summary_nodes &lt;- bind_rows(\n  miss_var_summary(filah_nodes) %&gt;% mutate(dataset = \"FILAH\"),\n  miss_var_summary(trout_nodes) %&gt;% mutate(dataset = \"TROUT\"),\n  miss_var_summary(journalist_nodes) %&gt;% mutate(dataset = \"JOURNALIST\")\n) %&gt;% \n  filter(n_miss &gt; 0) %&gt;% \n  select(dataset, variable, n_miss, pct_miss)\n\nmiss_summary_edges &lt;- bind_rows(\n  miss_var_summary(filah_edges) %&gt;% mutate(dataset = \"FILAH\"),\n  miss_var_summary(trout_edges) %&gt;% mutate(dataset = \"TROUT\"),\n  miss_var_summary(journalist_edges) %&gt;% mutate(dataset = \"JOURNALIST\")\n) %&gt;% \n  filter(n_miss &gt; 0) %&gt;% \n  select(dataset, variable, n_miss, pct_miss)\n\n# Display filtered tables\nDT::datatable(miss_summary_nodes)\nDT::datatable(miss_summary_edges)\n\n\n\n\n\n\n\n\nObservation\n\n\n\nAcross all datasets, key attributes such as role, zone, plan_type, and sentiment exhibit high number of missing values—exceeding 90% in most cases for FILAH and TROUT. The JOURNALIST dataset provides broader coverage but still lacks complete detail in certain fields. These gaps highlight the need to interpret findings cautiously and emphasize the importance of using the full dataset for bias assessment."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#check-for-duplicate-values",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#check-for-duplicate-values",
    "title": "Take-home Exercise 2",
    "section": "4.3 Check for Duplicate Values",
    "text": "4.3 Check for Duplicate Values\nIn the code below we will check for any duplicate values in the dataset.\n\n\nShow the code\n\n\n# Check for duplicate IDs in each dataset\nlist(\n  FILAH = filah_nodes %&gt;% summarise(duplicates = sum(duplicated(id))),\n  TROUT = trout_nodes %&gt;% summarise(duplicates = sum(duplicated(id))),\n  JOURNALIST = journalist_nodes %&gt;% summarise(duplicates = sum(duplicated(id)))\n)\n\n$FILAH\n# A tibble: 1 × 1\n  duplicates\n       &lt;int&gt;\n1          0\n\n$TROUT\n# A tibble: 1 × 1\n  duplicates\n       &lt;int&gt;\n1          0\n\n$JOURNALIST\n# A tibble: 1 × 1\n  duplicates\n       &lt;int&gt;\n1          0\n\n\n\n\n\n\n\n\n\nDuplicate ID Check\n\n\n\nAll three node datasets (FILAH, TROUT, and JOURNALIST) have unique id values with no duplicates, confirming structural integrity at the node level."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#data-cleaning-wrangling-and-visualization",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#data-cleaning-wrangling-and-visualization",
    "title": "Take-home Exercise 02",
    "section": "5. Data Cleaning, Wrangling, and Visualization",
    "text": "5. Data Cleaning, Wrangling, and Visualization\nWe define reusable functions to clean and wrangle each dataset into a graph structure and visualize the result.\n\n# Function to clean and build graph\n\nbuild_graph_data &lt;- function(nodes_df, edges_df) {\n  # Clean nodes\n  nodes_cleaned &lt;- nodes_df %&gt;%\n    mutate(id = as.character(id)) %&gt;%\n    filter(!is.na(id)) %&gt;%\n    distinct(id, .keep_all = TRUE) %&gt;%\n    select(id, type, label)\n  \n  # Clean edges\n  edges_cleaned &lt;- edges_df %&gt;%\n    rename(from = source, to = target) %&gt;%\n    mutate(across(c(from, to), as.character)) %&gt;%\n    filter(from %in% nodes_cleaned$id, to %in% nodes_cleaned$id)\n  \n  # Simplified edge table for graph\n  edges_min &lt;- edges_cleaned %&gt;%\n    select(from, to, role)\n  \n  # Build tidygraph object\n  graph_obj &lt;- tbl_graph(\n    nodes = nodes_cleaned,\n    edges = edges_min,\n    directed = TRUE\n  )\n  \n  # Return all elements for reuse\n  return(list(\n    nodes_cleaned = nodes_cleaned,\n    edges_cleaned = edges_cleaned,\n    edges_min = edges_min,\n    graph = graph_obj\n  ))\n}\n\n\nplot_graph_overview &lt;- function(graph_obj, title = \"Graph Overview\") {\n  set.seed(1234)  # Ensure reproducibility\n  \n  ggraph(graph_obj, layout = \"fr\") +\n    geom_edge_link(alpha = 0.3, colour = \"gray\") +\n    geom_node_point(aes(color = type), size = 4) +\n    geom_node_text(aes(label = type), repel = TRUE, size = 2.5) +\n    ggtitle(title) +\n    theme_void()\n}\n\n\nFILAHTROUTJOURNALIST\n\n\n\nfilah_data &lt;- build_graph_data(filah_nodes, filah_edges)\nplot_graph_overview(filah_data$graph, \"FILAH Knowledge Graph\")\n\n\n\n\n\n\n\n\n\n\n\n\ntrout_data &lt;- build_graph_data(trout_nodes, trout_edges)\nplot_graph_overview(trout_data$graph, \"TROUT Knowledge Graph\")\n\n\n\n\n\n\n\n\n\n\n\n\njournalist_data &lt;- build_graph_data(journalist_nodes, journalist_edges)\nplot_graph_overview(journalist_data$graph, \"JOURNALIST Knowledge Graph\")\n\n\n\n\n\n\n\n\n\n\n\nPeople EDA\n\n# Extract COOTEFOO members (nodes with non-NA role)\ncootefoo_members_all &lt;- bind_rows(\n  filah_nodes %&gt;% filter(!is.na(role)) %&gt;% mutate(source = \"FILAH\"),\n  trout_nodes %&gt;% filter(!is.na(role)) %&gt;% mutate(source = \"TROUT\"),\n  journalist_nodes %&gt;% filter(!is.na(role)) %&gt;% mutate(source = \"JOURNALIST\")\n) %&gt;%\n  distinct(name, role, source)\n\n# View full member list\ncootefoo_members_all\n\n# A tibble: 15 × 3\n   name            role            source    \n   &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;     \n 1 Seal            Committee Chair FILAH     \n 2 Simone Kat      Member          FILAH     \n 3 Carol Limpet    Member          FILAH     \n 4 Teddy Goldstein Treasurer       TROUT     \n 5 Ed Helpsford    Vice Chair      TROUT     \n 6 Seal            Committee Chair TROUT     \n 7 Tante Titan     Member          TROUT     \n 8 Carol Limpet    Member          TROUT     \n 9 Simone Kat      Member          TROUT     \n10 Seal            Committee Chair JOURNALIST\n11 Ed Helpsford    Vice Chair      JOURNALIST\n12 Teddy Goldstein Treasurer       JOURNALIST\n13 Simone Kat      Member          JOURNALIST\n14 Tante Titan     Member          JOURNALIST\n15 Carol Limpet    Member          JOURNALIST\n\n\n\n# Load required package (already in pacman::p_load)\nlibrary(ggvenn)\n\n# Prepare member sets from each dataset (non-missing names with role)\nmember_sets &lt;- list(\n  FILAH = filah_nodes %&gt;% filter(!is.na(role)) %&gt;% pull(name) %&gt;% unique(),\n  TROUT = trout_nodes %&gt;% filter(!is.na(role)) %&gt;% pull(name) %&gt;% unique(),\n  JOURNALIST = journalist_nodes %&gt;% filter(!is.na(role)) %&gt;% pull(name) %&gt;% unique()\n)\n\n# Create inclusive Venn diagram using ggvenn\nggvenn(\n  member_sets,\n  fill_color = c(\"#99d8c9\", \"#fdbb84\", \"#c6dbef\"),\n  show_percentage = TRUE,\n  set_name_size = 4,\n  stroke_size = 0.5\n)\n\n\n\n\n\n\n\nReduce(intersect, list(\n  filah_nodes %&gt;% filter(!is.na(role)) %&gt;% pull(name),\n  trout_nodes %&gt;% filter(!is.na(role)) %&gt;% pull(name),\n  journalist_nodes %&gt;% filter(!is.na(role)) %&gt;% pull(name)\n))\n\n[1] \"Seal\"         \"Simone Kat\"   \"Carol Limpet\"\n\n\n\n# Filter by these three names across datasets\ncore_members &lt;- c(\"Seal\", \"Simone Kat\", \"Carol Limpet\")\n\n# Example: filter journalist_edges to just interactions involving them\njournalist_edges %&gt;%\n  filter(target %in% core_members | source %in% core_members)\n\n# A tibble: 267 × 9\n   role        source        target   key sentiment reason industry status time \n   &lt;chr&gt;       &lt;chr&gt;         &lt;chr&gt;  &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;list&gt;   &lt;chr&gt;  &lt;chr&gt;\n 1 participant expanding_to… Seal       0       0.1 Seems… &lt;chr&gt;    &lt;NA&gt;   &lt;NA&gt; \n 2 participant expanding_to… Simon…     0       0.5 Suppo… &lt;chr&gt;    &lt;NA&gt;   &lt;NA&gt; \n 3 participant expanding_to… Simon…     0       0.5 Suppo… &lt;chr&gt;    &lt;NA&gt;   &lt;NA&gt; \n 4 participant expanding_to… Seal       0       0.1 Seems… &lt;chr&gt;    &lt;NA&gt;   &lt;NA&gt; \n 5 participant expanding_to… Simon…     0       0.5 Suppo… &lt;chr&gt;    &lt;NA&gt;   &lt;NA&gt; \n 6 participant expanding_to… Seal       0       0.1 Seems… &lt;chr&gt;    &lt;NA&gt;   &lt;NA&gt; \n 7 participant expanding_to… Seal       0       0.1 Seems… &lt;chr&gt;    &lt;NA&gt;   &lt;NA&gt; \n 8 participant statue_john_… Seal       0       0.2 Appre… &lt;list&gt;   &lt;NA&gt;   &lt;NA&gt; \n 9 participant statue_john_… Seal       0       0.2 Appre… &lt;list&gt;   &lt;NA&gt;   &lt;NA&gt; \n10 participant deep_fishing… Simon…     0      NA   &lt;NA&gt;   &lt;NULL&gt;   &lt;NA&gt;   &lt;NA&gt; \n# ℹ 257 more rows\n\n\n\n# Step 1: Get full list of COOTEFOO members from journalist\nall_members &lt;- journalist_nodes %&gt;%\n  filter(!is.na(role)) %&gt;%\n  pull(name)\n\n# Step 2: Analyze participation and sentiment\nmember_stats &lt;- journalist_edges %&gt;%\n  filter(role == \"participant\", target %in% all_members | source %in% all_members) %&gt;%\n  mutate(member = if_else(target %in% all_members, target, source)) %&gt;%\n  group_by(member) %&gt;%\n  summarise(\n    n = n(),  # participation count\n    avg_sentiment = mean(sentiment, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(n))\n\n# View result\nmember_stats\n\n# A tibble: 6 × 3\n  member              n avg_sentiment\n  &lt;chr&gt;           &lt;int&gt;         &lt;dbl&gt;\n1 Tante Titan        54         0.819\n2 Simone Kat         45         0.469\n3 Teddy Goldstein    22         0.344\n4 Carol Limpet       21         0.655\n5 Ed Helpsford       20         0.7  \n6 Seal               12         0.108\n\n\n\nggplot(member_stats, aes(x = reorder(member, avg_sentiment), y = avg_sentiment, fill = n)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"COOTEFOO Members: Sentiment vs. Activity\",\n    x = \"Member\",\n    y = \"Average Sentiment\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Step 1: Get full member list from JOURNALIST\ncootefoo_members &lt;- journalist_nodes %&gt;%\n  filter(!is.na(role)) %&gt;%\n  pull(name) %&gt;%\n  unique()\n\n# Step 2: Function to extract member activity from any dataset\nget_member_stats &lt;- function(edges, dataset_name) {\n  edges %&gt;%\n    filter(role == \"participant\", source %in% cootefoo_members | target %in% cootefoo_members) %&gt;%\n    mutate(member = if_else(source %in% cootefoo_members, source, target)) %&gt;%\n    group_by(member) %&gt;%\n    summarise(\n      n = n(),\n      avg_sentiment = mean(sentiment, na.rm = TRUE),\n      dataset = dataset_name\n    )\n}\n\n# Step 3: Apply to all three datasets\nfilah_stats &lt;- get_member_stats(filah_edges, \"FILAH\")\ntrout_stats &lt;- get_member_stats(trout_edges, \"TROUT\")\njournalist_stats &lt;- get_member_stats(journalist_edges, \"JOURNALIST\")\n\n# Combine results\nall_member_stats &lt;- bind_rows(filah_stats, trout_stats, journalist_stats)\n\n# Step 4: Plotting\nlibrary(ggplot2)\n\nggplot(all_member_stats, aes(x = reorder(member, avg_sentiment), y = avg_sentiment, fill = dataset)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(\n    title = \"COOTEFOO Member Sentiment by Dataset\",\n    x = \"Member\",\n    y = \"Average Sentiment\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#building-the-function",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#building-the-function",
    "title": "Take-home Exercise 2",
    "section": "5.1 Building the Function",
    "text": "5.1 Building the Function\nWe define reusable functions to clean and wrangle the nodes and edges of each dataset into a graph structure and visualize the result. We will use id, type and label to build the function for Knowledge Graph.\n\n\nShow the code\n\n\n# Function to clean and build graph\n\nbuild_graph_data &lt;- function(nodes_df, edges_df) {\n  # Clean nodes\n  nodes_cleaned &lt;- nodes_df %&gt;%\n    mutate(id = as.character(id)) %&gt;%\n    filter(!is.na(id)) %&gt;%\n    distinct(id, .keep_all = TRUE) %&gt;%\n    select(id, type, label)\n  \n  # Clean edges\n  edges_cleaned &lt;- edges_df %&gt;%\n    rename(from = source, to = target) %&gt;%\n    mutate(across(c(from, to), as.character)) %&gt;%\n    filter(from %in% nodes_cleaned$id, to %in% nodes_cleaned$id)\n  \n  # Simplified edge table for graph\n  edges_min &lt;- edges_cleaned %&gt;%\n    select(from, to, role)\n    \n  # Build tidygraph object\n  graph_obj &lt;- tbl_graph(\n    nodes = nodes_cleaned,\n    edges = edges_min,\n    directed = TRUE\n  )\n  \n  # Return all elements for reuse\n  return(list(\n    nodes_cleaned = nodes_cleaned,\n    edges_cleaned = edges_cleaned,\n    edges_min = edges_min,\n    graph = graph_obj\n  ))\n}\n\n\nAs several of ggraph layouts involve randomization, in order to ensure reproducibility, it is necessary to set the seed value before plotting. We will use the following function to visualize the knowledge graph:\n\n\nShow the code\n\n\nplot_graph_overview &lt;- function(graph_obj, title = \"Graph Overview\") {\n  set.seed(1234)  # Ensure reproducibility\n  \n  ggraph(graph_obj, layout = \"fr\") +\n    geom_edge_link(alpha = 0.3, colour = \"gray\") +\n    geom_node_point(aes(color = type), size = 4) +\n    geom_node_text(aes(label = type), repel = TRUE, size = 2.5) +\n    ggtitle(title) +\n    theme_void()\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#visualizing-the-knowledge-graph",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#visualizing-the-knowledge-graph",
    "title": "Take-home Exercise 2",
    "section": "5.2 Visualizing the Knowledge Graph",
    "text": "5.2 Visualizing the Knowledge Graph\nwe will use the functions set up earlier for each dataset to visualize the knowledge graph as follows:\n\nFILAHTROUTJOURNALIST\n\n\n\nfilah_data &lt;- build_graph_data(filah_nodes, filah_edges)\nplot_graph_overview(filah_data$graph, \"FILAH Knowledge Graph\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights — FILAH Knowledge Graph\n\n\n\nThe FILAH Knowledge Graph is strongly travel-oriented, with trip and place nodes dominating the structure. These nodes form tight clusters, particularly on the graph’s periphery, highlighting a dataset constructed heavily around physical movements and site visits. The central region connects a smaller set of plan, discussion, and topic nodes, indicating some internal deliberation, though not as extensively represented. The prevalence of pink (trip) and cyan (place) suggests a bias toward documenting activities tied to fishing zones and physical visits, aligning with FILAH’s focus. There are relatively few missing (NA) nodes, and entity.person nodes appear less central—implying limited metadata on individual involvement.\n\n\n\n\n\n\ntrout_data &lt;- build_graph_data(trout_nodes, trout_edges)\nplot_graph_overview(trout_data$graph, \"TROUT Knowledge Graph\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights — TROUT Knowledge Graph\n\n\n\nThe TROUT Knowledge Graph presents a denser, more balanced core structure, emphasizing discussion, plan, and meeting nodes. These indicate a dataset centered on dialogue and strategy rather than physical movement. Trip and place nodes are present but largely positioned in the outer cluster, suggesting they play a supporting rather than dominant role in this narrative. The central cluster tightly links topics to discussions and plans, reflecting TROUT’s focus on tourism policy, planning, and civic engagement. Entity.person nodes are more visible here than in FILAH, showing clearer attribution of roles within planning processes. Overall, the structure reflects a policy-driven lens with a centralized documentation approach.\n\n\n\n\n\n\njournalist_data &lt;- build_graph_data(journalist_nodes, journalist_edges)\nplot_graph_overview(journalist_data$graph, \"JOURNALIST Knowledge Graph\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights — Journalist Knowledge Graph\n\n\n\nThe Journalist Knowledge Graph is the most comprehensive and integrated among the three. It merges the narrative strengths of both FILAH and TROUT datasets—featuring a rich, interconnected core of plans, discussions, topics, and meetings, while also showing extensive clusters of trips and places. The graph structure indicates a full lifecycle of committee activity: from discourse to field visits. Entity.person and entity.organization nodes are more evenly distributed and active, suggesting better attribution and data coverage. While there are more NA-labeled nodes compared to other graphs, the overall density and connectivity reveal a holistic portrayal of COOTEFOO’s activities, enabling clearer bias assessment when cross-referenced with the other two graphs."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#cootefoo-member-involvement",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#cootefoo-member-involvement",
    "title": "Take-home Exercise 02",
    "section": "5.3 COOTEFOO Member Involvement",
    "text": "5.3 COOTEFOO Member Involvement\nNext, we will examine the Name and Role variables from each dataset to see the involvement of the COOTEFOO members, with the code below:\n\n\nShow the code\n\n\n# Set role hierarchy for custom ordering\nrole_order &lt;- c(\"Committee Chair\", \"Vice Chair\", \"Treasurer\", \"Member\")\n\n# Combine and pivot the dataset\ncootefoo_members_all &lt;- bind_rows(\n  filah_nodes %&gt;% filter(!is.na(role)) %&gt;% mutate(source = \"FILAH\"),\n  trout_nodes %&gt;% filter(!is.na(role)) %&gt;% mutate(source = \"TROUT\"),\n  journalist_nodes %&gt;% filter(!is.na(role)) %&gt;% mutate(source = \"JOURNALIST\")\n) %&gt;%\n  distinct(name, role, source) %&gt;%\n  mutate(present = TRUE) %&gt;%\n  pivot_wider(\n    names_from = source,\n    values_from = present,\n    values_fill = FALSE\n  ) %&gt;%\n  mutate(role = factor(role, levels = role_order)) %&gt;%\n  arrange(role, name)\n\n# Optional: convert TRUE/FALSE to \"✔\" / \"\"\ncootefoo_members_all_display &lt;- cootefoo_members_all %&gt;%\n  mutate(across(FILAH:JOURNALIST, ~ ifelse(.x, \"✔\", \"\")))\n\n# View arranged table\ncootefoo_members_all_display\n\n# A tibble: 6 × 5\n  name            role            FILAH TROUT JOURNALIST\n  &lt;chr&gt;           &lt;fct&gt;           &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     \n1 Seal            Committee Chair \"✔\"   ✔     ✔         \n2 Ed Helpsford    Vice Chair      \"\"    ✔     ✔         \n3 Teddy Goldstein Treasurer       \"\"    ✔     ✔         \n4 Carol Limpet    Member          \"✔\"   ✔     ✔         \n5 Simone Kat      Member          \"✔\"   ✔     ✔         \n6 Tante Titan     Member          \"\"    ✔     ✔         \n\n\n\n\n\n\n\n\n\nInsights — COOTEFOO Member Dataset Representation\n\n\n\nAll six COOTEFOO members are present in the JOURNALIST dataset, confirming its completeness. The TROUT dataset also includes all members, while FILAH is missing Ed Helpsford, Teddy Goldstein, and Tante Titan — all of whom hold senior or relevant committee positions. We should explore and investigate further\n\n\n\n# Step 1: Get full list of COOTEFOO members from journalist\nall_members &lt;- journalist_nodes %&gt;%\n  filter(!is.na(role)) %&gt;%\n  pull(name)\n\n# Step 2: Analyze participation and sentiment\nmember_stats &lt;- journalist_edges %&gt;%\n  filter(role == \"participant\", target %in% all_members | source %in% all_members) %&gt;%\n  mutate(member = if_else(target %in% all_members, target, source)) %&gt;%\n  group_by(member) %&gt;%\n  summarise(\n    n = n(),  # participation count\n    avg_sentiment = mean(sentiment, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(n))\n\n# View result\nmember_stats\n\n# A tibble: 6 × 3\n  member              n avg_sentiment\n  &lt;chr&gt;           &lt;int&gt;         &lt;dbl&gt;\n1 Tante Titan        54         0.819\n2 Simone Kat         45         0.469\n3 Teddy Goldstein    22         0.344\n4 Carol Limpet       21         0.655\n5 Ed Helpsford       20         0.7  \n6 Seal               12         0.108\n\n\n\nggplot(member_stats, aes(x = reorder(member, avg_sentiment), y = avg_sentiment, fill = n)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"COOTEFOO Members: Sentiment vs. Activity\",\n    x = \"Member\",\n    y = \"Average Sentiment\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Step 1: Get full member list from JOURNALIST\ncootefoo_members &lt;- journalist_nodes %&gt;%\n  filter(!is.na(role)) %&gt;%\n  pull(name) %&gt;%\n  unique()\n\n# Step 2: Function to extract member activity from any dataset\nget_member_stats &lt;- function(edges, dataset_name) {\n  edges %&gt;%\n    filter(role == \"participant\", source %in% cootefoo_members | target %in% cootefoo_members) %&gt;%\n    mutate(member = if_else(source %in% cootefoo_members, source, target)) %&gt;%\n    group_by(member) %&gt;%\n    summarise(\n      n = n(),\n      avg_sentiment = mean(sentiment, na.rm = TRUE),\n      dataset = dataset_name\n    )\n}\n\n# Step 3: Apply to all three datasets\nfilah_stats &lt;- get_member_stats(filah_edges, \"FILAH\")\ntrout_stats &lt;- get_member_stats(trout_edges, \"TROUT\")\njournalist_stats &lt;- get_member_stats(journalist_edges, \"JOURNALIST\")\n\n# Combine results\nall_member_stats &lt;- bind_rows(filah_stats, trout_stats, journalist_stats)\n\n# Step 4: Plotting\nlibrary(ggplot2)\n\nggplot(all_member_stats, aes(x = reorder(member, avg_sentiment), y = avg_sentiment, fill = dataset)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(\n    title = \"COOTEFOO Member Sentiment by Dataset\",\n    x = \"Member\",\n    y = \"Average Sentiment\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#cootefoo-member-list",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#cootefoo-member-list",
    "title": "Take-home Exercise 2",
    "section": "5.4 COOTEFOO Member List",
    "text": "5.4 COOTEFOO Member List\nNext, we will examine the list of Name and Role variables that are present in each dataset to see the involvement of the COOTEFOO members, with the code below:\n\n\nShow the code\n\n\n# Set role hierarchy for custom ordering\nrole_order &lt;- c(\"Committee Chair\", \"Vice Chair\", \"Treasurer\", \"Member\")\n\n# Combine and pivot the dataset\ncootefoo_members_all &lt;- bind_rows(\n  filah_nodes %&gt;% filter(!is.na(role)) %&gt;% mutate(source = \"FILAH\"),\n  trout_nodes %&gt;% filter(!is.na(role)) %&gt;% mutate(source = \"TROUT\"),\n  journalist_nodes %&gt;% filter(!is.na(role)) %&gt;% mutate(source = \"JOURNALIST\")\n) %&gt;%\n  distinct(name, role, source) %&gt;%\n  mutate(present = TRUE) %&gt;%\n  pivot_wider(\n    names_from = source,\n    values_from = present,\n    values_fill = FALSE\n  ) %&gt;%\n  mutate(role = factor(role, levels = role_order)) %&gt;%\n  arrange(role, name)\n\n# convert TRUE/FALSE to \"✔\" / \"\"\ncootefoo_members_all_display &lt;- cootefoo_members_all %&gt;%\n  mutate(across(FILAH:JOURNALIST, ~ ifelse(.x, \"✔\", \"\")))\n\n# View arranged table\ncootefoo_members_all_display\n\n# A tibble: 6 × 5\n  name            role            FILAH TROUT JOURNALIST\n  &lt;chr&gt;           &lt;fct&gt;           &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     \n1 Seal            Committee Chair \"✔\"   ✔     ✔         \n2 Ed Helpsford    Vice Chair      \"\"    ✔     ✔         \n3 Teddy Goldstein Treasurer       \"\"    ✔     ✔         \n4 Carol Limpet    Member          \"✔\"   ✔     ✔         \n5 Simone Kat      Member          \"✔\"   ✔     ✔         \n6 Tante Titan     Member          \"\"    ✔     ✔         \n\n\n\n\n\n\n\n\n\nInsights — COOTEFOO Member Dataset Representation\n\n\n\nAll six COOTEFOO members are present in the JOURNALIST dataset, confirming its completeness. The TROUT dataset also includes all members, while FILAH is missing Ed Helpsford, Teddy Goldstein, and Tante Titan — all of whom hold senior or relevant committee positions. We should explore and investigate further."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Draft2.html",
    "href": "Take-home_Ex/Take-home_Ex_2/Draft2.html",
    "title": "Draft2",
    "section": "",
    "text": "Show the code\npacman::p_load(\n  tidyverse,     \n  jsonlite,       \n  tidygraph,      \n  ggraph,         \n  visNetwork,     \n  SmartEDA,      \n  lubridate,   \n  ggforce,        \n  plotly,\n  skimr,\n  ggrepel\n)\n\n\n#Import JSON\n\ntrout     &lt;- fromJSON(\"data/TROUT.json\")\nfilah     &lt;- fromJSON(\"data/FILAH.json\")\njournalist&lt;- fromJSON(\"data/journalist.json\")\n\n#Extract Node\n\ntrout_nodes  &lt;- as_tibble(trout$nodes)\ntrout_edges  &lt;- as_tibble(trout$links)\nfilah_nodes  &lt;- as_tibble(filah$nodes)\nfilah_edges  &lt;- as_tibble(filah$links)\njour_nodes   &lt;- as_tibble(journalist$nodes)\njour_edges   &lt;- as_tibble(journalist$links)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Draft2.html#bias-computation",
    "href": "Take-home_Ex/Take-home_Ex_2/Draft2.html#bias-computation",
    "title": "Draft2",
    "section": "Bias Computation",
    "text": "Bias Computation\n\n# Step 10: Helper to compute average sentiment (“bias”) per person\ncompute_bias &lt;- function(nodes, edges) {\n  # 1. Identify person nodes\n  people &lt;- nodes %&gt;%\n    filter(type == \"entity.person\") %&gt;%\n    select(person = id, name)\n\n  # 2. Keep only edges with valid numeric sentiment\n  edges2 &lt;- edges %&gt;%\n    filter(!is.na(sentiment)) %&gt;%\n    mutate(sentiment = as.numeric(sentiment))\n\n  # 3. Pivot both endpoints into one column\n  sent_long &lt;- edges2 %&gt;%\n    pivot_longer(\n      cols      = c(from, to),\n      names_to  = \"endpoint\",\n      values_to = \"person\"\n    ) %&gt;%\n    filter(person %in% people$person)\n\n  # 4. Compute mean sentiment and count per person\n  sent_long %&gt;%\n    group_by(person) %&gt;%\n    summarise(\n      n_edges  = n(),\n      bias_avg = mean(sentiment),\n      .groups  = \"drop\"\n    ) %&gt;%\n    left_join(people, by = \"person\")\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Draft2.html#compute-bias-scores-for-trout-and-filah",
    "href": "Take-home_Ex/Take-home_Ex_2/Draft2.html#compute-bias-scores-for-trout-and-filah",
    "title": "Draft2",
    "section": "Compute bias scores for TROUT and FILAH",
    "text": "Compute bias scores for TROUT and FILAH\n\n# Step 11a: Prepare per‐source edges with from/to naming\ntrout_edges_bias &lt;- trout_edges_clean  %&gt;% rename(from = source, to = target)\nfilah_edges_bias &lt;- filah_edges_clean  %&gt;% rename(from = source, to = target)\n\n# Step 11: Compute per-member bias in each advocacy dataset\ntrout_bias &lt;- compute_bias(trout_nodes, trout_edges_bias)\nfilah_bias &lt;- compute_bias(filah_nodes, filah_edges_bias)\n\n# Quick peek at the results\ntrout_bias %&gt;% slice_max(order_by = bias_avg, n = 5)\n\n# A tibble: 3 × 4\n  person          n_edges bias_avg name           \n  &lt;chr&gt;             &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 Ed Helpsford         20    0.7   Ed Helpsford   \n2 Teddy Goldstein      16    0.344 Teddy Goldstein\n3 Seal                 12    0.108 Seal           \n\nfilah_bias %&gt;% slice_min(order_by = bias_avg, n = 5)\n\n# A tibble: 3 × 4\n  person       n_edges bias_avg name        \n  &lt;chr&gt;          &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 Seal              12    0.108 Seal        \n2 Simone Kat        42    0.469 Simone Kat  \n3 Carol Limpet      21    0.655 Carol Limpet"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Draft2.html#visualise-the-distribution-of-bias-scores",
    "href": "Take-home_Ex/Take-home_Ex_2/Draft2.html#visualise-the-distribution-of-bias-scores",
    "title": "Draft2",
    "section": "Visualise the distribution of bias scores",
    "text": "Visualise the distribution of bias scores\n\ndensity plot\n\n# Step 12: Distribution of member bias in each dataset\nlibrary(ggplot2)\n\n# Combine for plotting\nbias_all &lt;- bind_rows(\n  trout_bias %&gt;% mutate(dataset = \"TROUT\"),\n  filah_bias %&gt;% mutate(dataset = \"FILAH\")\n)\n\nggplot(bias_all, aes(x = bias_avg, fill = dataset)) +\n  geom_density(alpha = 0.6) +\n  scale_x_continuous(limits = c(-1, 1)) +\n  scale_fill_manual(values = c(TROUT = \"#1f78b4\", FILAH = \"#33a02c\")) +\n  labs(\n    title = \"Distribution of COOTEFOO Member Bias in TROUT vs FILAH\",\n    x     = \"Average sentiment (–1 = fishing bias, +1 = tourism bias)\",\n    y     = \"Density\",\n    fill  = \"Dataset\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nHighlight the Top ±5 Most Extreme Members\n\n# Step 13: Bar charts of top ±5 extremes\n\nlibrary(forcats)\n\n# Helper to extract extremes\ntop_extremes &lt;- function(df, n = 5) {\n  df %&gt;%\n    arrange(desc(bias_avg)) %&gt;% slice_head(n = n) %&gt;%\n    bind_rows(df %&gt;% arrange(bias_avg) %&gt;% slice_head(n = n)) %&gt;%\n    mutate(direction = if_else(bias_avg &gt; 0, \"Tourism\", \"Fishing\"))\n}\n\n# Plot function\nplot_extremes &lt;- function(df, title, fill_vals) {\n  df %&gt;%\n    mutate(name = fct_reorder(name, bias_avg)) %&gt;%\n    ggplot(aes(x = name, y = bias_avg, fill = direction)) +\n    geom_col() +\n    coord_flip() +\n    scale_y_continuous(limits = c(-1, 1)) +\n    scale_fill_manual(values = fill_vals) +\n    labs(title = title, x = \"Member\", y = \"Average sentiment\") +\n    theme_light() +\n    theme(legend.position = \"none\")\n}\n\n\n\nTROUT Extreme\n\nplot_extremes(\n  top_extremes(trout_bias),\n  title     = \"TROUT: Top ±5 Member Biases\",\n  fill_vals = c(Tourism = \"#e31a1c\", Fishing = \"#348ABD\")\n)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\n\nFILAH Extreme\n\nplot_extremes(\n  top_extremes(filah_bias),\n  title     = \"FILAH: Top ±5 Member Biases\",\n  fill_vals = c(Tourism = \"#e31a1c\", Fishing = \"#348ABD\")\n)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\nBoth advocacy datasets skew positive\n\nThe density plots show TROUT’s bias scores clustered around +0.3 – +0.8 and FILAH’s around +0.4 – +0.9.\nNeither set contains a sizeable fishing-leaning (negative) mass.\n\nTop ±5 extremes are almost all tourism\n\nTROUT’s strongest voices—Ed Helpsford and Teddy Goldstein—both score near +0.9; only Seal dips modestly below zero.\nFILAH’s top advocates—Simone Kat (+0.95) and Carol Limpet (+0.65)—are likewise almost purely tourism-focused; again only Seal shows any slight fishing bias.\n\nAccusations unsupported by their own data\n\nTROUT’s claim of fishing-industry favoritism is contradicted: their own records are overwhelmingly pro-tourism.\nFILAH’s charge of anti-fishing bias similarly finds no support: their dataset also tilts strongly toward tourism."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Draft2.html#compute-centrality-community",
    "href": "Take-home_Ex/Take-home_Ex_2/Draft2.html#compute-centrality-community",
    "title": "Draft2",
    "section": "Compute centrality & community",
    "text": "Compute centrality & community\n\n#── Q2.1 Build combined nodes & edges ────────────────────────────────────────────\ncombined_nodes &lt;- bind_rows(\n  trout_nodes  %&gt;% mutate(source_dataset = \"TROUT\"),\n  filah_nodes  %&gt;% mutate(source_dataset = \"FILAH\"),\n  jour_nodes   %&gt;% mutate(source_dataset = \"JOURNALIST\")\n) %&gt;% distinct(id, .keep_all = TRUE)\n\ncombined_edges &lt;- bind_rows(\n  trout_edges_clean  %&gt;% mutate(source_dataset = \"TROUT\"),\n  filah_edges_clean  %&gt;% mutate(source_dataset = \"FILAH\"),\n  jour_edges_clean   %&gt;% mutate(source_dataset = \"JOURNALIST\")\n) %&gt;%\n  rename(from = source, to = target) %&gt;%\n  filter(from %in% combined_nodes$id, to %in% combined_nodes$id)\n\n\n#── Q2.2 Build graph & compute metrics (incl. bias) ─────────────────────────────\nlibrary(tidygraph)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Helper to compute bias_avg per node\nbias_lookup &lt;- compute_bias(combined_nodes, combined_edges)\n\ncombined_graph &lt;- tbl_graph(\n  nodes    = combined_nodes,\n  edges    = combined_edges,\n  directed = TRUE,\n  node_key = \"id\"\n) %&gt;%\n  activate(nodes) %&gt;%\n  left_join(bias_lookup %&gt;% select(person, bias_avg), by = c(\"id\" = \"person\")) %&gt;%\n  mutate(\n    degree   = centrality_degree(mode = \"all\"),\n    cluster  = group_infomap(),               \n    bias_cat = if_else(bias_avg &gt;= 0, \"tourism\", \"fishing\")\n  )\n\n\n#── Q2.3 Plot distribution of combined bias ──────────────────────────────────────\nlibrary(ggplot2)\n\nggplot(bias_lookup, aes(x = bias_avg)) +\n  geom_density(fill = \"#66c2a5\", alpha = 0.6) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  labs(\n    title = \"Bias Scores Across the Full COOTEFOO Dataset\",\n    x     = \"Average sentiment (–1=fishing, +1=tourism)\",\n    y     = \"Density\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nset.seed(42)\nggraph(combined_graph, layout = \"fr\") +\n  geom_edge_link(aes(colour = source_dataset), alpha = 0.3) +\n  geom_node_point(aes(size = degree, colour = bias_cat), alpha = 0.8) +\n  geom_node_text(aes(label = name), repel = TRUE, size = 2) +\n  scale_edge_colour_manual(values = c(\n    TROUT      = \"#1f78b4\",\n    FILAH      = \"#33a02c\",\n    JOURNALIST = \"#e31a1c\"\n  )) +\n  scale_colour_manual(\n    values      = c(fishing = \"#348ABD\", tourism = \"#E24A33\"),\n    na.value    = \"grey80\",\n    na.translate= FALSE\n  ) +\n  scale_size(range = c(2, 8)) +\n  labs(\n    title       = \"Combined COOTEFOO Network\",\n    edge_colour = \"Record Source\",\n    colour      = \"Member Bias\",\n    size        = \"Node Degree\"\n  ) +\n  theme_void()\n\nWarning: Removed 734 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 692 rows containing missing values or values outside the scale range\n(`geom_text_repel()`).\n\n\nWarning: ggrepel: 27 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n\nWhen we merge TROUT, FILAH and the journalist’s extra records into a single knowledge graph and examine both the bias‐score density and the force-directed network, we see:\nStrong Pro-Tourism Bias Across the Board\n\nThe density of combined bias scores lies almost entirely above zero (−1 = fishing, +1 = tourism), peaking around +0.6–+0.8.\nThis confirms that, in the full dataset, the committee as a whole spends far more time on tourism-related activities than on fishing.\n\nCentralisation of Tourism-Leaning Members\n\nIn the network layout, the largest nodes (highest degree) are predominantly tourism-leaning (red).\nThese core actors drive the majority of meetings, site visits and plans, indicating they set the agenda.\n\nPeripheral Fishing Voices\n\nFishing-leaning members (blue) appear only on the fringes, with low degree and few connections.\nSeal remains the principal fishing advocate but is marginalised in the overall network.\n\nUnified Record Sources\n\nTROUT and FILAH edges (blue and green) overlap heavily, and the journalist’s supplemental edges (red) fill in gaps but still tie into the same tourism-centred core.\nThere are no distinct sub-communities of fishing activity; all sources reinforce the tourism cluster."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Draft2.html#comparison-table-of-bias-score",
    "href": "Take-home_Ex/Take-home_Ex_2/Draft2.html#comparison-table-of-bias-score",
    "title": "Draft2",
    "section": "Comparison Table of Bias Score",
    "text": "Comparison Table of Bias Score\n\nlibrary(dplyr)\n\nbias_comparison &lt;- trout_bias %&gt;% \n  select(person, bias_trout = bias_avg) %&gt;%\n  full_join(\n    filah_bias %&gt;% select(person, bias_filah = bias_avg),\n    by = \"person\"\n  ) %&gt;%\n  full_join(\n    bias_lookup %&gt;% select(person, bias_combined = bias_avg),\n    by = \"person\"\n  ) %&gt;%\n  # attach human‐readable names\n  left_join(\n    combined_nodes %&gt;% \n      filter(type == \"entity.person\") %&gt;% \n      select(person = id, name),\n    by = \"person\"\n  ) %&gt;%\n  filter(!is.na(name))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Draft2.html#visualise-shifts-with-a-dumbbell-chart",
    "href": "Take-home_Ex/Take-home_Ex_2/Draft2.html#visualise-shifts-with-a-dumbbell-chart",
    "title": "Draft2",
    "section": "Visualise shifts with a “dumbbell” chart",
    "text": "Visualise shifts with a “dumbbell” chart\n\nlibrary(ggplot2)\nlibrary(forcats)\n\n# Prepare for TROUT comparison\ndumbbell_trout &lt;- bias_comparison %&gt;%\n  filter(!is.na(bias_trout)) %&gt;%\n  select(name, Original = bias_trout, Combined = bias_combined) %&gt;%\n  arrange(Original) %&gt;%\n  mutate(name = factor(name, levels = name)) %&gt;%\n  pivot_longer(c(Original, Combined), \n               names_to = \"Dataset\", values_to = \"Bias\")\n\n# Plot\nggplot(dumbbell_trout, aes(y = name, x = Bias, colour = Dataset)) +\n  geom_line(aes(group = name), colour = \"grey70\") +\n  geom_point(size = 3) +\n  scale_colour_manual(values = c(Original = \"#1f78b4\", Combined = \"#33a02c\")) +\n  labs(\n    title = \"TROUT Bias: Original vs Combined\",\n    x     = \"Average sentiment (–1 = fishing, +1 = tourism)\",\n    y     = \"Member\",\n    colour= \"\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Draft2.html#summary",
    "href": "Take-home_Ex/Take-home_Ex_2/Draft2.html#summary",
    "title": "Draft2",
    "section": "Summary",
    "text": "Summary\n\nbias_comparison %&gt;%\n  filter(!is.na(bias_trout)) %&gt;%\n  transmute(\n    Member      = name,\n    `Original (TROUT)`  = round(bias_trout, 3),\n    `Combined`          = round(bias_combined, 3),\n    `Delta`             = round(bias_combined - bias_trout, 3)\n  ) %&gt;%\n  arrange(desc(Delta)) %&gt;%\n  knitr::kable(digits = 3)\n\n\n\n\nMember\nOriginal (TROUT)\nCombined\nDelta\n\n\n\n\nEd Helpsford\n0.700\n0.700\n0\n\n\nSeal\n0.108\n0.108\n0\n\n\nTeddy Goldstein\n0.344\n0.344\n0\n\n\n\n\n\n\nInsights\nWhen we compare each member’s original bias in TROUT (and likewise in FILAH) to their bias in the fully combined dataset, we find no change:\n\nEvery member’s “Combined” score is exactly the same as their “Original” score—∆ = 0.\n\nConclusion:\nAdding the journalist’s extra records neither strengthens nor weakens TROUT’s (or FILAH’s) original accusations. In all cases the fuller dataset leaves each member’s measured bias unchanged, so those initial claims are unchanged when viewed in context of the complete data."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Draft2.html#prepare-the-nodes-edges-for-visnetwork",
    "href": "Take-home_Ex/Take-home_Ex_2/Draft2.html#prepare-the-nodes-edges-for-visnetwork",
    "title": "Draft2",
    "section": "Prepare the nodes & edges for visNetwork",
    "text": "Prepare the nodes & edges for visNetwork\n\n#–– 4.1 Data Prep \n\n# First, join bias_avg into combined_nodes so each row has its own bias\nnodes_vn &lt;- combined_nodes %&gt;%\n  # 1. bring in bias_lookup cleanly\n  left_join(\n    bias_lookup %&gt;% select(person, bias_avg),\n    by = c(\"id\" = \"person\")\n  ) %&gt;%\n  # 2. then transmute\n  transmute(\n    id    = id,\n    label = coalesce(name, id),\n    group = if_else(type == \"entity.person\", \"Member\", \"Event\"),\n    title = if_else(\n      group == \"Member\",\n      paste0(\"&lt;b&gt;\", label, \"&lt;/b&gt;&lt;br&gt;Bias: \", round(bias_avg, 2)),\n      label\n    )\n  )\n\n# And edges_vn as before\nedges_vn &lt;- combined_edges %&gt;%\n  group_by(from, to, source_dataset) %&gt;%\n  summarise(weight = n(), .groups = \"drop\") %&gt;%\n  filter(from != to) %&gt;%\n  mutate(\n    color = case_when(\n      source_dataset == \"TROUT\"      ~ \"#1f78b4\",\n      source_dataset == \"FILAH\"      ~ \"#33a02c\",\n      source_dataset == \"JOURNALIST\" ~ \"#e31a1c\",\n      TRUE                            ~ \"grey80\"\n    ),\n    title = paste0(source_dataset, \" (n=\", weight, \")\")\n  ) %&gt;%\n  select(from, to, weight, color, title)\n\n\n#–– 4.2 Working with layout -------------------------------------------\n\nlibrary(visNetwork)\n\nvisNetwork(nodes_vn, edges_vn, height = \"600px\", width = \"100%\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\")\n\n\n\n\n\n\nvisNetwork(nodes_vn, edges_vn) %&gt;%\n  # force‐directed layout via igraph\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  # auto‐colour by `group`, no need to override colour\n  # add legend for those groups\n  visLegend() %&gt;%\n  # freeze the layout\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n#–– 4.4 Working with visual attributes – Edges ------------------------\nvisNetwork(nodes_vn, edges_vn) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  # draw arrowheads and smooth the curves\n  visEdges(\n    arrows = \"to\",\n    smooth = list(enabled = TRUE, type = \"curvedCW\")\n  ) %&gt;%\n  # legend for your edge‐colour mapping (if you manually set edge colors)\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n#–– 4.5 Interactivity --------------------------------------------------\nmember_ids &lt;- nodes_vn %&gt;% \n  filter(group == \"Member\") %&gt;% \n  pull(id)\n\nvisNetwork(nodes_vn, edges_vn) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(\n    highlightNearest   = list(enabled = TRUE, degree = 1, hover = TRUE),\n    nodesIdSelection   = list(\n      enabled   = TRUE,\n      useLabels = TRUE,\n      values    = member_ids,\n      main      = \"Select a COOTEFOO member\"\n    )\n  ) %&gt;%\n  visLegend(\n    addNodes = data.frame(\n      label = c(\"TROUT\", \"FILAH\", \"JOURNALIST\"),\n      shape = \"square\",\n      color = c(\"#1f78b4\", \"#33a02c\", \"#e31a1c\"),\n      stringsAsFactors = FALSE\n    ),\n    useGroups = FALSE\n  ) %&gt;%\n  visLayout(randomSeed = 42)\n\n\n\n\n\n\n#── P1: Records‐per‐Source Bar Chart ──────────────────────────────────\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nseal_summary &lt;- combined_edges %&gt;%\n  filter(from == \"Seal\" | to == \"Seal\") %&gt;%\n  count(source_dataset, name = \"n\") %&gt;%\n  complete(source_dataset = c(\"TROUT\",\"FILAH\",\"JOURNALIST\"), fill = list(n=0))\n\nggplot(seal_summary, aes(x = source_dataset, y = n, fill = source_dataset)) +\n  geom_col() +\n  scale_fill_manual(values = c(\n    TROUT      = \"#1f78b4\",\n    FILAH      = \"#33a02c\",\n    JOURNALIST = \"#e31a1c\"\n  )) +\n  labs(\n    title = \"Seal: Records per Source\",\n    x     = \"Dataset\",\n    y     = \"Count\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n#── P2: Seal’s 1‐Step Ego‐Network ────────────────────────────────────\n\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(igraph)\n\n\nAttaching package: 'igraph'\n\n\nThe following object is masked from 'package:plotly':\n\n    groups\n\n\nThe following object is masked from 'package:tidygraph':\n\n    groups\n\n\nThe following objects are masked from 'package:lubridate':\n\n    %--%, union\n\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\nlibrary(ggplot2)\n\n# build the ego‐edge table\nseal_edges &lt;- combined_edges %&gt;%\n  filter(from == \"Seal\" | to == \"Seal\") %&gt;%\n  count(from, to, source_dataset, name = \"weight\")\n\n# build the ego‐node table\nseal_nodes &lt;- tibble(id = unique(c(seal_edges$from, seal_edges$to))) %&gt;%\n  left_join(combined_nodes %&gt;% select(id, name), by = \"id\") %&gt;%\n  transmute(\n    id,\n    label = coalesce(name, id),\n    type  = if_else(id == \"Seal\", \"Selected\", \"Neighbour\")\n  )\n\n# create the graph\nseal_graph &lt;- tbl_graph(nodes = seal_nodes, edges = seal_edges, directed = TRUE)\n\n# plot\nset.seed(2025)\nggraph(seal_graph, layout = \"star\") +\n  geom_edge_link(aes(width = weight, colour = source_dataset),\n                 alpha = 0.8,\n                 arrow = arrow(type = \"closed\", length = unit(2, \"mm\"))) +\n  scale_edge_width(range = c(0.2, 1.5), guide = guide_legend(\"Count\")) +\n  scale_edge_colour_manual(name = \"Record Source\", values = c(\n    TROUT      = \"#1f78b4\",\n    FILAH      = \"#33a02c\",\n    JOURNALIST = \"#e31a1c\"\n  )) +\n  geom_node_point(aes(fill = type), shape = 21, size = 6, colour = \"black\") +\n  scale_fill_manual(values = c(Selected = \"firebrick\", Neighbour = \"steelblue\"),\n                    guide = FALSE) +\n  geom_node_text(aes(filter = (id == \"Seal\"), label = label),\n                 repel = TRUE, fontface = \"bold\", size = 4) +\n  theme_void() +\n  labs(title = \"Seal’s Ego-Network\")\n\nWarning: The `guide` argument in `scale_*()` cannot be `FALSE`. This was deprecated in\nggplot2 3.3.4.\nℹ Please use \"none\" instead.\n\n\n\n\n\n\n\n\n\nInsight\nBy examining Seal’s activity through both a count plot and a ego-network, we see that TROUT’s dataset captures only a small fraction of his true engagements. TROUT recorded roughly 13 of Seal’s 79 total events, whereas FILAH and the independent journalist each logged ≈ 66. Visually, Seal’s ego-network fans out almost completely in green (FILAH) and red (journalist) spokes, with only a thin blue wedge for TROUT. Thus, any characterisation of Seal’s “bias” or level of involvement based solely on TROUT’s data is severely misleading; the fuller, combined record reveals a far more active and tourism-focused set of activities than TROUT alone would suggest."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#dataset-overview",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#dataset-overview",
    "title": "Take-home Exercise 2",
    "section": "4.4 Dataset Overview",
    "text": "4.4 Dataset Overview\nBefore proceeding, we shall take a look at the edges and nodes data overview using the skim function, with the code below.\n\n\nShow the code\n\n\nFILAHTROUTJOURNALIST\n\n\n\nskim(filah_edges)\n\n\nData summary\n\n\nName\nfilah_edges\n\n\nNumber of rows\n765\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nlist\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrole\n354\n0.54\n4\n11\n0\n6\n0\n\n\nsource\n0\n1.00\n6\n82\n0\n300\n0\n\n\ntarget\n0\n1.00\n3\n82\n0\n195\n0\n\n\nreason\n656\n0.14\n23\n152\n0\n28\n0\n\n\nstatus\n712\n0.07\n7\n11\n0\n4\n0\n\n\ntime\n600\n0.22\n19\n19\n0\n160\n0\n\n\n\nVariable type: list\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn_unique\nmin_length\nmax_length\n\n\n\n\nindustry\n0\n1\n7\n0\n2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nkey\n0\n1.00\n0.00\n0.00\n0\n0.0\n0.0\n0\n0\n▁▁▇▁▁\n\n\nsentiment\n656\n0.14\n0.43\n0.63\n-1\n0.1\n0.5\n1\n1\n▂▁▃▂▇\n\n\n\n\n\n\n\n\nskim(trout_edges)\n\n\nData summary\n\n\nName\ntrout_edges\n\n\nNumber of rows\n378\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nlist\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrole\n94\n0.75\n4\n11\n0\n6\n0\n\n\nsource\n0\n1.00\n7\n73\n0\n103\n0\n\n\ntarget\n0\n1.00\n3\n73\n0\n133\n0\n\n\nreason\n296\n0.22\n34\n102\n0\n26\n0\n\n\nstatus\n342\n0.10\n7\n11\n0\n5\n0\n\n\ntime\n302\n0.20\n19\n19\n0\n56\n0\n\n\n\nVariable type: list\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn_unique\nmin_length\nmax_length\n\n\n\n\nindustry\n0\n1\n6\n0\n2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nkey\n0\n1.00\n0.0\n0.00\n0\n0\n0.0\n0\n0\n▁▁▇▁▁\n\n\nsentiment\n296\n0.22\n0.4\n0.65\n-1\n0\n0.5\n1\n1\n▁▂▅▂▇\n\n\n\n\n\n\n\n\nskim(journalist_edges)\n\n\nData summary\n\n\nName\njournalist_edges\n\n\nNumber of rows\n2436\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nlist\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrole\n1705\n0.30\n4\n11\n0\n6\n0\n\n\nsource\n0\n1.00\n6\n82\n0\n531\n0\n\n\ntarget\n0\n1.00\n3\n82\n0\n382\n0\n\n\nreason\n2237\n0.08\n23\n152\n0\n42\n0\n\n\nstatus\n2338\n0.04\n7\n11\n0\n5\n0\n\n\ntime\n1073\n0.56\n19\n19\n0\n925\n0\n\n\n\nVariable type: list\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn_unique\nmin_length\nmax_length\n\n\n\n\nindustry\n0\n1\n7\n0\n2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nkey\n0\n1.00\n0.00\n0.00\n0\n0.00\n0.00\n0\n0\n▁▁▇▁▁\n\n\nsentiment\n2237\n0.08\n0.56\n0.57\n-1\n0.25\n0.75\n1\n1\n▁▁▂▃▇\n\n\n\n\n\n\n\n\n\nskim(filah_nodes)\n\n\nData summary\n\n\nName\nfilah_nodes\n\n\nNumber of rows\n396\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n15\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n12\n0.97\n4\n19\n0\n8\n0\n\n\ndate\n195\n0.51\n9\n10\n0\n130\n0\n\n\nlabel\n257\n0.35\n9\n82\n0\n139\n0\n\n\nid\n0\n1.00\n3\n82\n0\n396\n0\n\n\nname\n385\n0.03\n4\n24\n0\n11\n0\n\n\nrole\n393\n0.01\n6\n15\n0\n2\n0\n\n\nshort_topic\n382\n0.04\n11\n23\n0\n14\n0\n\n\nlong_topic\n382\n0.04\n11\n73\n0\n14\n0\n\n\nshort_title\n297\n0.25\n33\n82\n0\n99\n0\n\n\nlong_title\n297\n0.25\n25\n80\n0\n71\n0\n\n\nplan_type\n355\n0.10\n6\n12\n0\n9\n0\n\n\nzone\n325\n0.18\n7\n11\n0\n5\n0\n\n\nzone_detail\n388\n0.02\n4\n10\n0\n3\n0\n\n\nstart\n207\n0.48\n8\n8\n0\n71\n0\n\n\nend\n207\n0.48\n8\n8\n0\n86\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlat\n325\n0.18\n-165.19\n0.63\n-165.96\n-165.68\n-165.59\n-164.53\n-164.34\n▅▆▁▁▇\n\n\nlon\n325\n0.18\n39.38\n0.21\n38.99\n39.26\n39.43\n39.54\n39.67\n▆▁▃▆▇\n\n\n\n\nskim(trout_nodes)\n\n\nData summary\n\n\nName\ntrout_nodes\n\n\nNumber of rows\n164\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n15\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n3\n0.98\n4\n19\n0\n8\n0\n\n\nshort_title\n92\n0.44\n28\n73\n0\n72\n0\n\n\nlong_title\n92\n0.44\n25\n84\n0\n43\n0\n\n\nplan_type\n131\n0.20\n6\n12\n0\n8\n0\n\n\nlabel\n61\n0.63\n7\n73\n0\n103\n0\n\n\nid\n0\n1.00\n3\n73\n0\n164\n0\n\n\ndate\n133\n0.19\n9\n10\n0\n31\n0\n\n\nshort_topic\n150\n0.09\n7\n23\n0\n14\n0\n\n\nlong_topic\n150\n0.09\n11\n73\n0\n14\n0\n\n\nzone\n131\n0.20\n7\n11\n0\n6\n0\n\n\nzone_detail\n146\n0.11\n0\n13\n1\n7\n0\n\n\nname\n133\n0.19\n4\n30\n0\n31\n0\n\n\nrole\n158\n0.04\n6\n15\n0\n4\n0\n\n\nstart\n146\n0.11\n8\n8\n0\n15\n0\n\n\nend\n146\n0.11\n8\n8\n0\n13\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlat\n131\n0.2\n-165.39\n0.59\n-165.96\n-165.88\n-165.60\n-164.58\n-164.34\n▇▅▁▁▅\n\n\nlon\n131\n0.2\n39.36\n0.24\n38.99\n39.10\n39.43\n39.55\n39.67\n▇▁▃▆▇\n\n\n\n\nskim(journalist_nodes)\n\n\nData summary\n\n\nName\njournalist_nodes\n\n\nNumber of rows\n740\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n15\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n19\n0.97\n4\n19\n0\n8\n0\n\n\ndate\n382\n0.48\n8\n10\n0\n159\n0\n\n\nlabel\n515\n0.30\n7\n82\n0\n225\n0\n\n\nid\n0\n1.00\n3\n82\n0\n740\n0\n\n\nname\n692\n0.06\n4\n30\n0\n48\n0\n\n\nrole\n734\n0.01\n6\n15\n0\n4\n0\n\n\nshort_topic\n725\n0.02\n7\n23\n0\n15\n0\n\n\nlong_topic\n725\n0.02\n11\n73\n0\n15\n0\n\n\nshort_title\n565\n0.24\n27\n82\n0\n175\n0\n\n\nlong_title\n565\n0.24\n25\n97\n0\n115\n0\n\n\nplan_type\n666\n0.10\n6\n12\n0\n10\n0\n\n\nzone\n568\n0.23\n7\n11\n0\n6\n0\n\n\nzone_detail\n705\n0.05\n0\n21\n1\n13\n0\n\n\nstart\n398\n0.46\n8\n8\n0\n122\n0\n\n\nend\n398\n0.46\n8\n8\n0\n164\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlat\n568\n0.23\n-165.13\n0.63\n-165.96\n-165.61\n-165.57\n-164.53\n-164.33\n▅▆▁▁▇\n\n\nlon\n568\n0.23\n39.38\n0.20\n38.99\n39.26\n39.42\n39.54\n39.67\n▅▁▃▇▆"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#edges-and-nodes-overview",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#edges-and-nodes-overview",
    "title": "Take-home Exercise 2",
    "section": "4.4 Edges and Nodes Overview",
    "text": "4.4 Edges and Nodes Overview\nBefore proceeding, we shall take a look at the edges and nodes data overview using the skim function, with the code below.\n\n\nShow the code\n\n\nFILAHTROUTJOURNALIST\n\n\n\nskim(filah_edges)\n\n\nData summary\n\n\nName\nfilah_edges\n\n\nNumber of rows\n765\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nlist\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrole\n354\n0.54\n4\n11\n0\n6\n0\n\n\nsource\n0\n1.00\n6\n82\n0\n300\n0\n\n\ntarget\n0\n1.00\n3\n82\n0\n195\n0\n\n\nreason\n656\n0.14\n23\n152\n0\n28\n0\n\n\nstatus\n712\n0.07\n7\n11\n0\n4\n0\n\n\ntime\n600\n0.22\n19\n19\n0\n160\n0\n\n\n\nVariable type: list\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn_unique\nmin_length\nmax_length\n\n\n\n\nindustry\n0\n1\n7\n0\n2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nkey\n0\n1.00\n0.00\n0.00\n0\n0.0\n0.0\n0\n0\n▁▁▇▁▁\n\n\nsentiment\n656\n0.14\n0.43\n0.63\n-1\n0.1\n0.5\n1\n1\n▂▁▃▂▇\n\n\n\n\n\n\n\n\nskim(trout_edges)\n\n\nData summary\n\n\nName\ntrout_edges\n\n\nNumber of rows\n378\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nlist\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrole\n94\n0.75\n4\n11\n0\n6\n0\n\n\nsource\n0\n1.00\n7\n73\n0\n103\n0\n\n\ntarget\n0\n1.00\n3\n73\n0\n133\n0\n\n\nreason\n296\n0.22\n34\n102\n0\n26\n0\n\n\nstatus\n342\n0.10\n7\n11\n0\n5\n0\n\n\ntime\n302\n0.20\n19\n19\n0\n56\n0\n\n\n\nVariable type: list\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn_unique\nmin_length\nmax_length\n\n\n\n\nindustry\n0\n1\n6\n0\n2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nkey\n0\n1.00\n0.0\n0.00\n0\n0\n0.0\n0\n0\n▁▁▇▁▁\n\n\nsentiment\n296\n0.22\n0.4\n0.65\n-1\n0\n0.5\n1\n1\n▁▂▅▂▇\n\n\n\n\n\n\n\n\nskim(journalist_edges)\n\n\nData summary\n\n\nName\njournalist_edges\n\n\nNumber of rows\n2436\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nlist\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrole\n1705\n0.30\n4\n11\n0\n6\n0\n\n\nsource\n0\n1.00\n6\n82\n0\n531\n0\n\n\ntarget\n0\n1.00\n3\n82\n0\n382\n0\n\n\nreason\n2237\n0.08\n23\n152\n0\n42\n0\n\n\nstatus\n2338\n0.04\n7\n11\n0\n5\n0\n\n\ntime\n1073\n0.56\n19\n19\n0\n925\n0\n\n\n\nVariable type: list\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn_unique\nmin_length\nmax_length\n\n\n\n\nindustry\n0\n1\n7\n0\n2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nkey\n0\n1.00\n0.00\n0.00\n0\n0.00\n0.00\n0\n0\n▁▁▇▁▁\n\n\nsentiment\n2237\n0.08\n0.56\n0.57\n-1\n0.25\n0.75\n1\n1\n▁▁▂▃▇\n\n\n\n\n\n\n\n\n\nskim(filah_nodes)\n\n\nData summary\n\n\nName\nfilah_nodes\n\n\nNumber of rows\n396\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n15\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n12\n0.97\n4\n19\n0\n8\n0\n\n\ndate\n195\n0.51\n9\n10\n0\n130\n0\n\n\nlabel\n257\n0.35\n9\n82\n0\n139\n0\n\n\nid\n0\n1.00\n3\n82\n0\n396\n0\n\n\nname\n385\n0.03\n4\n24\n0\n11\n0\n\n\nrole\n393\n0.01\n6\n15\n0\n2\n0\n\n\nshort_topic\n382\n0.04\n11\n23\n0\n14\n0\n\n\nlong_topic\n382\n0.04\n11\n73\n0\n14\n0\n\n\nshort_title\n297\n0.25\n33\n82\n0\n99\n0\n\n\nlong_title\n297\n0.25\n25\n80\n0\n71\n0\n\n\nplan_type\n355\n0.10\n6\n12\n0\n9\n0\n\n\nzone\n325\n0.18\n7\n11\n0\n5\n0\n\n\nzone_detail\n388\n0.02\n4\n10\n0\n3\n0\n\n\nstart\n207\n0.48\n8\n8\n0\n71\n0\n\n\nend\n207\n0.48\n8\n8\n0\n86\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlat\n325\n0.18\n-165.19\n0.63\n-165.96\n-165.68\n-165.59\n-164.53\n-164.34\n▅▆▁▁▇\n\n\nlon\n325\n0.18\n39.38\n0.21\n38.99\n39.26\n39.43\n39.54\n39.67\n▆▁▃▆▇\n\n\n\n\nskim(trout_nodes)\n\n\nData summary\n\n\nName\ntrout_nodes\n\n\nNumber of rows\n164\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n15\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n3\n0.98\n4\n19\n0\n8\n0\n\n\nshort_title\n92\n0.44\n28\n73\n0\n72\n0\n\n\nlong_title\n92\n0.44\n25\n84\n0\n43\n0\n\n\nplan_type\n131\n0.20\n6\n12\n0\n8\n0\n\n\nlabel\n61\n0.63\n7\n73\n0\n103\n0\n\n\nid\n0\n1.00\n3\n73\n0\n164\n0\n\n\ndate\n133\n0.19\n9\n10\n0\n31\n0\n\n\nshort_topic\n150\n0.09\n7\n23\n0\n14\n0\n\n\nlong_topic\n150\n0.09\n11\n73\n0\n14\n0\n\n\nzone\n131\n0.20\n7\n11\n0\n6\n0\n\n\nzone_detail\n146\n0.11\n0\n13\n1\n7\n0\n\n\nname\n133\n0.19\n4\n30\n0\n31\n0\n\n\nrole\n158\n0.04\n6\n15\n0\n4\n0\n\n\nstart\n146\n0.11\n8\n8\n0\n15\n0\n\n\nend\n146\n0.11\n8\n8\n0\n13\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlat\n131\n0.2\n-165.39\n0.59\n-165.96\n-165.88\n-165.60\n-164.58\n-164.34\n▇▅▁▁▅\n\n\nlon\n131\n0.2\n39.36\n0.24\n38.99\n39.10\n39.43\n39.55\n39.67\n▇▁▃▆▇\n\n\n\n\nskim(journalist_nodes)\n\n\nData summary\n\n\nName\njournalist_nodes\n\n\nNumber of rows\n740\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n15\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n19\n0.97\n4\n19\n0\n8\n0\n\n\ndate\n382\n0.48\n8\n10\n0\n159\n0\n\n\nlabel\n515\n0.30\n7\n82\n0\n225\n0\n\n\nid\n0\n1.00\n3\n82\n0\n740\n0\n\n\nname\n692\n0.06\n4\n30\n0\n48\n0\n\n\nrole\n734\n0.01\n6\n15\n0\n4\n0\n\n\nshort_topic\n725\n0.02\n7\n23\n0\n15\n0\n\n\nlong_topic\n725\n0.02\n11\n73\n0\n15\n0\n\n\nshort_title\n565\n0.24\n27\n82\n0\n175\n0\n\n\nlong_title\n565\n0.24\n25\n97\n0\n115\n0\n\n\nplan_type\n666\n0.10\n6\n12\n0\n10\n0\n\n\nzone\n568\n0.23\n7\n11\n0\n6\n0\n\n\nzone_detail\n705\n0.05\n0\n21\n1\n13\n0\n\n\nstart\n398\n0.46\n8\n8\n0\n122\n0\n\n\nend\n398\n0.46\n8\n8\n0\n164\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlat\n568\n0.23\n-165.13\n0.63\n-165.96\n-165.61\n-165.57\n-164.53\n-164.33\n▅▆▁▁▇\n\n\nlon\n568\n0.23\n39.38\n0.20\n38.99\n39.26\n39.42\n39.54\n39.67\n▅▁▃▇▆"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#question-1",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#question-1",
    "title": "Take-home Exercise 2",
    "section": "6.1 Question 1",
    "text": "6.1 Question 1\n\n\n\n\n\n\nThe Question\n\n\n\nBased on the datasets that TROUT & FILAH have provided, use visual analytics to determine if each group’s accusations are supported by their own record set. In other words, develop a visualization to highlight bias (if present) in TROUT & FILAH’s datasets. Is there evidence of bias in the COOTEFOO member actions in either dataset?\n\n\n\n6.1.1 🧭 How Sentiment Is Analyzed\nTo analyze potential bias in each dataset, we extract sentiment scores linked to COOTEFOO members using the participant edges. These scores capture how positively or negatively each member responded to topics associated with Fishing or Tourism.\nHowever, sentiment alone is not enough—context matters. That’s why we also examine the associated industry and reason columns to classify the sentiment into high-level categories:\n\nFishing\nTourism\nOther\n\nThis approach ensures that when a member expresses a positive sentiment, we understand toward what. For example, a +1 score could mean “pro-fishing” in FILAH or “pro-tourism” in TROUT, depending on the topic context. We classify topics accordingly and compute average sentiment scores per member and per dataset.\n\n\n6.1.2 Overall Sentiment - Bias Score Ridgeline\nThis ridgeline chart shows how the aggregate sentiment scores (bias scores) are distributed across the TROUT and FILAH datasets. A score near +1 suggests strong support for tourism, while a score near –1 suggests alignment with fishing interests. We will use blue colour to represent FILAH and yellow colour for TROUT.\n\n\nShow the code\n\n\n# Define COOTEFOO member names\ncootefoo_members &lt;- c(\"Seal\", \"Simone Kat\", \"Carol Limpet\", \n                      \"Teddy Goldstein\", \"Ed Helpsford\", \"Tante Titan\")\n\n# Function to classify topic by industry\nassign_topic_category &lt;- function(industry, reason) {\n  industry &lt;- tolower(industry)\n  reason   &lt;- tolower(reason)\n\n  case_when(\n    str_detect(reason, \"housing\") ~ \"Other\",\n    str_detect(industry, \"tourism|tourist|wharf|travel|harbor|marina|port\") |\n      str_detect(reason, \"tourism|tourist|wharf|travel|harbor|marina|port\") ~ \"Tourism\",\n    str_detect(industry, \"fishing|vessel|dock|crane|fish\") |\n      str_detect(reason, \"fishing|vessel|dock|crane|fish\") ~ \"Fishing\",\n    TRUE ~ \"Other\"\n  )\n}\n\n# Ensure edge tables exist\nfilah_edges &lt;- as_tibble(filah$links)\ntrout_edges &lt;- as_tibble(trout$links)\n\n# Compute FILAH sentiment by member\nfilah_sentiment_by_member &lt;- filah_edges %&gt;%\n  filter(role == \"participant\",\n         !is.na(sentiment),\n         target %in% cootefoo_members,\n         !is.na(industry),\n         industry != \"character(0)\",\n         industry != \"\") %&gt;%\n  mutate(\n    industry_clean = str_replace_all(industry, \"c\\\\(|\\\\)|\\\"\", \"\"),\n    industry_group = assign_topic_category(industry_clean, reason)\n  ) %&gt;%\n  group_by(target) %&gt;%\n  summarise(avg_sentiment = mean(sentiment, na.rm = TRUE), .groups = \"drop\")\n\n# Compute TROUT sentiment by member\ntrout_sentiment_by_member &lt;- trout_edges %&gt;%\n  filter(role == \"participant\",\n         !is.na(sentiment),\n         target %in% cootefoo_members,\n         !is.na(industry),\n         industry != \"character(0)\",\n         industry != \"\") %&gt;%\n  mutate(\n    industry_clean = str_replace_all(industry, \"c\\\\(|\\\\)|\\\"\", \"\"),\n    industry_group = assign_topic_category(industry_clean, reason)\n  ) %&gt;%\n  group_by(target) %&gt;%\n  summarise(avg_sentiment = mean(sentiment, na.rm = TRUE), .groups = \"drop\")\n\n# Combine both datasets\nbias_all &lt;- bind_rows(\n  filah_sentiment_by_member %&gt;%\n    rename(name = target, bias_avg = avg_sentiment) %&gt;%\n    mutate(dataset = \"FILAH\"),\n  \n  trout_sentiment_by_member %&gt;%\n    rename(name = target, bias_avg = avg_sentiment) %&gt;%\n    mutate(dataset = \"TROUT\")\n)\n\n# Filter to only COOTEFOO members\nbias_all_filtered &lt;- bias_all %&gt;%\n  filter(name %in% cootefoo_members)\n\n# Plot ridgeline chart of overall sentiment\nggplot(bias_all_filtered, aes(x = bias_avg, y = fct_rev(dataset), fill = dataset)) +\n  geom_density_ridges(\n    alpha = 0.7, \n    scale = 0.95, \n    color = \"white\",\n    size = 0.3\n  ) +\n  scale_fill_manual(values = c(\"TROUT\" = \"#ffcc00\", \"FILAH\" = \"#1f78b4\")) +\n  scale_x_continuous(\n    limits = c(-1, 1),\n    breaks = c(-1, 0, 1),\n    labels = c(\"Fishing Bias\", \"Neutral\", \"Tourism Bias\")\n  ) +\n  labs(\n    title = \"Overall COOTEFOO Member Sentiment — FILAH vs TROUT\",\n    subtitle = \"Average sentiment score distribution by dataset\",\n    x = \"Bias Score\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_text(face = \"bold\"),\n    plot.title = element_text(face = \"bold\"),\n    plot.subtitle = element_text(margin = margin(b = 10))\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nFILAH member sentiments are centered around neutral-to-positive, with a slight lean toward tourism despite the group’s fishing-oriented stance. TROUT shows more polarized sentiment, including a member with strong pro-fishing sentiment (unexpected for a tourism advocacy group). This suggests each dataset presents a selective narrative that may not fully align with their stated agenda.\n\n\nTo better understand the potential bias, it’s important to examine how each individual COOTEFOO member is represented in the FILAH and TROUT datasets. To do this, we generate member-level sentiment visualizations to explore how sentiment scores vary across members and industries in each dataset.\n\n\n6.1.3 Individual Member Sentiment\nThis chart breaks down how individual members in the FILAH and TROUT dataset express sentiment toward Fishing and Tourism.\n\n\nShow the code\n\n\nFILAHTROUT\n\n\n\n# Clean and transform FILAH sentiment data\nfilah_sentiment_by_member &lt;- filah_edges %&gt;%\n  filter(role == \"participant\",\n         !is.na(sentiment),\n         target %in% cootefoo_members,\n         !is.na(industry),\n         industry != \"character(0)\",\n         industry != \"\") %&gt;%\n  mutate(\n    industry_clean = str_replace_all(industry, \"c\\\\(|\\\\)|\\\"\", \"\"),\n    industry_clean = tolower(industry_clean),\n    industry_group = assign_topic_category(industry_clean, reason)\n  ) %&gt;%\n  group_by(target, industry_group) %&gt;%\n  summarise(\n    avg_sentiment = mean(sentiment, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  filter(industry_group %in% c(\"Fishing\", \"Tourism\"))\n\n# Combined dot plot (no facets)\nggplot(filah_sentiment_by_member, aes(x = avg_sentiment, y = fct_rev(target))) +\n  geom_point(aes(color = industry_group), size = 5, position = position_dodge(width = 0.5)) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"gray60\") +\n  scale_color_manual(values = c(\"Fishing\" = \"#1f78b4\", \"Tourism\" = \"#ffcc00\")) +\n  scale_x_continuous(limits = c(-1, 1), breaks = seq(-1, 1, 0.5)) +\n  labs(\n    title = \"COOTEFOO Member Sentiment — FILAH Dataset\",\n    subtitle = \"Each dot shows average sentiment toward Fishing or Tourism\",\n    x = \"Sentiment Score (–1: Oppose, +1: Support)\",\n    y = NULL,\n    color = \"Industry\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.text.y = element_text(face = \"bold\"),\n    legend.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nOnly 3 COOTEFOO members appear in FILAH: Seal, Carol Limpet, and Simone Kat. Seal remains neutral, while the other two show surprisingly positive sentiment toward tourism, not fishing. This undermines FILAH’s claimed fishing advocacy and reveals significant sampling bias in member representation.\n\n\n\n\n\n# Clean and transform TROUT sentiment data\ntrout_sentiment_by_member &lt;- trout_edges %&gt;%\n  filter(role == \"participant\",\n         !is.na(sentiment),\n         target %in% cootefoo_members,\n         !is.na(industry),\n         industry != \"character(0)\",\n         industry != \"\") %&gt;%\n  mutate(\n    industry_clean = str_replace_all(industry, \"c\\\\(|\\\\)|\\\"\", \"\"),\n    industry_clean = tolower(industry_clean),\n    industry_group = assign_topic_category(industry_clean, reason)\n  ) %&gt;%\n  group_by(target, industry_group) %&gt;%\n  summarise(\n    avg_sentiment = mean(sentiment, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  filter(industry_group %in% c(\"Fishing\", \"Tourism\"))\n\n\nggplot(trout_sentiment_by_member, aes(x = avg_sentiment, y = fct_rev(target))) +\n  geom_point(aes(color = industry_group), size = 5, position = position_dodge(width = 0.5)) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"gray60\") +\n  scale_color_manual(values = c(\"Fishing\" = \"#1f78b4\", \"Tourism\" = \"#ffcc00\")) +\n  scale_x_continuous(limits = c(-1, 1), breaks = seq(-1, 1, 0.5)) +\n  labs(\n    title = \"COOTEFOO Member Sentiment — TROUT Dataset\",\n    subtitle = \"Each dot shows average sentiment toward Fishing or Tourism\",\n    x = \"Sentiment Score (–1: Oppose, +1: Support)\",\n    y = NULL,\n    color = \"Industry\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.text.y = element_text(face = \"bold\"),\n    legend.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nTROUT features Teddy Goldstein, Seal, and Ed Helpsford. Teddy expresses strong pro-fishing sentiment, contradicting TROUT’s tourism alignment. Seal is again neutral. TROUT omits several members (e.g., Simone Kat), and the presence of fishing support in a tourism dataset suggests selective inclusion to make a point or to avoid contradicting narratives.\n\n\n\n\n\n\n\n\n\nQ1 Answer — Evidence of Bias in TROUT & FILAH\n\n\n\nBoth the TROUT and FILAH datasets reveal potential indicators of bias, particularly in the way sentiment is recorded and which COOTEFOO members are included or omitted.\nFILAH includes only a subset of COOTEFOO members and primarily reflects positive sentiment toward tourism, which appears at odds with its stated advocacy for the fishing sector.\nTROUT, while including more members, emphasizes voices that are critical of tourism and supportive of fishing, suggesting a narrative aligned with their stance.\nThese observations suggest that each dataset may reflect the priorities and framing choices of its source organization. However, the patterns of inclusion, omission, and sentiment warrant deeper exploration.\nTo better understand the extent and implications of these biases, the subsequent questions (Q2–Q4) will integrate a more complete dataset and examine structural, geographic, and individual-level behavior in context."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#geographic-data-overview-oceanus-zones-and-road-network",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#geographic-data-overview-oceanus-zones-and-road-network",
    "title": "Take-home Exercise 2",
    "section": "4.5 Geographic Data Overview: Oceanus Zones and Road Network",
    "text": "4.5 Geographic Data Overview: Oceanus Zones and Road Network\nTo supplement the knowledge graph analysis with spatial context, we incorporate two geographic datasets:\n\nOceanus Zone Map (oceanus_map.geojson): Defines land use zones across the island (e.g., residential, tourism, industrial).\nRoad Network (road_map.json): Represents the transportation infrastructure using node-link format with GPS coordinates.\n\nThese datasets provide spatial grounding for COOTEFOO committee activities, including meeting venues and travel routes. This helps identify geographic bias or clustering in committee decisions and movement patterns.\n\n\n📂 Load Spatial Data\n\n\n# Load geographic data\noceanus_map &lt;- st_read(\"data/oceanus_map.geojson\")\n\nReading layer `oceanus_map' from data source \n  `D:\\shartiono\\ISSS608-VAA\\Take-home_Ex\\Take-home_Ex_2\\data\\oceanus_map.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 29 features and 6 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\nroad_json &lt;- fromJSON(\"data/road_map.json\", simplifyDataFrame = TRUE)\n\n\nWe then prepare the road network for inspection and visualize both datasets to confirm spatial integrity.\n\n\nShow the Code\n\n\n# Prepare road network data\nroad_nodes &lt;- road_json$nodes %&gt;%\n  mutate(id = as.character(id), x = longitude, y = latitude)\n\nroad_edges &lt;- road_json$links %&gt;%\n  rename(from = source, to = target) %&gt;%\n  mutate(across(c(from, to), as.character))\n\n# Preview structure of both datasets\nglimpse(oceanus_map)\n\nRows: 29\nColumns: 7\n$ Name                 &lt;chr&gt; \"Suna Island\", \"Thalassa Retreat\", \"Makara Shoal\"…\n$ Description          &lt;chr&gt; \"Large island of Oceanus\", \"Smaller island of Oce…\n$ type                 &lt;chr&gt; \"Entity.Location.Region\", \"Entity.Location.Region…\n$ Kind                 &lt;chr&gt; \"Island\", \"Island\", \"Island\", \"Island\", \"Fishing …\n$ Activities           &lt;list&gt; \"Residential\", \"Residential\", \"Recreation\", &lt;\"To…\n$ fish_species_present &lt;list&gt; &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;\"Cod/Gadus n.specificatae\", \"Bi…\n$ geometry             &lt;GEOMETRY [°]&gt; MULTIPOLYGON (((-166.0111 3..., MULTIPOL…\n\nglimpse(road_nodes)\n\nRows: 2,664\nColumns: 8\n$ zone      &lt;chr&gt; \"commercial\", \"commercial\", \"commercial\", \"commercial\", \"com…\n$ city_name &lt;chr&gt; \"Lomark\", \"Lomark\", \"Lomark\", \"Lomark\", \"Lomark\", \"Lomark\", …\n$ longitude &lt;dbl&gt; -165.5773, -165.5769, -165.5768, -165.5780, -165.5787, -165.…\n$ latitude  &lt;dbl&gt; 39.53082, 39.52992, 39.53158, 39.53109, 39.53041, 39.54057, …\n$ id        &lt;chr&gt; \"48344443\", \"48344507\", \"48524007\", \"2135056313\", \"212811835…\n$ name      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Har…\n$ x         &lt;dbl&gt; -165.5773, -165.5769, -165.5768, -165.5780, -165.5787, -165.…\n$ y         &lt;dbl&gt; 39.53082, 39.52992, 39.53158, 39.53109, 39.53041, 39.54057, …\n\n# Visual preview: Oceanus zones and road network\npar(mfrow = c(1, 2))\nplot(oceanus_map$geometry,\n     main = \"Oceanus Zones (GeoJSON)\",\n     col = \"lightblue\", border = \"gray\")\nplot(road_nodes$x, road_nodes$y,\n     main = \"Road Network Nodes\",\n     pch = 19, col = \"darkred\",\n     xlab = \"Longitude\", ylab = \"Latitude\")\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#question-2",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#question-2",
    "title": "Take-home Exercise 2",
    "section": "6.2 Question 2",
    "text": "6.2 Question 2\n\n\n\n\n\n\nThe Question\n\n\n\n\nAs a journalist, Ms. Moray would like a more complete picture of the COOTEFOO’s actions and activities. She has arranged to combine the data provided by TROUT and FILAH into a single knowledge graph along with additional records. Design visual analytics approaches for this combined knowledge graph to see how members of COOTEFOO spend their time. Is the committee as a whole biased? Provide visual evidence for your conclusions.\n\n\n\nTo answer this, we integrated the TROUT, FILAH, and JOURNALIST datasets into a single comprehensive knowledge graph. We use both network centrality and geographic activity patterns to determine whether the committee’s actions reflect a collective bias toward either industry.\n\n6.2.1 Network Graph Analysis\nThe combined knowledge graph visualizes:\n\nEdges by source dataset (TROUT = orange, FILAH = brown, JOURNALIST = green)\nNodes by sentiment bias (yellow = tourism, blue = fishing, grey = unknown)\nNode size by degree centrality (activity/influence level)\n\n\n\nShow the code\n\n\n# Compute average sentiment per person\ncompute_bias &lt;- function(nodes, edges) {\n  edges %&gt;%\n    filter(!is.na(sentiment), str_detect(role, \"participant\")) %&gt;%\n    filter(to %in% nodes$id) %&gt;%\n    group_by(person = to) %&gt;%\n    summarise(\n      bias_avg = mean(sentiment, na.rm = TRUE),\n      n_obs    = n(),\n      .groups  = \"drop\"\n    )\n}\nbias_lookup &lt;- compute_bias(combined_nodes, combined_edges)\n\n# Build combined graph with metrics\ncombined_graph &lt;- tbl_graph(\n  nodes = combined_nodes,\n  edges = combined_edges,\n  directed = TRUE,\n  node_key = \"id\"\n) %&gt;%\n  activate(nodes) %&gt;%\n  left_join(bias_lookup, by = c(\"id\" = \"person\")) %&gt;%\n  mutate(\n    degree   = centrality_degree(mode = \"all\"),\n    cluster  = group_infomap(),\n    bias_cat = case_when(\n      is.na(bias_avg) ~ NA_character_,\n      bias_avg &gt;= 0   ~ \"tourism\",\n      TRUE            ~ \"fishing\"\n    )\n  )\n\n# Plot the network graph\nset.seed(42)\n\nggraph(combined_graph, layout = \"fr\") +\n  geom_edge_link(aes(colour = source_dataset), alpha = 0.3) +\n  geom_node_point(aes(\n    size = degree,\n    colour = bias_cat,\n    alpha = if_else(is.na(bias_cat), 0.05, 0.9)\n  )) +\n  geom_node_text(aes(label = label), repel = TRUE, size = 2.5, alpha = 0.8) +\n  scale_edge_colour_manual(values = c(\n    TROUT      = \"#FFA500\",  # Orange\n    FILAH      = \"#8B4513\",  # Brown\n    JOURNALIST = \"#33a02c\"   # Green\n  )) +\n  scale_colour_manual(values = c(\n    fishing = \"#1f78b4\",     # Blue\n    tourism = \"#FFD700\"      # Yellow\n  ), na.value = \"grey80\") +\n  scale_alpha_identity() +\n  scale_size(range = c(2, 8)) +\n  labs(\n    title       = \"Combined COOTEFOO Network (Bias Highlighted, Others Dimmed)\",\n    edge_colour = \"Source Dataset\",\n    colour      = \"Bias Category\",\n    size        = \"Degree Centrality\"\n  ) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation — Network Graph (Bias Highlighted)\n\n\n\nThe visualization shows that nodes with tourism-aligned sentiment (yellow) tend to be larger and more centrally located, while fishing-aligned nodes (blue) appear less connected and more peripheral. The JOURNALIST dataset contributes most of the connections across the network. This view reflects how sentiment categories are structurally embedded within the overall committee activity network.\n\n\n\n\n\n6.2.2 Geographic Activity Analysis\nTo complement the network analysis, we examine the spatial movement of COOTEFOO members using trip records tagged with latitude and longitude. These records help reveal where board members travel across Oceanus and whether their movement patterns correspond to certain zone types (e.g., tourism, fishing, commercial).\nThis analysis leverages:\n\nThe Oceanus Zone Map (oceanus_map.geojson) from Section 4.5, which defines land use classification.\nThe Road Network (road_map.json), which supports spatial orientation but is not directly used in the trip overlay.\n\nBefore extracting trip locations, we enrich the combined node dataset with latitude and longitude fields from the original JOURNALIST dataset to ensure coordinate data is available for spatial mapping.\n\n\nShow the code\n\n\n# Enrich combined_nodes with lat/lon from the journalist dataset\ncombined_nodes &lt;- combined_nodes %&gt;%\n  left_join(\n    journalist_nodes %&gt;% select(id, lat, lon),\n    by = \"id\"\n  )\n\n\nThe plot below shows board member trip locations, color-coded by member name, overlaid on the zoning map.\n\n\nShow the code\n\n\n# Step 1: Identify board members\nboard_members &lt;- combined_nodes %&gt;%\n  filter(type == \"entity.person\") %&gt;%\n  select(person_id = id, member_name = label)\n\n# Step 2: Extract trip-to-person edges\ntrip_participant_edges &lt;- combined_edges %&gt;%\n  filter(role == \"participant\") %&gt;%\n  inner_join(board_members, by = c(\"to\" = \"person_id\")) %&gt;%\n  filter(str_detect(from, \"trip\")) %&gt;%\n  select(trip_id = from, member_name)\n\n# Step 3: Match trip nodes with location coordinates\ncootefoo_trip_locs &lt;- combined_nodes %&gt;%\n  filter(type == \"trip\", !is.na(lat), !is.na(lon)) %&gt;%\n  select(id, label, lat, lon) %&gt;%\n  inner_join(trip_participant_edges, by = c(\"id\" = \"trip_id\")) %&gt;%\n  mutate(\n    latitude = as.numeric(lat),\n    longitude = as.numeric(lon)\n  )\n\n# Step 4: Plot board member trips on Oceanus zone map\nggplot() +\n  geom_sf(data = oceanus_map, aes(fill = Kind), color = \"black\", alpha = 0.4) +\n  geom_point(data = cootefoo_trip_locs, aes(x = longitude, y = latitude, color = member_name),\n             size = 2, alpha = 0.8) +\n  labs(\n    title = \"COOTEFOO Board Member Trips Over Oceanus Zones\",\n    fill = \"Zone Type\",\n    color = \"Board Member\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation — Geographic View of Board Member Trips\n\n\n\nThis map shows COOTEFOO board member trips (black dots) overlaid on the Oceanus zoning map. Most trip locations are clustered near Island, City, and Ecological Preserve zones, while relatively few are located within or near Fishing Ground zones (blue areas). This spatial distribution suggests that board member activity, as captured through recorded trips, is more concentrated in non-fishing zones, offering geographic context to complement the network analysis.\n\n\n\n\n6.2.3 Member Involvement by Dataset and Activity Type\nTo complement the earlier network graph, we insert a bar plot showing how many times each COOTEFOO member appears across different datasets and the type of engagement (e.g., meeting, site visit, etc.). This mirrors the approach seen in the reference link and helps Ms. Moray understand member activity depth and focus areas.\n\n\nShow the code\n\n\n# Filter only COOTEFOO members and participant roles\ncootefoo_members &lt;- c(\"Seal\", \"Simone Kat\", \"Carol Limpet\", \n                      \"Teddy Goldstein\", \"Ed Helpsford\", \"Tante Titan\")\n\nmember_activity &lt;- combined_edges %&gt;%\n  filter(from %in% cootefoo_members | to %in% cootefoo_members) %&gt;%\n  pivot_longer(cols = c(from, to), names_to = \"direction\", values_to = \"person\") %&gt;%\n  filter(person %in% cootefoo_members) %&gt;%\n  count(person, source_dataset, name = \"n\") %&gt;%\n  mutate(source_dataset = factor(source_dataset, levels = c(\"TROUT\", \"FILAH\", \"JOURNALIST\")))\n\n# Bar chart\nggplot(member_activity, aes(x = fct_reorder(person, n), y = n, fill = source_dataset)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"TROUT\" = \"#ffcc00\", \"FILAH\" = \"#1f78b4\", \"JOURNALIST\" = \"#33a02c\")) +\n  labs(\n    title = \"COOTEFOO Member Activity by Dataset\",\n    subtitle = \"Each bar shows the number of activities a member is linked to\",\n    x = \"Member\",\n    y = \"Activity Count\",\n    fill = \"Dataset\"\n  ) +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation — Dataset Participation by Member\n\n\n\nThis bar chart reveals notable disparities in dataset coverage across COOTEFOO members:\nTante Titan, Ed Helpsford, and Teddy Goldstein have substantial engagement logged in the JOURNALIST dataset but are largely missing or underrepresented in FILAH, confirming a sampling bias in that subset.\nSimone Kat and Carol Limpet are prominently featured in FILAH, but absent or minimally recorded in TROUT, suggesting selective emphasis favoring tourism-leaning narratives.\nSeal is the only member with relatively balanced representation across all three datasets, though still with variations in total activity count.\nThe JOURNALIST dataset captures the most complete engagement for every member, underscoring its critical value in correcting incomplete perspectives presented by TROUT and FILAH.\nTogether, this visualization strengthens the argument that no individual dataset tells the full story, and evaluating COOTEFOO’s behavior in context requires triangulating across all sources.\n\n\n\n\n\n\n\n\n\nAnswer — Question 2: Is COOTEFOO as a whole biased?\n\n\n\nThe combined analysis of network structure, geographic activity, and member engagement reveals that COOTEFOO as a whole shows operational bias toward tourism-related initiatives, even if this bias is not overtly declared.\nIn the network graph, nodes aligned with tourism sentiment (yellow) are more central and active than those aligned with fishing (blue), suggesting that discussions and plans about tourism are more influential within the committee. The JOURNALIST dataset, which contributes the majority of connections, provides the clearest evidence of this structural tilt.\nThe geographic trip overlay confirms this finding: COOTEFOO members predominantly travel to zones associated with urban development, islands, and ecological preserves—areas tied to tourism and infrastructure—while fishing grounds receive minimal attention.\nFinally, the member activity bar chart highlights sampling bias in the advocacy datasets. Some members (e.g., Teddy Goldstein, Tante Titan) are active in the full dataset but underrepresented or omitted in TROUT and FILAH. This disparity reinforces the importance of using the full dataset when assessing committee behavior.\nTaken together, the evidence suggests that while COOTEFOO may not be explicitly biased, its actions and priorities in practice show a systematic leaning toward tourism interests, largely underreported in the subset datasets."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#question-3",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#question-3",
    "title": "Take-home Exercise 2",
    "section": "6.3 Question 3",
    "text": "6.3 Question 3\n\n\n\n\n\n\nThe Question\n\n\n\n\nThe TROUT and FILAH datasets are incomplete. Use your visualizations to compare and contrast conclusions drawn from the TROUT and FILAH datasets separately with behaviors in the whole dataset. Are the accusations of TROUT strengthened, weakened or unchanged when taken in context of the whole dataset?\n\n\n\nWe compare how sentiment toward Fishing and Tourism is represented across TROUT, FILAH, and the full JOURNALIST dataset. This reveals whether either subset presents a skewed or selective view of COOTEFOO member attitudes. Discrepancies in sentiment distributions highlight potential bias or missing context.\n\n\nShow the code\n\n\n# Helper function to classify topic by industry\nassign_topic_category &lt;- function(industry, reason) {\n  industry &lt;- tolower(industry)\n  reason   &lt;- tolower(reason)\n  \n  case_when(\n    str_detect(reason, \"housing\") ~ \"Other\",\n    str_detect(industry, \"tourism|tourist|wharf|travel|harbor|marina|port\") |\n      str_detect(reason,   \"tourism|tourist|wharf|travel|harbor|marina|port\") ~ \"Tourism\",\n    str_detect(industry, \"fishing|vessel|dock|crane|fish\") |\n      str_detect(reason,   \"fishing|vessel|dock|crane|fish\") ~ \"Fishing\",\n    TRUE ~ \"Other\"\n  )\n}\n\n# Function to extract sentiment records\nextract_sentiments &lt;- function(edge_df, dataset_label) {\n  edge_df %&gt;%\n    filter(role == \"participant\", !is.na(sentiment), !is.na(industry)) %&gt;%\n    mutate(\n      industry_group = assign_topic_category(industry, reason),\n      dataset = dataset_label\n    ) %&gt;%\n    select(target, sentiment, industry_group, dataset)\n}\n\n# Apply to all three datasets\ntrout_sentiments &lt;- extract_sentiments(trout_edges, \"TROUT\")\nfilah_sentiments &lt;- extract_sentiments(filah_edges, \"FILAH\")\njournalist_sentiments &lt;- extract_sentiments(journalist_edges, \"JOURNALIST\")\n\n# Combine into one tidy dataset\ncombined_sentiments &lt;- bind_rows(trout_sentiments, filah_sentiments, journalist_sentiments)\n\n\n\n6.3.1🎻 Sentiment Distribution by Industry and Dataset\nThis violin plot shows how each dataset portrays sentiment toward Fishing, Tourism, and Other topics. Wider shapes reflect more sentiment records. By comparing TROUT and FILAH to the full JOURNALIST dataset, we can identify patterns of omission or emphasis.\n\n\nShow the code\n\n\n### Violin Plot for Sentiment Comparison\n\nggplot(combined_sentiments, aes(x = industry_group, y = sentiment, fill = dataset)) +\n  geom_violin(trim = FALSE, scale = \"width\", alpha = 0.7) +\n  geom_jitter(aes(color = dataset), size = 1.4, width = 0.2, alpha = 0.5, show.legend = FALSE) +\n  facet_wrap(~ industry_group, scales = \"free_x\") +\n  scale_fill_manual(values = c(\n    \"TROUT\" = \"#ffcc00\",\n    \"FILAH\" = \"#1f78b4\",\n    \"JOURNALIST\" = \"#33a02c\"\n  )) +\n  scale_color_manual(values = c(\n    \"TROUT\" = \"#ffcc00\",\n    \"FILAH\" = \"#1f78b4\",\n    \"JOURNALIST\" = \"#33a02c\"\n  )) +\n  labs(\n    title = \"Sentiment Toward Industry by Dataset\",\n    subtitle = \"Violin plots comparing TROUT, FILAH, and JOURNALIST sentiment\",\n    x = \"Industry Category\",\n    y = \"Sentiment Score\",\n    fill = \"Dataset\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nTeddy Goldstein stands out with conflicting sentiment: strongly positive in TROUT and JOURNALIST on Fishing, but negative in TROUT on Tourism. FILAH omits his sentiment entirely. Tante Titan, absent from TROUT and FILAH, only appears in the JOURNALIST dataset. These gaps and contradictions suggest each subset selectively represents member behavior, underscoring the importance of cross-dataset analysis.\n\n\n\n\n\n6.3.2 📊 Volume of Sentiment Records per Dataset\nThis stacked bar chart complements the violin plot by showing the total number of sentiment-tagged records per dataset, broken down by industry category. This directly exposes which datasets are underreporting certain industries, which helps explain why the sentiment heatmap has missing cells. The codes are shown below:\n\n\nShow the code\n\n\n# Count total sentiment records by dataset and industry\nsentiment_volume &lt;- combined_sentiments %&gt;%\n  filter(industry_group %in% c(\"Fishing\", \"Tourism\", \"Other\")) %&gt;%\n  count(dataset, industry_group)\n\n# Plot: Stacked bar chart of sentiment volume\nggplot(sentiment_volume, aes(x = dataset, y = n, fill = industry_group)) +\n  geom_col(position = \"stack\") +\n  scale_fill_manual(values = c(\n    \"Fishing\" = \"#1f78b4\",\n    \"Tourism\" = \"#ffcc00\",\n    \"Other\" = \"gray70\"\n  )) +\n  labs(\n    title = \"Total Sentiment Records by Dataset and Industry\",\n    subtitle = \"Highlights coverage gaps in FILAH and TROUT\",\n    x = \"Dataset\",\n    y = \"Number of Sentiment Records\",\n    fill = \"Industry Category\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    plot.subtitle = element_text(margin = margin(b = 10)),\n    legend.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation — Sentiment Volume by Dataset\n\n\n\nThe bar chart reveals major coverage disparities:\n\nJOURNALIST provides the most complete sentiment coverage, with nearly equal attention to Tourism, Fishing, and Other topics.\nFILAH heavily emphasizes Tourism, despite being a pro-fishing group, and contributes minimal sentiment records on Fishing.\nTROUT presents a narrower distribution with relatively few records overall, and underrepresents Tourism sentiment compared to expectations.\n\nThese gaps directly affect how COOTEFOO member sentiment appears in analysis—highlighting why sentiment conclusions based solely on TROUT or FILAH may be unreliable.\n\n\n\n\n\n6.3.3🔍 COOTEFOO Member-Level Sentiment Heatmap\nThis heatmap compares average sentiment scores for each COOTEFOO member by dataset and industry category. It highlights inconsistencies across data sources and reveals how individual member portrayals shift depending on which dataset is used. Blank cells represent missing sentiment data.\n\n\nShow the code\n\n\n# Define COOTEFOO members\ncootefoo_members &lt;- c(\"Seal\", \"Simone Kat\", \"Carol Limpet\", \n                      \"Teddy Goldstein\", \"Ed Helpsford\", \"Tante Titan\")\n\n# Clean sentiment data: keep only COOTEFOO member targets\nmember_sentiments &lt;- combined_sentiments %&gt;%\n  filter(target %in% cootefoo_members) %&gt;%\n  group_by(target, dataset, industry_group) %&gt;%\n  summarise(avg_sentiment = mean(sentiment, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(column_id = paste(dataset, industry_group, sep = \"_\"))\n\n# Reshape to wide format for heatmap-style display\nsentiment_matrix &lt;- member_sentiments %&gt;%\n  select(name = target, column_id, avg_sentiment) %&gt;%\n  pivot_wider(names_from = column_id, values_from = avg_sentiment)\n\n# Create actual heatmap-style plot\nsentiment_matrix_long &lt;- sentiment_matrix %&gt;%\n  pivot_longer(-name, names_to = \"Dataset_Industry\", values_to = \"Sentiment\")\n\nggplot(sentiment_matrix_long, aes(x = Dataset_Industry, y = fct_rev(name), fill = Sentiment)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = round(Sentiment, 2)), size = 3) +\n  scale_fill_gradient2(low = \"#b2182b\", mid = \"white\", high = \"#2166ac\", midpoint = 0, na.value = \"grey90\") +\n  labs(\n    title = \"Sentiment Presence by COOTEFOO Member and Dataset\",\n    subtitle = \"Missing = not scored in that dataset/industry\",\n    x = \"Dataset × Industry\", y = NULL, fill = \"Avg Sentiment\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n# Add count\nmember_sentiments &lt;- combined_sentiments %&gt;%\n  filter(target %in% cootefoo_members) %&gt;%\n  group_by(target, dataset, industry_group) %&gt;%\n  summarise(\n    avg_sentiment = mean(sentiment, na.rm = TRUE),\n    n_obs = n(),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(label = paste0(round(avg_sentiment, 2), \" (\", n_obs, \")\"),\n         column_id = paste(dataset, industry_group, sep = \"_\"))\n\n\n\n\n\n\n\nObservation\n\n\n\nThe heatmap shows that while all six COOTEFOO members are structurally present in the TROUT dataset, only Seal, Ed Helpsford, and Teddy Goldstein have sentiment scores recorded. Tante Titan, Simone Kat, and Carol Limpet have no sentiment values in TROUT, despite being scored in the JOURNALIST dataset with moderate-to-positive sentiment—especially toward Tourism. This partial sentiment coverage skews TROUT’s representation, amplifying voices like Goldstein’s (strong pro-fishing) while silencing others who may offer more balanced or tourism-aligned perspectives.\n\n\n\n\n\n\n\n\n\nAnswer — Question 3: Are TROUT’s Accusations Strengthened, Weakened, or Unchanged?\n\n\n\nTROUT asserts that the COOTEFOO board is biased in favor of the fishing industry and resistant to tourism development. However, this claim is weakened when TROUT is analyzed alongside the more complete JOURNALIST dataset.\nThe violin plot reveals that TROUT records include sentiment values toward both Fishing and Tourism, with several members expressing positive views on tourism, contradicting the central accusation. The sentiment distribution in TROUT actually mirrors the broader sentiment balance seen in JOURNALIST, undermining the claim that the board opposes tourism outright.\nThe heatmap further highlights internal inconsistency: while all six COOTEFOO members are structurally present in TROUT, only three (Seal, Ed Helpsford, and Teddy Goldstein) have sentiment data attached. The omission of sentiment values for Simone Kat, Carol Limpet, and Tante Titan—who are documented in the JOURNALIST dataset as expressing tourism-positive or balanced views—suggests that TROUT selectively includes voices that reinforce a fishing-biased narrative.\nFinally, the sentiment volume bar chart shows that TROUT has fewer total sentiment records than JOURNALIST, and contributes only a narrow slice of the available context. FILAH, although more voluminous, also shows an unexpected skew toward tourism sentiment and underrepresents fishing.\nTaken together, these visualizations demonstrate that TROUT’s dataset lacks key sentiment context and omits critical voices. Its accusations appear to be based on incomplete and selectively framed evidence. The more comprehensive JOURNALIST data offers a more nuanced and balanced picture, with COOTEFOO members engaging meaningfully with both industries.\nTROUT’s narrative of systemic fishing bias within COOTEFOO is not substantiated when assessed in the full context. The omission of member sentiment, especially those favoring tourism, diminishes the credibility of the accusation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#combining-all-graphs-for-section-6-analysis",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#combining-all-graphs-for-section-6-analysis",
    "title": "Take-home Exercise 2",
    "section": "5.3 Combining All Graphs for Section 6 Analysis",
    "text": "5.3 Combining All Graphs for Section 6 Analysis\nTo support the comparative analysis in Section 6, we now construct a combined dataset from the three sources. This step ensures that all relevant nodes and edges are merged into a single structure for downstream bias evaluation using sentiment, centrality, and spatial analysis. The code is shown below:\n\n\nShow the code\n\n\n# Combine cleaned nodes and edges for integrated analysis\ncombined_nodes &lt;- bind_rows(\n  trout_data$nodes_cleaned %&gt;% mutate(source_dataset = \"TROUT\"),\n  filah_data$nodes_cleaned %&gt;% mutate(source_dataset = \"FILAH\"),\n  journalist_data$nodes_cleaned %&gt;% mutate(source_dataset = \"JOURNALIST\")\n) %&gt;%\n  distinct(id, .keep_all = TRUE)\n\ncombined_edges &lt;- bind_rows(\n  trout_data$edges_cleaned %&gt;% mutate(source_dataset = \"TROUT\"),\n  filah_data$edges_cleaned %&gt;% mutate(source_dataset = \"FILAH\"),\n  journalist_data$edges_cleaned %&gt;% mutate(source_dataset = \"JOURNALIST\")\n) %&gt;%\n  filter(from %in% combined_nodes$id, to %in% combined_nodes$id)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#question-4",
    "href": "Take-home_Ex/Take-home_Ex_2/Take-home_Ex_2.html#question-4",
    "title": "Take-home Exercise 2",
    "section": "6.4 Question 4",
    "text": "6.4 Question 4\n\n\n\n\n\n\nThe Question\n\n\n\nDesign a visualization that allows Ms. Moray to pick a person and highlight the differences in that person’s behavior as illustrated through the different datasets. Focus on the contrast in the story each dataset tells.\n\nPick at least one COOTEFOO member accused by TROUT.\nIllustrate how your understanding of their activities changed when using the more complete dataset.\nWhat are the key pieces of evidence missing from the original TROUT data that most influenced the change in judgement?\nWhose behaviors are most impacted by sampling bias when looking at the FILAH dataset in context of the other data?\nIllustrate the bias of the FILAH data in the context of the whole dataset.\n\n\n\n\n6.4.1 🗺️ Building on Q1–Q3\nIn Q1–Q3, we uncovered evidence of selective omission and framing across the TROUT and FILAH datasets. TROUT emphasized a pro-fishing stance while omitting planning-related reasoning. FILAH omitted multiple active members entirely. Using the full JOURNALIST dataset clarified that COOTEFOO member sentiment is more nuanced, with participation spanning fishing, tourism, and broader infrastructure concerns.\n\n\n6.4.2👤 Focal Member: Teddy Goldstein\nTeddy was explicitly accused by TROUT of resisting tourism and favoring fishing. His record is:\n\nPresent in TROUT and JOURNALIST datasets\nAbsent from FILAH, indicating sampling bias\nShows contrasting portrayals between datasets\n\n\n\n6.4.3 📊 Teddy’s Activity Record Count\nWe begin with a simple bar chart showing the number of Teddy’s engagements recorded across the three datasets.\n\n\nShow the code\n\n\nteddy_summary &lt;- combined_edges %&gt;%\n  filter(from == \"Teddy Goldstein\" | to == \"Teddy Goldstein\") %&gt;%\n  count(source_dataset, name = \"n\") %&gt;%\n  complete(source_dataset = c(\"TROUT\", \"FILAH\", \"JOURNALIST\"), fill = list(n = 0))\n\nggplot(teddy_summary, aes(x = source_dataset, y = n, fill = source_dataset)) +\n  geom_col() +\n  scale_fill_manual(values = c(\n    \"TROUT\" = \"#ffcc00\",\n    \"FILAH\" = \"#1f78b4\",\n    \"JOURNALIST\" = \"#33a02c\"\n  )) +\n  labs(\n    title = \"Teddy Goldstein: Records per Source\",\n    x = \"Dataset\",\n    y = \"Number of Records\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nTROUT logs only a fraction of Teddy’s total engagements. He is completely omitted from FILAH. The complete JOURNALIST dataset records the majority of his interactions, showing a more balanced presence across tourism and fishing topics.\n\n\n\n\n\n6.4.4 📊 Ego Network Visualization (static)\nWe now generate a static circular ego network using ggraph to illustrate how Teddy’s interactions differ by dataset.\n\n\nShow the code\n\n\n# Prepare ego network\nteddy_edges &lt;- combined_edges %&gt;%\n  filter(from == \"Teddy Goldstein\" | to == \"Teddy Goldstein\") %&gt;%\n  count(from, to, source_dataset, name = \"weight\")\n\nteddy_nodes &lt;- tibble(id = unique(c(teddy_edges$from, teddy_edges$to))) %&gt;%\n  left_join(combined_nodes %&gt;% select(id, label), by = \"id\") %&gt;%\n  mutate(group = if_else(id == \"Teddy Goldstein\", \"Selected\", \"Neighbour\"))\n\nteddy_graph &lt;- tbl_graph(nodes = teddy_nodes, edges = teddy_edges, directed = TRUE)\n\n# Static circular layout\nset.seed(2025)\nggraph(teddy_graph, layout = \"circle\") +\n  geom_edge_link(aes(width = weight, colour = source_dataset),\n                 alpha = 0.8, arrow = arrow(type = \"closed\", length = unit(2, \"mm\"))) +\n  scale_edge_colour_manual(values = c(\n    \"TROUT\" = \"#ffcc00\",\n    \"FILAH\" = \"#1f78b4\",\n    \"JOURNALIST\" = \"#33a02c\"\n  )) +\n  geom_node_point(aes(fill = group), shape = 21, size = 6, color = \"black\") +\n  geom_node_text(aes(label = label), repel = TRUE, size = 3.5) +\n  scale_fill_manual(values = c(\"Selected\" = \"firebrick\", \"Neighbour\" = \"steelblue\")) +\n  scale_edge_width(range = c(0.4, 1.5)) +\n  theme_void() +\n  labs(title = \"Teddy Goldstein’s Ego Network by Dataset\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThis ego network shows a dense range of interactions for Teddy across many nodes. Green links (JOURNALIST) dominate, showing diverse participation, while yellow links (TROUT) are limited and skewed. Blue links (FILAH) are absent, confirming Teddy is completely missing from that dataset.\n\n\n\n\n\n6.4.5 🕸️ Ego Network (Interactive View)\nTo explore interactions in more depth, we include an interactive visNetwork version of the ego network.\n\n\nShow the code\n\n\n# Step 1: Prepare edges for visNetwork\nteddy_vis_edges &lt;- teddy_edges %&gt;%\n  mutate(\n    color = case_when(\n      source_dataset == \"TROUT\"      ~ \"#ffcc00\",       # Yellow\n      source_dataset == \"FILAH\"      ~ \"#1f78b4\",       # Blue\n      source_dataset == \"JOURNALIST\" ~ \"#33a02c\",       # Green\n      TRUE                           ~ \"gray\"\n    ),\n    title = paste0(\"Source: \", source_dataset, \"&lt;br&gt;Weight: \", weight),\n    arrows = \"to\"\n  ) %&gt;%\n  select(from, to, color, title, arrows)\n\n# Step 2: Prepare nodes for visNetwork\nteddy_vis_nodes &lt;- teddy_nodes %&gt;%\n  mutate(\n    label = coalesce(label, id),\n    shape = if_else(group == \"Selected\", \"star\", \"dot\"),\n    color = if_else(group == \"Selected\", \"firebrick\", \"gray\"),\n    title = paste0(\"&lt;b&gt;\", label, \"&lt;/b&gt;\")\n  )\n\n# Step 3: Generate interactive network\nvisNetwork(teddy_vis_nodes, teddy_vis_edges, height = \"700px\", width = \"100%\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 1, hover = TRUE),\n    nodesIdSelection = list(enabled = TRUE, main = \"Explore the network\")\n  ) %&gt;%\n  visLegend(\n    addNodes = data.frame(\n      label = c(\"TROUT\", \"FILAH\", \"JOURNALIST\", \"Selected\", \"Neighbour\"),\n      shape = c(\"dot\", \"dot\", \"dot\", \"star\", \"dot\"),\n      color = c(\"#ffcc00\", \"#1f78b4\", \"#33a02c\", \"firebrick\", \"gray\"),\n      stringsAsFactors = FALSE\n    ),\n    useGroups = FALSE\n  ) %&gt;%\n  visLayout(randomSeed = 42)\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThis interactive visualization highlights Teddy Goldstein’s personal network across the three datasets.\n\nTotal interactions: 65 unique edge connections.\n\nTROUT edges (yellow): 17 links recorded.\nJOURNALIST edges (green): 48 links — the majority of Teddy’s engagement.\nFILAH edges (blue): 0 — Teddy is completely absent in FILAH.\n\nNode count: The network spans 65 nodes, with Teddy at the center (star shape, red), and all connected nodes shown as blue circles (neighbours).\nVisual pattern:\n\nThe green spokes (JOURNALIST) radiate outward in all directions, connecting Teddy to a wide variety of meetings, trips, and discussions.\nYellow spokes (TROUT) are limited and concentrated to fewer topics, visually representing the constrained narrative captured by TROUT.\nBlue spokes (FILAH) are absent, confirming FILAH omitted Teddy’s contributions entirely.\n\nThis layout offers immediate insight into the disparity in data coverage: the richness of Teddy’s documented activities in JOURNALIST versus his underrepresentation in TROUT and total absence in FILAH. The presence of both pro-tourism and pro-fishing topics in the green connections reveals the nuance in Teddy’s actual role, which is oversimplified or missing in the two advocacy datasets.\n\n\n\n\n\n\n\n\n\n\nAnswer — Q4\n\n\n\nTeddy Goldstein is portrayed in the TROUT dataset as a clear opponent of tourism and a staunch supporter of fishing. While this characterization is partially accurate, it is derived from a limited subset of records. The full JOURNALIST dataset reveals a more nuanced profile: Teddy supports fishing-related infrastructure for its economic and operational efficiency, but also expresses concern over environmental impacts and participates in planning-related discussions. His critiques of tourism appear conditional—focused on instances where tourism development may jeopardize fishing livelihoods or environmental stability. By contrast, the FILAH dataset omits Teddy entirely, excluding his perspective from the narrative altogether.\nThis case highlights how bias emerges not only from framing, but from omission. The lack of context in TROUT, particularly missing reasoning behind sentiments, obscures Teddy’s planning and sustainability concerns. FILAH’s total exclusion removes any possibility of evaluating his role. When viewed in full, Teddy is best described as strategically pro-fishing, rather than blindly opposed to tourism. His story exemplifies why data completeness and contextual richness are critical for fair interpretation, and why relying on partial datasets can lead to misleading or polarized conclusions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html",
    "href": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html",
    "title": "Hands-on Exercise 08A",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable for you to read the functional description of each function before using them.\n\n\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually.\n\n\n\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\shartiono\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08A\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThings to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", \n              style = \"quantile\", \n              n = 5,\n              palette = \"Blues\",\n              title = \"Dependency Ratio\") +\n  tm_layout(\n    title = \"Distribution of Dependency Ratio by Planning Subzone\",\n    title.size = 1.2,  # reduce if too large\n    title.position = c(\"center\", \"top\"),\n    outer.margins = c(0.08, 0.02, 0.02, 0.02),  # add margin at top\n    frame = TRUE\n  ) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\n    \"Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics (DOS)\", \n    position = c(\"left\", \"bottom\")\n  )\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"fixed\",\n              breaks = c(0, 5, 10, 15, 20),\n              palette = \"Blues\",\n              colorNA = \"grey70\",\n              textNA = \"Missing\",\n              title = \"DEPENDENCY\") +\n  tm_borders(lwd = 0.01) +\n  tm_layout(\n    frame = TRUE,\n    outer.margins = c(0.02, 0.02, 0.02, 0.02),\n    legend.title.size = 1.0,\n    legend.text.size = 0.8,\n    title = NULL  # Ensures no title is rendered\n  )\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"jenks\",\n              n = 5,\n              palette = \"Blues\",\n              title = \"Dependency Ratio\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"equal\",  # Equal interval bins\n              n = 5,\n              palette = \"Blues\",\n              title = \"Dependency Ratio\") +\n  tm_borders(alpha = 0.5)  # Border transparency\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\nWarning: Maps Lie!\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\nUsing the KMeans classification method, the dependency ratios are grouped based on cluster similarity rather than even ranges or frequencies. This highlights distinct regional clusters but may produce uneven class widths, which can obscure subtle local variations.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"kmeans\",  # try \"equal\", \"jenks\", etc.\n              n = 5,\n              palette = \"Blues\",\n              title = \"KMeans Classification\") +\n  tm_layout(title = \"KMeans Method\", legend.outside = TRUE)\n\n\n\n\n\n\n\n\nUsing the Jenks classification method with 10 classes, the choropleth map reveals finer distinctions in dependency ratios, highlighting several subzones with distinctly higher ratios (e.g., in the north and east). This method effectively emphasizes natural groupings while maintaining readability. The code chunks are below:\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"jenks\",\n              n = 10,\n              palette = \"Blues\",\n              title = \"Jenks, 10 classes\") +\n  tm_layout(title = \"Jenks Method, 10 Classes\", legend.outside = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"fixed\",\n              breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00),\n              palette = \"Blues\",\n              alpha = 0.8,\n              title = \"Dependency\") +\n  tm_borders(alpha = 0.5)  # correct argument\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"quantile\",\n              n = 5,\n              palette = \"Greens\",\n              title = \"Dependency\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", \n              style = \"quantile\",\n              n = 5,\n              palette = \"Blues\",\n              title = \"Dependency Ratio\") +\n  tm_layout(\n    title = \"Distribution of Dependency Ratio by Planning Subzone\",\n    frame = TRUE\n  ) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics (DOS)\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#overview",
    "title": "Hands-on Exercise 08A",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#getting-started",
    "title": "Hands-on Exercise 08A",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#importing-data-into-r",
    "title": "Hands-on Exercise 08A",
    "section": "",
    "text": "Two data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\shartiono\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08A\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThings to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 08A",
    "section": "",
    "text": "Two approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", \n              style = \"quantile\", \n              n = 5,\n              palette = \"Blues\",\n              title = \"Dependency Ratio\") +\n  tm_layout(\n    title = \"Distribution of Dependency Ratio by Planning Subzone\",\n    title.size = 1.2,  # reduce if too large\n    title.position = c(\"center\", \"top\"),\n    outer.margins = c(0.08, 0.02, 0.02, 0.02),  # add margin at top\n    frame = TRUE\n  ) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\n    \"Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics (DOS)\", \n    position = c(\"left\", \"bottom\")\n  )\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"fixed\",\n              breaks = c(0, 5, 10, 15, 20),\n              palette = \"Blues\",\n              colorNA = \"grey70\",\n              textNA = \"Missing\",\n              title = \"DEPENDENCY\") +\n  tm_borders(lwd = 0.01) +\n  tm_layout(\n    frame = TRUE,\n    outer.margins = c(0.02, 0.02, 0.02, 0.02),\n    legend.title.size = 1.0,\n    legend.text.size = 0.8,\n    title = NULL  # Ensures no title is rendered\n  )\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"jenks\",\n              n = 5,\n              palette = \"Blues\",\n              title = \"Dependency Ratio\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"equal\",  # Equal interval bins\n              n = 5,\n              palette = \"Blues\",\n              title = \"Dependency Ratio\") +\n  tm_borders(alpha = 0.5)  # Border transparency\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\nWarning: Maps Lie!\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\nUsing the KMeans classification method, the dependency ratios are grouped based on cluster similarity rather than even ranges or frequencies. This highlights distinct regional clusters but may produce uneven class widths, which can obscure subtle local variations.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"kmeans\",  # try \"equal\", \"jenks\", etc.\n              n = 5,\n              palette = \"Blues\",\n              title = \"KMeans Classification\") +\n  tm_layout(title = \"KMeans Method\", legend.outside = TRUE)\n\n\n\n\n\n\n\n\nUsing the Jenks classification method with 10 classes, the choropleth map reveals finer distinctions in dependency ratios, highlighting several subzones with distinctly higher ratios (e.g., in the north and east). This method effectively emphasizes natural groupings while maintaining readability. The code chunks are below:\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"jenks\",\n              n = 10,\n              palette = \"Blues\",\n              title = \"Jenks, 10 classes\") +\n  tm_layout(title = \"Jenks Method, 10 Classes\", legend.outside = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"fixed\",\n              breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00),\n              palette = \"Blues\",\n              alpha = 0.8,\n              title = \"Dependency\") +\n  tm_borders(alpha = 0.5)  # correct argument\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\",\n              style = \"quantile\",\n              n = 5,\n              palette = \"Greens\",\n              title = \"Dependency\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\", \n              style = \"quantile\",\n              n = 5,\n              palette = \"Blues\",\n              title = \"Dependency Ratio\") +\n  tm_layout(\n    title = \"Distribution of Dependency Ratio by Planning Subzone\",\n    frame = TRUE\n  ) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics (DOS)\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08A/Hands-on_Ex08A.html#reference",
    "title": "Hands-on Exercise 08A",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08A/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex08A/data/geospatial/MPSZ-2019.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#learning-outcome",
    "title": "Hands-on Exercise 08B",
    "section": "1.1 Learning outcome",
    "text": "1.1 Learning outcome\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex08B/data/geospatial/MPSZ-2019.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#the-data",
    "title": "Hands-on Exercise 08B",
    "section": "3.1 The data",
    "text": "3.1 The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#data-import-and-preparation",
    "title": "Hands-on Exercise 08B",
    "section": "3.2 Data Import and Preparation",
    "text": "3.2 Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 08B",
    "section": "3.3 Creating a sf data frame from an aspatial data frame",
    "text": "3.3 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#it-all-started-with-an-interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#it-all-started-with-an-interactive-point-symbol-map",
    "title": "Hands-on Exercise 08B",
    "section": "4.1 It all started with an interactive point symbol map",
    "text": "4.1 It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(\n    size = 1,            \n    col = \"red\",         \n    border.col = \"black\",\n    border.lwd = 1       \n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#lets-make-it-proportional",
    "title": "Hands-on Exercise 08B",
    "section": "4.2 Lets make it proportional",
    "text": "4.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(\n    size = \"Gp1Gp2 Winnings\", \n    col = \"red\",              \n    border.col = \"black\",     \n    border.lwd = 1             \n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#lets-give-it-a-different-colour",
    "title": "Hands-on Exercise 08B",
    "section": "4.3 Lets give it a different colour",
    "text": "4.3 Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(\n    size = \"Gp1Gp2 Winnings\",  \n    col = \"OUTLET TYPE\",       \n    border.col = \"black\",      \n    border.lwd = 1             \n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#i-have-a-twin-brothers",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#i-have-a-twin-brothers",
    "title": "Hands-on Exercise 08B",
    "section": "4.4 I have a twin brothers :)",
    "text": "4.4 I have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(\n    size = \"Gp1Gp2 Winnings\",  \n    col = \"OUTLET TYPE\",       \n    border.col = \"black\",      \n    border.lwd = 1             \n  ) +\n  tm_facets(\n    by = \"OUTLET TYPE\",\n    nrow = 1,\n    sync = TRUE\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#all-about-tmap-package",
    "title": "Hands-on Exercise 08B",
    "section": "5.1 All about tmap package",
    "text": "5.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#geospatial-data-wrangling-1",
    "title": "Hands-on Exercise 08B",
    "section": "5.2 Geospatial data wrangling",
    "text": "5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#data-wrangling",
    "title": "Hands-on Exercise 08B",
    "section": "5.3 Data wrangling",
    "text": "5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#i-have-a-twin",
    "href": "Hands-on_Ex/Hands-on_Ex08B/Hands-on_Ex08B.html#i-have-a-twin",
    "title": "Hands-on Exercise 08B",
    "section": "4.4 I have a twin :)",
    "text": "4.4 I have a twin :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(\n    size = \"Gp1Gp2 Winnings\",  \n    col = \"OUTLET TYPE\",       \n    border.col = \"black\",      \n    border.lwd = 1             \n  ) +\n  tm_facets(\n    by = \"OUTLET TYPE\",\n    nrow = 1,\n    sync = TRUE\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  }
]